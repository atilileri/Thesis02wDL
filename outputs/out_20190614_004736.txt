Total of 2 configuration(s) will be run
============ Config: 1/2 -> lstmKeras with stepSize: 4 ==============================================
Parameters: {'inputFolder': 'D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'trainingEpoch': 500, 'stepSize': 4, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam'}
================== 2019.06.14 00:47:36 =========================
Initial Scan.
Shuffling...
Reading:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2627 Files with 13 Label(s): ['mb', 'ek', 'by', 'yd', 'eb', 'ib', 'ce', 'sg', 'sk', 'ds', 'ck', 'eo', 'my'].
Padding:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 2627 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/
Total of 13 classes
2048 steps for training, 579 steps for test
------Model for Mags------
Train Batch: (2048, 11988, 36)
Test Batch: (579, 11988, 36)
Optimizer: <keras.optimizers.Adam object at 0x000001F880FEFB00>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001F8D99F80D0>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 249, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 249, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 10, 16)            3088      
_________________________________________________________________
activation_2 (Activation)    (None, 10, 16)            0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 10, 24)            3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 13)                169       
=================================================================
Total params: 22,801
Trainable params: 22,801
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.5476, Accuracy:0.1030
Epoch #2: Loss:2.5395, Accuracy:0.1118
Epoch #3: Loss:2.5339, Accuracy:0.1187
Epoch #4: Loss:2.5304, Accuracy:0.1187
Epoch #5: Loss:2.5273, Accuracy:0.1187
Epoch #6: Loss:2.5247, Accuracy:0.1187
Epoch #7: Loss:2.5221, Accuracy:0.1187
Epoch #8: Loss:2.5195, Accuracy:0.1187
Epoch #9: Loss:2.5176, Accuracy:0.1187
Epoch #10: Loss:2.5151, Accuracy:0.1187
Epoch #11: Loss:2.5126, Accuracy:0.1187
Epoch #12: Loss:2.5089, Accuracy:0.1187
Epoch #13: Loss:2.5034, Accuracy:0.1187
Epoch #14: Loss:2.4937, Accuracy:0.1196
Epoch #15: Loss:2.4779, Accuracy:0.1313
Epoch #16: Loss:2.4510, Accuracy:0.1392
Epoch #17: Loss:2.4142, Accuracy:0.1821
Epoch #18: Loss:2.3753, Accuracy:0.2256
Epoch #19: Loss:2.3430, Accuracy:0.2163
Epoch #20: Loss:2.3178, Accuracy:0.2134
Epoch #21: Loss:2.2948, Accuracy:0.2275
Epoch #22: Loss:2.2712, Accuracy:0.2153
Epoch #23: Loss:2.2482, Accuracy:0.1987
Epoch #24: Loss:2.2266, Accuracy:0.2021
Epoch #25: Loss:2.2075, Accuracy:0.2036
Epoch #26: Loss:2.1869, Accuracy:0.2046
Epoch #27: Loss:2.1684, Accuracy:0.2344
Epoch #28: Loss:2.1488, Accuracy:0.2651
Epoch #29: Loss:2.1280, Accuracy:0.2686
Epoch #30: Loss:2.1096, Accuracy:0.2871
Epoch #31: Loss:2.0909, Accuracy:0.3213
Epoch #32: Loss:2.0733, Accuracy:0.3213
Epoch #33: Loss:2.0594, Accuracy:0.3179
Epoch #34: Loss:2.0468, Accuracy:0.2954
Epoch #35: Loss:2.0227, Accuracy:0.3091
Epoch #36: Loss:2.0077, Accuracy:0.3120
Epoch #37: Loss:1.9965, Accuracy:0.3179
Epoch #38: Loss:1.9860, Accuracy:0.3096
Epoch #39: Loss:1.9728, Accuracy:0.3154
Epoch #40: Loss:1.9576, Accuracy:0.3271
Epoch #41: Loss:1.9474, Accuracy:0.3306
Epoch #42: Loss:1.9378, Accuracy:0.3267
Epoch #43: Loss:1.9494, Accuracy:0.3091
Epoch #44: Loss:1.9274, Accuracy:0.3232
Epoch #45: Loss:1.9109, Accuracy:0.3301
Epoch #46: Loss:1.9032, Accuracy:0.3423
Epoch #47: Loss:1.8936, Accuracy:0.3418
Epoch #48: Loss:1.8998, Accuracy:0.3325
Epoch #49: Loss:1.8933, Accuracy:0.3369
Epoch #50: Loss:1.8914, Accuracy:0.3320
Epoch #51: Loss:1.8735, Accuracy:0.3472
Epoch #52: Loss:1.8909, Accuracy:0.3418
Epoch #53: Loss:1.8813, Accuracy:0.3281
Epoch #54: Loss:1.8593, Accuracy:0.3530
Epoch #55: Loss:1.8553, Accuracy:0.3442
Epoch #56: Loss:1.8516, Accuracy:0.3511
Epoch #57: Loss:1.8483, Accuracy:0.3618
Epoch #58: Loss:1.8449, Accuracy:0.3442
Epoch #59: Loss:1.8421, Accuracy:0.3496
Epoch #60: Loss:1.8365, Accuracy:0.3613
Epoch #61: Loss:1.8310, Accuracy:0.3525
Epoch #62: Loss:1.8338, Accuracy:0.3574
Epoch #63: Loss:1.8216, Accuracy:0.3657
Epoch #64: Loss:1.8171, Accuracy:0.3677
Epoch #65: Loss:1.8161, Accuracy:0.3628
Epoch #66: Loss:1.8087, Accuracy:0.3638
Epoch #67: Loss:1.8067, Accuracy:0.3657
Epoch #68: Loss:1.8028, Accuracy:0.3755
Epoch #69: Loss:1.7997, Accuracy:0.3687
Epoch #70: Loss:1.7959, Accuracy:0.3696
Epoch #71: Loss:1.7977, Accuracy:0.3721
Epoch #72: Loss:1.7962, Accuracy:0.3643
Epoch #73: Loss:1.7898, Accuracy:0.3701
Epoch #74: Loss:1.8117, Accuracy:0.3613
Epoch #75: Loss:1.8010, Accuracy:0.3613
Epoch #76: Loss:1.7934, Accuracy:0.3677
Epoch #77: Loss:1.7922, Accuracy:0.3633
Epoch #78: Loss:1.7934, Accuracy:0.3633
Epoch #79: Loss:1.7876, Accuracy:0.3760
Epoch #80: Loss:1.7793, Accuracy:0.3745
Epoch #81: Loss:1.7773, Accuracy:0.3711
Epoch #82: Loss:1.7692, Accuracy:0.3823
Epoch #83: Loss:1.7745, Accuracy:0.3677
Epoch #84: Loss:1.7834, Accuracy:0.3730
Epoch #85: Loss:1.7761, Accuracy:0.3657
Epoch #86: Loss:1.7646, Accuracy:0.3804
Epoch #87: Loss:1.7710, Accuracy:0.3721
Epoch #88: Loss:1.7712, Accuracy:0.3755
Epoch #89: Loss:1.7644, Accuracy:0.3750
Epoch #90: Loss:1.7609, Accuracy:0.3745
Epoch #91: Loss:1.7578, Accuracy:0.3770
Epoch #92: Loss:1.7725, Accuracy:0.3765
Epoch #93: Loss:1.7633, Accuracy:0.3789
Epoch #94: Loss:1.7767, Accuracy:0.3818
Epoch #95: Loss:1.7632, Accuracy:0.3760
Epoch #96: Loss:1.7736, Accuracy:0.3726
Epoch #97: Loss:1.7724, Accuracy:0.3745
Epoch #98: Loss:1.7658, Accuracy:0.3799
Epoch #99: Loss:1.7548, Accuracy:0.3818
Epoch #100: Loss:1.7435, Accuracy:0.3818
Epoch #101: Loss:1.7579, Accuracy:0.3848
Epoch #102: Loss:1.7498, Accuracy:0.3838
Epoch #103: Loss:1.7471, Accuracy:0.3735
Epoch #104: Loss:1.7581, Accuracy:0.3750
Epoch #105: Loss:1.7434, Accuracy:0.3823
Epoch #106: Loss:1.7380, Accuracy:0.3770
Epoch #107: Loss:1.7368, Accuracy:0.3804
Epoch #108: Loss:1.7318, Accuracy:0.3877
Epoch #109: Loss:1.7297, Accuracy:0.3857
Epoch #110: Loss:1.7288, Accuracy:0.3853
Epoch #111: Loss:1.7368, Accuracy:0.3887
Epoch #112: Loss:1.7264, Accuracy:0.3887
Epoch #113: Loss:1.7276, Accuracy:0.3818
Epoch #114: Loss:1.7235, Accuracy:0.3896
Epoch #115: Loss:1.7268, Accuracy:0.3882
Epoch #116: Loss:1.7239, Accuracy:0.3838
Epoch #117: Loss:1.7481, Accuracy:0.3911
Epoch #118: Loss:1.7358, Accuracy:0.3853
Epoch #119: Loss:1.7213, Accuracy:0.3818
Epoch #120: Loss:1.7166, Accuracy:0.3926
Epoch #121: Loss:1.7168, Accuracy:0.3916
Epoch #122: Loss:1.7184, Accuracy:0.3950
Epoch #123: Loss:1.7166, Accuracy:0.3936
Epoch #124: Loss:1.7138, Accuracy:0.3916
Epoch #125: Loss:1.7253, Accuracy:0.3896
Epoch #126: Loss:1.7193, Accuracy:0.3926
Epoch #127: Loss:1.7068, Accuracy:0.3916
Epoch #128: Loss:1.7086, Accuracy:0.3975
Epoch #129: Loss:1.7054, Accuracy:0.3945
Epoch #130: Loss:1.7016, Accuracy:0.3999
Epoch #131: Loss:1.7002, Accuracy:0.3945
Epoch #132: Loss:1.7068, Accuracy:0.3921
Epoch #133: Loss:1.6962, Accuracy:0.4023
Epoch #134: Loss:1.6928, Accuracy:0.4023
Epoch #135: Loss:1.6897, Accuracy:0.4033
Epoch #136: Loss:1.7028, Accuracy:0.3994
Epoch #137: Loss:1.6984, Accuracy:0.3989
Epoch #138: Loss:1.6973, Accuracy:0.4033
Epoch #139: Loss:1.6860, Accuracy:0.4048
Epoch #140: Loss:1.6867, Accuracy:0.4087
Epoch #141: Loss:1.6823, Accuracy:0.4092
Epoch #142: Loss:1.6799, Accuracy:0.4082
Epoch #143: Loss:1.6873, Accuracy:0.4038
Epoch #144: Loss:1.7096, Accuracy:0.4004
Epoch #145: Loss:1.6977, Accuracy:0.3965
Epoch #146: Loss:1.6818, Accuracy:0.4146
Epoch #147: Loss:1.6785, Accuracy:0.4150
Epoch #148: Loss:1.6712, Accuracy:0.4121
Epoch #149: Loss:1.6710, Accuracy:0.4199
Epoch #150: Loss:1.6728, Accuracy:0.4062
Epoch #151: Loss:1.6724, Accuracy:0.4146
Epoch #152: Loss:1.7020, Accuracy:0.3926
Epoch #153: Loss:1.6710, Accuracy:0.4077
Epoch #154: Loss:1.6738, Accuracy:0.4077
Epoch #155: Loss:1.6563, Accuracy:0.4194
Epoch #156: Loss:1.6532, Accuracy:0.4209
Epoch #157: Loss:1.6583, Accuracy:0.4248
Epoch #158: Loss:1.6581, Accuracy:0.4238
Epoch #159: Loss:1.6484, Accuracy:0.4272
Epoch #160: Loss:1.6495, Accuracy:0.4243
Epoch #161: Loss:1.6494, Accuracy:0.4268
Epoch #162: Loss:1.6412, Accuracy:0.4307
Epoch #163: Loss:1.6469, Accuracy:0.4253
Epoch #164: Loss:1.6387, Accuracy:0.4297
Epoch #165: Loss:1.6367, Accuracy:0.4282
Epoch #166: Loss:1.6365, Accuracy:0.4312
Epoch #167: Loss:1.6317, Accuracy:0.4326
Epoch #168: Loss:1.6316, Accuracy:0.4258
Epoch #169: Loss:1.6256, Accuracy:0.4321
Epoch #170: Loss:1.6277, Accuracy:0.4360
Epoch #171: Loss:1.6224, Accuracy:0.4346
Epoch #172: Loss:1.6150, Accuracy:0.4438
Epoch #173: Loss:1.6105, Accuracy:0.4434
Epoch #174: Loss:1.6084, Accuracy:0.4463
Epoch #175: Loss:1.6042, Accuracy:0.4453
Epoch #176: Loss:1.6044, Accuracy:0.4463
Epoch #177: Loss:1.5973, Accuracy:0.4448
Epoch #178: Loss:1.5937, Accuracy:0.4478
Epoch #179: Loss:1.5916, Accuracy:0.4443
Epoch #180: Loss:1.5919, Accuracy:0.4526
Epoch #181: Loss:1.6003, Accuracy:0.4458
Epoch #182: Loss:1.5945, Accuracy:0.4414
Epoch #183: Loss:1.5874, Accuracy:0.4463
Epoch #184: Loss:1.5775, Accuracy:0.4575
Epoch #185: Loss:1.5848, Accuracy:0.4458
Epoch #186: Loss:1.5738, Accuracy:0.4517
Epoch #187: Loss:1.5781, Accuracy:0.4565
Epoch #188: Loss:1.6027, Accuracy:0.4463
Epoch #189: Loss:1.6001, Accuracy:0.4414
Epoch #190: Loss:1.5636, Accuracy:0.4556
Epoch #191: Loss:1.5709, Accuracy:0.4590
Epoch #192: Loss:1.5703, Accuracy:0.4487
Epoch #193: Loss:1.5496, Accuracy:0.4609
Epoch #194: Loss:1.5592, Accuracy:0.4551
Epoch #195: Loss:1.5422, Accuracy:0.4585
Epoch #196: Loss:1.5534, Accuracy:0.4580
Epoch #197: Loss:1.5390, Accuracy:0.4688
Epoch #198: Loss:1.5425, Accuracy:0.4629
Epoch #199: Loss:1.5303, Accuracy:0.4746
Epoch #200: Loss:1.5241, Accuracy:0.4673
Epoch #201: Loss:1.5152, Accuracy:0.4722
Epoch #202: Loss:1.5178, Accuracy:0.4697
Epoch #203: Loss:1.5111, Accuracy:0.4746
Epoch #204: Loss:1.5333, Accuracy:0.4746
Epoch #205: Loss:1.5325, Accuracy:0.4639
Epoch #206: Loss:1.5106, Accuracy:0.4819
Epoch #207: Loss:1.4999, Accuracy:0.4834
Epoch #208: Loss:1.4981, Accuracy:0.4814
Epoch #209: Loss:1.4861, Accuracy:0.4902
Epoch #210: Loss:1.4856, Accuracy:0.4863
Epoch #211: Loss:1.4850, Accuracy:0.4883
Epoch #212: Loss:1.4795, Accuracy:0.4893
Epoch #213: Loss:1.4784, Accuracy:0.4937
Epoch #214: Loss:1.4689, Accuracy:0.4917
Epoch #215: Loss:1.4792, Accuracy:0.4854
Epoch #216: Loss:1.4730, Accuracy:0.4897
Epoch #217: Loss:1.4624, Accuracy:0.4946
Epoch #218: Loss:1.4637, Accuracy:0.4863
Epoch #219: Loss:1.4594, Accuracy:0.4932
Epoch #220: Loss:1.4637, Accuracy:0.4863
Epoch #221: Loss:1.4697, Accuracy:0.4868
Epoch #222: Loss:1.4548, Accuracy:0.4951
Epoch #223: Loss:1.4505, Accuracy:0.4976
Epoch #224: Loss:1.4442, Accuracy:0.4956
Epoch #225: Loss:1.4541, Accuracy:0.4927
Epoch #226: Loss:1.4487, Accuracy:0.4980
Epoch #227: Loss:1.4338, Accuracy:0.5000
Epoch #228: Loss:1.4402, Accuracy:0.4966
Epoch #229: Loss:1.4554, Accuracy:0.4971
Epoch #230: Loss:1.4601, Accuracy:0.4829
Epoch #231: Loss:1.4277, Accuracy:0.5088
Epoch #232: Loss:1.4390, Accuracy:0.4971
Epoch #233: Loss:1.4500, Accuracy:0.4912
Epoch #234: Loss:1.4373, Accuracy:0.5020
Epoch #235: Loss:1.4425, Accuracy:0.4941
Epoch #236: Loss:1.4137, Accuracy:0.5049
Epoch #237: Loss:1.4181, Accuracy:0.5107
Epoch #238: Loss:1.4061, Accuracy:0.5156
Epoch #239: Loss:1.4107, Accuracy:0.5093
Epoch #240: Loss:1.4124, Accuracy:0.5142
Epoch #241: Loss:1.4074, Accuracy:0.5107
Epoch #242: Loss:1.4124, Accuracy:0.5078
Epoch #243: Loss:1.4094, Accuracy:0.5083
Epoch #244: Loss:1.4069, Accuracy:0.5063
Epoch #245: Loss:1.4012, Accuracy:0.5122
Epoch #246: Loss:1.4074, Accuracy:0.5107
Epoch #247: Loss:1.3899, Accuracy:0.5244
Epoch #248: Loss:1.3865, Accuracy:0.5166
Epoch #249: Loss:1.3871, Accuracy:0.5176
Epoch #250: Loss:1.3824, Accuracy:0.5234
Epoch #251: Loss:1.3818, Accuracy:0.5225
Epoch #252: Loss:1.3925, Accuracy:0.5166
Epoch #253: Loss:1.3766, Accuracy:0.5156
Epoch #254: Loss:1.3858, Accuracy:0.5190
Epoch #255: Loss:1.4000, Accuracy:0.5156
Epoch #256: Loss:1.3918, Accuracy:0.5078
Epoch #257: Loss:1.3809, Accuracy:0.5225
Epoch #258: Loss:1.3973, Accuracy:0.5078
Epoch #259: Loss:1.3731, Accuracy:0.5210
Epoch #260: Loss:1.3665, Accuracy:0.5322
Epoch #261: Loss:1.3534, Accuracy:0.5327
Epoch #262: Loss:1.3595, Accuracy:0.5352
Epoch #263: Loss:1.3480, Accuracy:0.5293
Epoch #264: Loss:1.3522, Accuracy:0.5352
Epoch #265: Loss:1.3503, Accuracy:0.5371
Epoch #266: Loss:1.3491, Accuracy:0.5298
Epoch #267: Loss:1.3606, Accuracy:0.5312
Epoch #268: Loss:1.3537, Accuracy:0.5288
Epoch #269: Loss:1.3584, Accuracy:0.5278
Epoch #270: Loss:1.3546, Accuracy:0.5449
Epoch #271: Loss:1.3448, Accuracy:0.5371
Epoch #272: Loss:1.3387, Accuracy:0.5352
Epoch #273: Loss:1.3372, Accuracy:0.5376
Epoch #274: Loss:1.3494, Accuracy:0.5317
Epoch #275: Loss:1.3422, Accuracy:0.5386
Epoch #276: Loss:1.3349, Accuracy:0.5342
Epoch #277: Loss:1.3328, Accuracy:0.5400
Epoch #278: Loss:1.3277, Accuracy:0.5503
Epoch #279: Loss:1.3297, Accuracy:0.5366
Epoch #280: Loss:1.3198, Accuracy:0.5532
Epoch #281: Loss:1.3417, Accuracy:0.5420
Epoch #282: Loss:1.3319, Accuracy:0.5454
Epoch #283: Loss:1.3230, Accuracy:0.5430
Epoch #284: Loss:1.3207, Accuracy:0.5420
Epoch #285: Loss:1.3113, Accuracy:0.5547
Epoch #286: Loss:1.3127, Accuracy:0.5571
Epoch #287: Loss:1.3115, Accuracy:0.5552
Epoch #288: Loss:1.3219, Accuracy:0.5518
Epoch #289: Loss:1.3012, Accuracy:0.5566
Epoch #290: Loss:1.3099, Accuracy:0.5532
Epoch #291: Loss:1.3009, Accuracy:0.5566
Epoch #292: Loss:1.3138, Accuracy:0.5493
Epoch #293: Loss:1.3449, Accuracy:0.5293
Epoch #294: Loss:1.3305, Accuracy:0.5371
Epoch #295: Loss:1.3765, Accuracy:0.5234
Epoch #296: Loss:1.3351, Accuracy:0.5293
Epoch #297: Loss:1.3145, Accuracy:0.5425
Epoch #298: Loss:1.3015, Accuracy:0.5469
Epoch #299: Loss:1.2943, Accuracy:0.5542
Epoch #300: Loss:1.2798, Accuracy:0.5645
Epoch #301: Loss:1.2775, Accuracy:0.5635
Epoch #302: Loss:1.2734, Accuracy:0.5645
Epoch #303: Loss:1.2746, Accuracy:0.5620
Epoch #304: Loss:1.2788, Accuracy:0.5654
Epoch #305: Loss:1.2801, Accuracy:0.5605
Epoch #306: Loss:1.2854, Accuracy:0.5566
Epoch #307: Loss:1.2794, Accuracy:0.5591
Epoch #308: Loss:1.2757, Accuracy:0.5630
Epoch #309: Loss:1.2675, Accuracy:0.5654
Epoch #310: Loss:1.2706, Accuracy:0.5669
Epoch #311: Loss:1.2660, Accuracy:0.5713
Epoch #312: Loss:1.2622, Accuracy:0.5703
Epoch #313: Loss:1.2542, Accuracy:0.5752
Epoch #314: Loss:1.2582, Accuracy:0.5684
Epoch #315: Loss:1.2685, Accuracy:0.5645
Epoch #316: Loss:1.2575, Accuracy:0.5718
Epoch #317: Loss:1.2484, Accuracy:0.5762
Epoch #318: Loss:1.2468, Accuracy:0.5752
Epoch #319: Loss:1.2462, Accuracy:0.5791
Epoch #320: Loss:1.2457, Accuracy:0.5762
Epoch #321: Loss:1.2614, Accuracy:0.5684
Epoch #322: Loss:1.2510, Accuracy:0.5659
Epoch #323: Loss:1.2636, Accuracy:0.5630
Epoch #324: Loss:1.2648, Accuracy:0.5664
Epoch #325: Loss:1.2970, Accuracy:0.5488
Epoch #326: Loss:1.2763, Accuracy:0.5645
Epoch #327: Loss:1.2928, Accuracy:0.5547
Epoch #328: Loss:1.2627, Accuracy:0.5557
Epoch #329: Loss:1.2699, Accuracy:0.5703
Epoch #330: Loss:1.2862, Accuracy:0.5576
Epoch #331: Loss:1.2549, Accuracy:0.5654
Epoch #332: Loss:1.2497, Accuracy:0.5698
Epoch #333: Loss:1.2515, Accuracy:0.5684
Epoch #334: Loss:1.2333, Accuracy:0.5811
Epoch #335: Loss:1.2190, Accuracy:0.5859
Epoch #336: Loss:1.2164, Accuracy:0.5874
Epoch #337: Loss:1.2130, Accuracy:0.5913
Epoch #338: Loss:1.2142, Accuracy:0.5874
Epoch #339: Loss:1.2151, Accuracy:0.5845
Epoch #340: Loss:1.2085, Accuracy:0.5864
Epoch #341: Loss:1.2121, Accuracy:0.5884
Epoch #342: Loss:1.1976, Accuracy:0.5928
Epoch #343: Loss:1.2056, Accuracy:0.5913
Epoch #344: Loss:1.2126, Accuracy:0.5840
Epoch #345: Loss:1.2110, Accuracy:0.5854
Epoch #346: Loss:1.2021, Accuracy:0.5908
Epoch #347: Loss:1.1974, Accuracy:0.6006
Epoch #348: Loss:1.2096, Accuracy:0.5874
Epoch #349: Loss:1.2025, Accuracy:0.5884
Epoch #350: Loss:1.1956, Accuracy:0.5918
Epoch #351: Loss:1.1839, Accuracy:0.5967
Epoch #352: Loss:1.1824, Accuracy:0.6011
Epoch #353: Loss:1.1834, Accuracy:0.5947
Epoch #354: Loss:1.1888, Accuracy:0.5903
Epoch #355: Loss:1.1955, Accuracy:0.5928
Epoch #356: Loss:1.1969, Accuracy:0.5938
Epoch #357: Loss:1.1951, Accuracy:0.5913
Epoch #358: Loss:1.1834, Accuracy:0.6025
Epoch #359: Loss:1.1948, Accuracy:0.5918
Epoch #360: Loss:1.2149, Accuracy:0.5718
Epoch #361: Loss:1.2114, Accuracy:0.5811
Epoch #362: Loss:1.2193, Accuracy:0.5771
Epoch #363: Loss:1.1901, Accuracy:0.5879
Epoch #364: Loss:1.1871, Accuracy:0.5928
Epoch #365: Loss:1.1706, Accuracy:0.6011
Epoch #366: Loss:1.1704, Accuracy:0.5957
Epoch #367: Loss:1.1484, Accuracy:0.6074
Epoch #368: Loss:1.1510, Accuracy:0.6055
Epoch #369: Loss:1.1495, Accuracy:0.6055
Epoch #370: Loss:1.1494, Accuracy:0.6040
Epoch #371: Loss:1.1499, Accuracy:0.6079
Epoch #372: Loss:1.1411, Accuracy:0.6040
Epoch #373: Loss:1.1453, Accuracy:0.6094
Epoch #374: Loss:1.1462, Accuracy:0.5991
Epoch #375: Loss:1.1476, Accuracy:0.6113
Epoch #376: Loss:1.1383, Accuracy:0.6177
Epoch #377: Loss:1.1370, Accuracy:0.6050
Epoch #378: Loss:1.1274, Accuracy:0.6152
Epoch #379: Loss:1.1295, Accuracy:0.6152
Epoch #380: Loss:1.1563, Accuracy:0.5981
Epoch #381: Loss:1.1313, Accuracy:0.6099
Epoch #382: Loss:1.1295, Accuracy:0.6128
Epoch #383: Loss:1.1308, Accuracy:0.6084
Epoch #384: Loss:1.1227, Accuracy:0.6099
Epoch #385: Loss:1.1183, Accuracy:0.6172
Epoch #386: Loss:1.1230, Accuracy:0.6162
Epoch #387: Loss:1.1132, Accuracy:0.6104
Epoch #388: Loss:1.1151, Accuracy:0.6138
Epoch #389: Loss:1.1248, Accuracy:0.6108
Epoch #390: Loss:1.1411, Accuracy:0.5981
Epoch #391: Loss:1.1387, Accuracy:0.6084
Epoch #392: Loss:1.1357, Accuracy:0.6064
Epoch #393: Loss:1.1206, Accuracy:0.6094
Epoch #394: Loss:1.1229, Accuracy:0.6196
Epoch #395: Loss:1.0989, Accuracy:0.6191
Epoch #396: Loss:1.1024, Accuracy:0.6182
Epoch #397: Loss:1.1005, Accuracy:0.6123
Epoch #398: Loss:1.1101, Accuracy:0.6162
Epoch #399: Loss:1.0973, Accuracy:0.6284
Epoch #400: Loss:1.1024, Accuracy:0.6196
Epoch #401: Loss:1.0891, Accuracy:0.6182
Epoch #402: Loss:1.0807, Accuracy:0.6323
Epoch #403: Loss:1.0889, Accuracy:0.6235
Epoch #404: Loss:1.0896, Accuracy:0.6245
Epoch #405: Loss:1.0984, Accuracy:0.6211
Epoch #406: Loss:1.1496, Accuracy:0.5962
Epoch #407: Loss:1.1204, Accuracy:0.6255
Epoch #408: Loss:1.0870, Accuracy:0.6245
Epoch #409: Loss:1.0729, Accuracy:0.6328
Epoch #410: Loss:1.0636, Accuracy:0.6313
Epoch #411: Loss:1.0601, Accuracy:0.6367
Epoch #412: Loss:1.0716, Accuracy:0.6299
Epoch #413: Loss:1.0776, Accuracy:0.6323
Epoch #414: Loss:1.0717, Accuracy:0.6328
Epoch #415: Loss:1.0905, Accuracy:0.6235
Epoch #416: Loss:1.0887, Accuracy:0.6187
Epoch #417: Loss:1.0641, Accuracy:0.6392
Epoch #418: Loss:1.0829, Accuracy:0.6221
Epoch #419: Loss:1.0944, Accuracy:0.6279
Epoch #420: Loss:1.0746, Accuracy:0.6304
Epoch #421: Loss:1.0667, Accuracy:0.6377
Epoch #422: Loss:1.0535, Accuracy:0.6372
Epoch #423: Loss:1.0480, Accuracy:0.6367
Epoch #424: Loss:1.0566, Accuracy:0.6372
Epoch #425: Loss:1.0529, Accuracy:0.6313
Epoch #426: Loss:1.0495, Accuracy:0.6377
Epoch #427: Loss:1.0533, Accuracy:0.6445
Epoch #428: Loss:1.0577, Accuracy:0.6377
Epoch #429: Loss:1.0523, Accuracy:0.6372
Epoch #430: Loss:1.0367, Accuracy:0.6436
Epoch #431: Loss:1.0451, Accuracy:0.6426
Epoch #432: Loss:1.0387, Accuracy:0.6382
Epoch #433: Loss:1.0403, Accuracy:0.6436
Epoch #434: Loss:1.0271, Accuracy:0.6470
Epoch #435: Loss:1.0316, Accuracy:0.6440
Epoch #436: Loss:1.0392, Accuracy:0.6470
Epoch #437: Loss:1.0305, Accuracy:0.6504
Epoch #438: Loss:1.0322, Accuracy:0.6392
Epoch #439: Loss:1.0388, Accuracy:0.6421
Epoch #440: Loss:1.0336, Accuracy:0.6406
Epoch #441: Loss:1.0300, Accuracy:0.6436
Epoch #442: Loss:1.0561, Accuracy:0.6333
Epoch #443: Loss:1.0659, Accuracy:0.6343
Epoch #444: Loss:1.0432, Accuracy:0.6436
Epoch #445: Loss:1.0316, Accuracy:0.6426
Epoch #446: Loss:1.0126, Accuracy:0.6562
Epoch #447: Loss:1.0240, Accuracy:0.6494
Epoch #448: Loss:1.0247, Accuracy:0.6401
Epoch #449: Loss:1.0286, Accuracy:0.6392
Epoch #450: Loss:1.0226, Accuracy:0.6455
Epoch #451: Loss:1.0192, Accuracy:0.6426
Epoch #452: Loss:1.0278, Accuracy:0.6460
Epoch #453: Loss:1.0184, Accuracy:0.6401
Epoch #454: Loss:1.0090, Accuracy:0.6562
Epoch #455: Loss:1.0279, Accuracy:0.6528
Epoch #456: Loss:1.0354, Accuracy:0.6416
Epoch #457: Loss:1.0658, Accuracy:0.6299
Epoch #458: Loss:1.0680, Accuracy:0.6240
Epoch #459: Loss:1.0589, Accuracy:0.6221
Epoch #460: Loss:1.0094, Accuracy:0.6543
Epoch #461: Loss:1.0324, Accuracy:0.6318
Epoch #462: Loss:1.0115, Accuracy:0.6572
Epoch #463: Loss:1.0055, Accuracy:0.6465
Epoch #464: Loss:0.9992, Accuracy:0.6577
Epoch #465: Loss:0.9907, Accuracy:0.6626
Epoch #466: Loss:1.0187, Accuracy:0.6406
Epoch #467: Loss:0.9850, Accuracy:0.6626
Epoch #468: Loss:0.9934, Accuracy:0.6606
Epoch #469: Loss:1.0024, Accuracy:0.6475
Epoch #470: Loss:0.9843, Accuracy:0.6587
Epoch #471: Loss:0.9727, Accuracy:0.6636
Epoch #472: Loss:0.9661, Accuracy:0.6650
Epoch #473: Loss:0.9709, Accuracy:0.6655
Epoch #474: Loss:0.9921, Accuracy:0.6567
Epoch #475: Loss:0.9963, Accuracy:0.6523
Epoch #476: Loss:0.9819, Accuracy:0.6650
Epoch #477: Loss:0.9964, Accuracy:0.6538
Epoch #478: Loss:0.9945, Accuracy:0.6504
Epoch #479: Loss:0.9948, Accuracy:0.6587
Epoch #480: Loss:0.9755, Accuracy:0.6680
Epoch #481: Loss:0.9533, Accuracy:0.6748
Epoch #482: Loss:0.9606, Accuracy:0.6768
Epoch #483: Loss:0.9739, Accuracy:0.6655
Epoch #484: Loss:0.9789, Accuracy:0.6670
Epoch #485: Loss:0.9693, Accuracy:0.6650
Epoch #486: Loss:0.9994, Accuracy:0.6553
Epoch #487: Loss:0.9988, Accuracy:0.6538
Epoch #488: Loss:0.9581, Accuracy:0.6772
Epoch #489: Loss:0.9723, Accuracy:0.6719
Epoch #490: Loss:0.9575, Accuracy:0.6738
Epoch #491: Loss:0.9695, Accuracy:0.6655
Epoch #492: Loss:0.9596, Accuracy:0.6694
Epoch #493: Loss:0.9467, Accuracy:0.6753
Epoch #494: Loss:0.9511, Accuracy:0.6763
Epoch #495: Loss:0.9369, Accuracy:0.6733
Epoch #496: Loss:0.9507, Accuracy:0.6694
Epoch #497: Loss:0.9543, Accuracy:0.6709
Epoch #498: Loss:0.9376, Accuracy:0.6748
Epoch #499: Loss:0.9323, Accuracy:0.6787
Epoch #500: Loss:0.9431, Accuracy:0.6748

Test:
Test Loss:0.9890, Accuracy:0.6356
Labels: ['mb', 'ek', 'by', 'yd', 'eb', 'ib', 'ce', 'sg', 'sk', 'ds', 'ck', 'eo', 'my']
Confusion Matrix:
[[42  2  0  0  3  0  0  0  0  5  5  0  0]
 [ 7 30  0  1  8  0  0  0  4  2  1  0  0]
 [ 0  0 32  2  0  2  2  6  0  0  0  0  0]
 [ 0  5  0 58  0  0  0  5  0  0  0  0  0]
 [ 0  1  0  0 50  0  0  0  2  2  0  0  1]
 [ 2  0  1  2  0 37  8  7  1  0  2  0  0]
 [ 1  0  2  0  0 10 11  1  3  0  1  1  0]
 [ 0  1  2 12  0 11  1 29  0  0  0  0  0]
 [ 0  0  0  0  2  0  1  0 29  0  3  0  1]
 [ 4  2  0  0 11  1  0  0  5  7  3  0  2]
 [ 1  0  0  0  1  0  2  0 11  1  9  0  0]
 [ 0  0  2  0  0  1  1  0  0  0  0 33  0]
 [ 1  0  0  0  1  0  1  0  8  2  8  0  1]]
Classification Report:
              precision    recall  f1-score   support

          mb       0.72      0.74      0.73        57
          ek       0.73      0.57      0.64        53
          by       0.82      0.73      0.77        44
          yd       0.77      0.85      0.81        68
          eb       0.66      0.89      0.76        56
          ib       0.60      0.62      0.61        60
          ce       0.41      0.37      0.39        30
          sg       0.60      0.52      0.56        56
          sk       0.46      0.81      0.59        36
          ds       0.37      0.20      0.26        35
          ck       0.28      0.36      0.32        25
          eo       0.97      0.89      0.93        37
          my       0.20      0.05      0.07        22

   micro avg       0.64      0.64      0.64       579
   macro avg       0.58      0.58      0.57       579
weighted avg       0.63      0.64      0.62       579

============ Config: 2/2 -> lstmKeras with stepSize: 4 ==============================================
Parameters: {'inputFolder': 'D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'trainingEpoch': 500, 'stepSize': 4, 'batchSize': 512, 'learningRate': 0.002, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam'}
================== 2019.06.14 01:52:52 =========================
Initial Scan.
Shuffling...
Reading:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2627 Files with 13 Label(s): ['eb', 'ib', 'my', 'yd', 'by', 'sk', 'mb', 'sg', 'ek', 'ck', 'ce', 'ds', 'eo'].
Padding:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 2627 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/
Total of 13 classes
2048 steps for training, 579 steps for test

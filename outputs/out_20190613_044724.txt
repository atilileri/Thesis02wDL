Total of 18 configuration(s) will be run
============ Config: 1/18 -> lstmKeras with stepSize: 4 ==============================================
Parameters: {'inputFolder': 'D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'trainingEpoch': 400, 'stepSize': 4, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam'}
================== 2019.06.13 04:47:24 =========================
Initial Scan.
Shuffling...
Reading:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2627 Files with 13 Label(s): ['sg', 'yd', 'ib', 'sk', 'mb', 'ce', 'my', 'eo', 'eb', 'ek', 'by', 'ck', 'ds'].
Padding:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 2627 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/
Total of 13 classes
2048 steps or training, 579 steps for test
------Model for Mags------
Train Batch: (2048, 11988, 36)
Test Batch: (579, 11988, 36)
Optimizer: <keras.optimizers.Adam object at 0x0000028900213CF8>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000002894EEA8048>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 249, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 249, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 10, 16)            3088      
_________________________________________________________________
activation_2 (Activation)    (None, 10, 16)            0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 10, 24)            3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 13)                169       
=================================================================
Total params: 22,801
Trainable params: 22,801
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.5729, Accuracy:0.0986
Epoch #2: Loss:2.5569, Accuracy:0.0986
Epoch #3: Loss:2.5464, Accuracy:0.0986
Epoch #4: Loss:2.5384, Accuracy:0.1030
Epoch #5: Loss:2.5336, Accuracy:0.1030
Epoch #6: Loss:2.5291, Accuracy:0.1030
Epoch #7: Loss:2.5250, Accuracy:0.1187
Epoch #8: Loss:2.5219, Accuracy:0.1187
Epoch #9: Loss:2.5197, Accuracy:0.1187
Epoch #10: Loss:2.5175, Accuracy:0.1187
Epoch #11: Loss:2.5155, Accuracy:0.1187
Epoch #12: Loss:2.5138, Accuracy:0.1187
Epoch #13: Loss:2.5111, Accuracy:0.1187
Epoch #14: Loss:2.5071, Accuracy:0.1187
Epoch #15: Loss:2.5017, Accuracy:0.1187
Epoch #16: Loss:2.4936, Accuracy:0.1187
Epoch #17: Loss:2.4808, Accuracy:0.1187
Epoch #18: Loss:2.4627, Accuracy:0.1201
Epoch #19: Loss:2.4386, Accuracy:0.1270
Epoch #20: Loss:2.4079, Accuracy:0.1587
Epoch #21: Loss:2.3759, Accuracy:0.1797
Epoch #22: Loss:2.3457, Accuracy:0.2065
Epoch #23: Loss:2.3193, Accuracy:0.2080
Epoch #24: Loss:2.2939, Accuracy:0.2207
Epoch #25: Loss:2.2647, Accuracy:0.2178
Epoch #26: Loss:2.2344, Accuracy:0.2075
Epoch #27: Loss:2.2086, Accuracy:0.2104
Epoch #28: Loss:2.1791, Accuracy:0.2202
Epoch #29: Loss:2.1513, Accuracy:0.2095
Epoch #30: Loss:2.1301, Accuracy:0.2212
Epoch #31: Loss:2.1041, Accuracy:0.2383
Epoch #32: Loss:2.0820, Accuracy:0.2695
Epoch #33: Loss:2.0605, Accuracy:0.2832
Epoch #34: Loss:2.0423, Accuracy:0.2900
Epoch #35: Loss:2.0283, Accuracy:0.2935
Epoch #36: Loss:2.0136, Accuracy:0.2959
Epoch #37: Loss:2.0033, Accuracy:0.2993
Epoch #38: Loss:1.9927, Accuracy:0.2993
Epoch #39: Loss:1.9854, Accuracy:0.3032
Epoch #40: Loss:1.9687, Accuracy:0.3057
Epoch #41: Loss:1.9574, Accuracy:0.2998
Epoch #42: Loss:1.9525, Accuracy:0.3159
Epoch #43: Loss:1.9371, Accuracy:0.3057
Epoch #44: Loss:1.9270, Accuracy:0.3198
Epoch #45: Loss:1.9155, Accuracy:0.3267
Epoch #46: Loss:1.9092, Accuracy:0.3179
Epoch #47: Loss:1.9009, Accuracy:0.3252
Epoch #48: Loss:1.8918, Accuracy:0.3330
Epoch #49: Loss:1.8867, Accuracy:0.3325
Epoch #50: Loss:1.8753, Accuracy:0.3467
Epoch #51: Loss:1.8708, Accuracy:0.3389
Epoch #52: Loss:1.8658, Accuracy:0.3384
Epoch #53: Loss:1.8579, Accuracy:0.3481
Epoch #54: Loss:1.8523, Accuracy:0.3496
Epoch #55: Loss:1.8427, Accuracy:0.3584
Epoch #56: Loss:1.8377, Accuracy:0.3481
Epoch #57: Loss:1.8331, Accuracy:0.3599
Epoch #58: Loss:1.8321, Accuracy:0.3555
Epoch #59: Loss:1.8292, Accuracy:0.3428
Epoch #60: Loss:1.8283, Accuracy:0.3496
Epoch #61: Loss:1.8283, Accuracy:0.3535
Epoch #62: Loss:1.8144, Accuracy:0.3511
Epoch #63: Loss:1.8143, Accuracy:0.3613
Epoch #64: Loss:1.8056, Accuracy:0.3594
Epoch #65: Loss:1.8013, Accuracy:0.3579
Epoch #66: Loss:1.8007, Accuracy:0.3657
Epoch #67: Loss:1.7982, Accuracy:0.3638
Epoch #68: Loss:1.7926, Accuracy:0.3657
Epoch #69: Loss:1.7896, Accuracy:0.3779
Epoch #70: Loss:1.7868, Accuracy:0.3789
Epoch #71: Loss:1.7813, Accuracy:0.3750
Epoch #72: Loss:1.7795, Accuracy:0.3691
Epoch #73: Loss:1.7763, Accuracy:0.3818
Epoch #74: Loss:1.7719, Accuracy:0.3828
Epoch #75: Loss:1.7756, Accuracy:0.3706
Epoch #76: Loss:1.7681, Accuracy:0.3896
Epoch #77: Loss:1.7649, Accuracy:0.3696
Epoch #78: Loss:1.7579, Accuracy:0.3828
Epoch #79: Loss:1.7534, Accuracy:0.3921
Epoch #80: Loss:1.7471, Accuracy:0.3945
Epoch #81: Loss:1.7443, Accuracy:0.3940
Epoch #82: Loss:1.7416, Accuracy:0.3955
Epoch #83: Loss:1.7411, Accuracy:0.3936
Epoch #84: Loss:1.7404, Accuracy:0.3823
Epoch #85: Loss:1.7400, Accuracy:0.3896
Epoch #86: Loss:1.7413, Accuracy:0.3911
Epoch #87: Loss:1.7297, Accuracy:0.3848
Epoch #88: Loss:1.7269, Accuracy:0.3906
Epoch #89: Loss:1.7233, Accuracy:0.3896
Epoch #90: Loss:1.7195, Accuracy:0.3911
Epoch #91: Loss:1.7184, Accuracy:0.3862
Epoch #92: Loss:1.7313, Accuracy:0.3862
Epoch #93: Loss:1.7139, Accuracy:0.3945
Epoch #94: Loss:1.7086, Accuracy:0.3984
Epoch #95: Loss:1.7275, Accuracy:0.3833
Epoch #96: Loss:1.7115, Accuracy:0.3921
Epoch #97: Loss:1.7059, Accuracy:0.3970
Epoch #98: Loss:1.7130, Accuracy:0.3877
Epoch #99: Loss:1.7049, Accuracy:0.3906
Epoch #100: Loss:1.7134, Accuracy:0.3994
Epoch #101: Loss:1.7114, Accuracy:0.3950
Epoch #102: Loss:1.6953, Accuracy:0.3945
Epoch #103: Loss:1.6827, Accuracy:0.4014
Epoch #104: Loss:1.6817, Accuracy:0.3979
Epoch #105: Loss:1.6768, Accuracy:0.3984
Epoch #106: Loss:1.6743, Accuracy:0.3989
Epoch #107: Loss:1.6699, Accuracy:0.4014
Epoch #108: Loss:1.6660, Accuracy:0.4077
Epoch #109: Loss:1.6690, Accuracy:0.4004
Epoch #110: Loss:1.6651, Accuracy:0.4058
Epoch #111: Loss:1.6601, Accuracy:0.4043
Epoch #112: Loss:1.6515, Accuracy:0.4038
Epoch #113: Loss:1.6486, Accuracy:0.4121
Epoch #114: Loss:1.6457, Accuracy:0.4102
Epoch #115: Loss:1.6411, Accuracy:0.4165
Epoch #116: Loss:1.6415, Accuracy:0.4131
Epoch #117: Loss:1.6342, Accuracy:0.4263
Epoch #118: Loss:1.6388, Accuracy:0.4111
Epoch #119: Loss:1.6314, Accuracy:0.4224
Epoch #120: Loss:1.6200, Accuracy:0.4199
Epoch #121: Loss:1.6124, Accuracy:0.4272
Epoch #122: Loss:1.6152, Accuracy:0.4263
Epoch #123: Loss:1.6129, Accuracy:0.4199
Epoch #124: Loss:1.5955, Accuracy:0.4312
Epoch #125: Loss:1.5937, Accuracy:0.4365
Epoch #126: Loss:1.5916, Accuracy:0.4380
Epoch #127: Loss:1.5939, Accuracy:0.4346
Epoch #128: Loss:1.5938, Accuracy:0.4297
Epoch #129: Loss:1.5787, Accuracy:0.4399
Epoch #130: Loss:1.5645, Accuracy:0.4497
Epoch #131: Loss:1.5561, Accuracy:0.4541
Epoch #132: Loss:1.5490, Accuracy:0.4561
Epoch #133: Loss:1.5425, Accuracy:0.4614
Epoch #134: Loss:1.5367, Accuracy:0.4580
Epoch #135: Loss:1.5331, Accuracy:0.4565
Epoch #136: Loss:1.5255, Accuracy:0.4644
Epoch #137: Loss:1.5185, Accuracy:0.4697
Epoch #138: Loss:1.5206, Accuracy:0.4658
Epoch #139: Loss:1.5124, Accuracy:0.4727
Epoch #140: Loss:1.5174, Accuracy:0.4688
Epoch #141: Loss:1.5040, Accuracy:0.4692
Epoch #142: Loss:1.4992, Accuracy:0.4829
Epoch #143: Loss:1.4908, Accuracy:0.4805
Epoch #144: Loss:1.4881, Accuracy:0.4868
Epoch #145: Loss:1.4749, Accuracy:0.4893
Epoch #146: Loss:1.4701, Accuracy:0.4902
Epoch #147: Loss:1.4815, Accuracy:0.4819
Epoch #148: Loss:1.4843, Accuracy:0.4844
Epoch #149: Loss:1.5116, Accuracy:0.4751
Epoch #150: Loss:1.5042, Accuracy:0.4683
Epoch #151: Loss:1.4802, Accuracy:0.4868
Epoch #152: Loss:1.4601, Accuracy:0.4980
Epoch #153: Loss:1.4540, Accuracy:0.4912
Epoch #154: Loss:1.4438, Accuracy:0.5010
Epoch #155: Loss:1.4407, Accuracy:0.5093
Epoch #156: Loss:1.4420, Accuracy:0.4990
Epoch #157: Loss:1.4312, Accuracy:0.5098
Epoch #158: Loss:1.4216, Accuracy:0.5078
Epoch #159: Loss:1.4144, Accuracy:0.5103
Epoch #160: Loss:1.4138, Accuracy:0.5107
Epoch #161: Loss:1.4166, Accuracy:0.5083
Epoch #162: Loss:1.4015, Accuracy:0.5122
Epoch #163: Loss:1.3970, Accuracy:0.5195
Epoch #164: Loss:1.4068, Accuracy:0.5117
Epoch #165: Loss:1.3926, Accuracy:0.5195
Epoch #166: Loss:1.3957, Accuracy:0.5151
Epoch #167: Loss:1.3917, Accuracy:0.5205
Epoch #168: Loss:1.3908, Accuracy:0.5122
Epoch #169: Loss:1.3779, Accuracy:0.5239
Epoch #170: Loss:1.3806, Accuracy:0.5210
Epoch #171: Loss:1.3723, Accuracy:0.5278
Epoch #172: Loss:1.3712, Accuracy:0.5229
Epoch #173: Loss:1.3752, Accuracy:0.5220
Epoch #174: Loss:1.3861, Accuracy:0.5215
Epoch #175: Loss:1.3592, Accuracy:0.5308
Epoch #176: Loss:1.3641, Accuracy:0.5259
Epoch #177: Loss:1.3545, Accuracy:0.5337
Epoch #178: Loss:1.3502, Accuracy:0.5278
Epoch #179: Loss:1.3565, Accuracy:0.5303
Epoch #180: Loss:1.3666, Accuracy:0.5166
Epoch #181: Loss:1.3619, Accuracy:0.5229
Epoch #182: Loss:1.3542, Accuracy:0.5288
Epoch #183: Loss:1.3397, Accuracy:0.5332
Epoch #184: Loss:1.3425, Accuracy:0.5312
Epoch #185: Loss:1.3519, Accuracy:0.5312
Epoch #186: Loss:1.3549, Accuracy:0.5234
Epoch #187: Loss:1.3910, Accuracy:0.5015
Epoch #188: Loss:1.3770, Accuracy:0.5146
Epoch #189: Loss:1.3613, Accuracy:0.5132
Epoch #190: Loss:1.3411, Accuracy:0.5317
Epoch #191: Loss:1.3450, Accuracy:0.5273
Epoch #192: Loss:1.3465, Accuracy:0.5239
Epoch #193: Loss:1.3360, Accuracy:0.5347
Epoch #194: Loss:1.3352, Accuracy:0.5269
Epoch #195: Loss:1.3159, Accuracy:0.5376
Epoch #196: Loss:1.3235, Accuracy:0.5342
Epoch #197: Loss:1.3192, Accuracy:0.5361
Epoch #198: Loss:1.3342, Accuracy:0.5347
Epoch #199: Loss:1.3211, Accuracy:0.5356
Epoch #200: Loss:1.3249, Accuracy:0.5322
Epoch #201: Loss:1.3367, Accuracy:0.5244
Epoch #202: Loss:1.3398, Accuracy:0.5229
Epoch #203: Loss:1.3167, Accuracy:0.5391
Epoch #204: Loss:1.3118, Accuracy:0.5420
Epoch #205: Loss:1.3080, Accuracy:0.5420
Epoch #206: Loss:1.2942, Accuracy:0.5488
Epoch #207: Loss:1.2890, Accuracy:0.5439
Epoch #208: Loss:1.2893, Accuracy:0.5493
Epoch #209: Loss:1.3016, Accuracy:0.5439
Epoch #210: Loss:1.3127, Accuracy:0.5361
Epoch #211: Loss:1.3039, Accuracy:0.5425
Epoch #212: Loss:1.2949, Accuracy:0.5410
Epoch #213: Loss:1.3084, Accuracy:0.5342
Epoch #214: Loss:1.2943, Accuracy:0.5488
Epoch #215: Loss:1.2846, Accuracy:0.5547
Epoch #216: Loss:1.2761, Accuracy:0.5459
Epoch #217: Loss:1.2724, Accuracy:0.5542
Epoch #218: Loss:1.2724, Accuracy:0.5542
Epoch #219: Loss:1.2787, Accuracy:0.5518
Epoch #220: Loss:1.2676, Accuracy:0.5542
Epoch #221: Loss:1.2631, Accuracy:0.5532
Epoch #222: Loss:1.2817, Accuracy:0.5483
Epoch #223: Loss:1.2694, Accuracy:0.5527
Epoch #224: Loss:1.2604, Accuracy:0.5527
Epoch #225: Loss:1.2638, Accuracy:0.5527
Epoch #226: Loss:1.2805, Accuracy:0.5454
Epoch #227: Loss:1.2756, Accuracy:0.5439
Epoch #228: Loss:1.2617, Accuracy:0.5493
Epoch #229: Loss:1.2537, Accuracy:0.5591
Epoch #230: Loss:1.2512, Accuracy:0.5586
Epoch #231: Loss:1.2490, Accuracy:0.5518
Epoch #232: Loss:1.2525, Accuracy:0.5522
Epoch #233: Loss:1.2465, Accuracy:0.5552
Epoch #234: Loss:1.2437, Accuracy:0.5532
Epoch #235: Loss:1.2468, Accuracy:0.5566
Epoch #236: Loss:1.2444, Accuracy:0.5537
Epoch #237: Loss:1.2426, Accuracy:0.5498
Epoch #238: Loss:1.2453, Accuracy:0.5591
Epoch #239: Loss:1.2562, Accuracy:0.5518
Epoch #240: Loss:1.2391, Accuracy:0.5591
Epoch #241: Loss:1.2494, Accuracy:0.5518
Epoch #242: Loss:1.2484, Accuracy:0.5562
Epoch #243: Loss:1.2381, Accuracy:0.5547
Epoch #244: Loss:1.2503, Accuracy:0.5513
Epoch #245: Loss:1.2369, Accuracy:0.5615
Epoch #246: Loss:1.2334, Accuracy:0.5562
Epoch #247: Loss:1.2384, Accuracy:0.5532
Epoch #248: Loss:1.2337, Accuracy:0.5645
Epoch #249: Loss:1.2261, Accuracy:0.5610
Epoch #250: Loss:1.2147, Accuracy:0.5640
Epoch #251: Loss:1.2171, Accuracy:0.5610
Epoch #252: Loss:1.2147, Accuracy:0.5620
Epoch #253: Loss:1.2217, Accuracy:0.5659
Epoch #254: Loss:1.2168, Accuracy:0.5625
Epoch #255: Loss:1.2107, Accuracy:0.5659
Epoch #256: Loss:1.2135, Accuracy:0.5654
Epoch #257: Loss:1.2212, Accuracy:0.5586
Epoch #258: Loss:1.2192, Accuracy:0.5654
Epoch #259: Loss:1.2109, Accuracy:0.5649
Epoch #260: Loss:1.2107, Accuracy:0.5669
Epoch #261: Loss:1.2126, Accuracy:0.5640
Epoch #262: Loss:1.2072, Accuracy:0.5698
Epoch #263: Loss:1.2037, Accuracy:0.5713
Epoch #264: Loss:1.1960, Accuracy:0.5718
Epoch #265: Loss:1.1950, Accuracy:0.5684
Epoch #266: Loss:1.2036, Accuracy:0.5645
Epoch #267: Loss:1.2230, Accuracy:0.5591
Epoch #268: Loss:1.2023, Accuracy:0.5679
Epoch #269: Loss:1.2020, Accuracy:0.5747
Epoch #270: Loss:1.1941, Accuracy:0.5762
Epoch #271: Loss:1.1883, Accuracy:0.5698
Epoch #272: Loss:1.1899, Accuracy:0.5713
Epoch #273: Loss:1.2096, Accuracy:0.5669
Epoch #274: Loss:1.1933, Accuracy:0.5713
Epoch #275: Loss:1.1894, Accuracy:0.5742
Epoch #276: Loss:1.1963, Accuracy:0.5703
Epoch #277: Loss:1.1881, Accuracy:0.5723
Epoch #278: Loss:1.1937, Accuracy:0.5679
Epoch #279: Loss:1.2136, Accuracy:0.5610
Epoch #280: Loss:1.1887, Accuracy:0.5762
Epoch #281: Loss:1.2019, Accuracy:0.5703
Epoch #282: Loss:1.1851, Accuracy:0.5732
Epoch #283: Loss:1.1865, Accuracy:0.5762
Epoch #284: Loss:1.1769, Accuracy:0.5781
Epoch #285: Loss:1.1691, Accuracy:0.5845
Epoch #286: Loss:1.1607, Accuracy:0.5913
Epoch #287: Loss:1.1611, Accuracy:0.5850
Epoch #288: Loss:1.1668, Accuracy:0.5811
Epoch #289: Loss:1.1582, Accuracy:0.5850
Epoch #290: Loss:1.1654, Accuracy:0.5825
Epoch #291: Loss:1.1547, Accuracy:0.5884
Epoch #292: Loss:1.1552, Accuracy:0.5977
Epoch #293: Loss:1.1553, Accuracy:0.5859
Epoch #294: Loss:1.1482, Accuracy:0.5913
Epoch #295: Loss:1.1511, Accuracy:0.5864
Epoch #296: Loss:1.1473, Accuracy:0.5874
Epoch #297: Loss:1.1515, Accuracy:0.5908
Epoch #298: Loss:1.1418, Accuracy:0.5908
Epoch #299: Loss:1.1483, Accuracy:0.5859
Epoch #300: Loss:1.1424, Accuracy:0.5889
Epoch #301: Loss:1.1392, Accuracy:0.5894
Epoch #302: Loss:1.1463, Accuracy:0.5938
Epoch #303: Loss:1.1515, Accuracy:0.5864
Epoch #304: Loss:1.1520, Accuracy:0.5903
Epoch #305: Loss:1.1471, Accuracy:0.5835
Epoch #306: Loss:1.1402, Accuracy:0.5918
Epoch #307: Loss:1.1276, Accuracy:0.5952
Epoch #308: Loss:1.1277, Accuracy:0.5923
Epoch #309: Loss:1.1438, Accuracy:0.5898
Epoch #310: Loss:1.1402, Accuracy:0.5898
Epoch #311: Loss:1.1273, Accuracy:0.6001
Epoch #312: Loss:1.1185, Accuracy:0.5981
Epoch #313: Loss:1.1195, Accuracy:0.5991
Epoch #314: Loss:1.1241, Accuracy:0.6045
Epoch #315: Loss:1.1361, Accuracy:0.5923
Epoch #316: Loss:1.1360, Accuracy:0.5933
Epoch #317: Loss:1.1433, Accuracy:0.5928
Epoch #318: Loss:1.1620, Accuracy:0.5898
Epoch #319: Loss:1.1381, Accuracy:0.5869
Epoch #320: Loss:1.1253, Accuracy:0.5957
Epoch #321: Loss:1.1068, Accuracy:0.6030
Epoch #322: Loss:1.0986, Accuracy:0.6069
Epoch #323: Loss:1.0996, Accuracy:0.6025
Epoch #324: Loss:1.0993, Accuracy:0.6113
Epoch #325: Loss:1.0932, Accuracy:0.6094
Epoch #326: Loss:1.0932, Accuracy:0.6074
Epoch #327: Loss:1.1024, Accuracy:0.6055
Epoch #328: Loss:1.0988, Accuracy:0.6055
Epoch #329: Loss:1.0942, Accuracy:0.6069
Epoch #330: Loss:1.0897, Accuracy:0.6094
Epoch #331: Loss:1.0908, Accuracy:0.6118
Epoch #332: Loss:1.0941, Accuracy:0.6050
Epoch #333: Loss:1.1176, Accuracy:0.6045
Epoch #334: Loss:1.1153, Accuracy:0.6050
Epoch #335: Loss:1.1081, Accuracy:0.6001
Epoch #336: Loss:1.1218, Accuracy:0.6069
Epoch #337: Loss:1.1095, Accuracy:0.5938
Epoch #338: Loss:1.0842, Accuracy:0.6074
Epoch #339: Loss:1.0798, Accuracy:0.6118
Epoch #340: Loss:1.0803, Accuracy:0.6060
Epoch #341: Loss:1.0801, Accuracy:0.6113
Epoch #342: Loss:1.0805, Accuracy:0.6138
Epoch #343: Loss:1.0793, Accuracy:0.6138
Epoch #344: Loss:1.0933, Accuracy:0.5981
Epoch #345: Loss:1.0747, Accuracy:0.6167
Epoch #346: Loss:1.0642, Accuracy:0.6191
Epoch #347: Loss:1.0752, Accuracy:0.6177
Epoch #348: Loss:1.0618, Accuracy:0.6172
Epoch #349: Loss:1.0552, Accuracy:0.6216
Epoch #350: Loss:1.0684, Accuracy:0.6118
Epoch #351: Loss:1.0609, Accuracy:0.6177
Epoch #352: Loss:1.0656, Accuracy:0.6147
Epoch #353: Loss:1.0531, Accuracy:0.6167
Epoch #354: Loss:1.0636, Accuracy:0.6206
Epoch #355: Loss:1.0735, Accuracy:0.6050
Epoch #356: Loss:1.0575, Accuracy:0.6162
Epoch #357: Loss:1.0494, Accuracy:0.6172
Epoch #358: Loss:1.0491, Accuracy:0.6221
Epoch #359: Loss:1.0477, Accuracy:0.6230
Epoch #360: Loss:1.0542, Accuracy:0.6221
Epoch #361: Loss:1.0492, Accuracy:0.6206
Epoch #362: Loss:1.0557, Accuracy:0.6172
Epoch #363: Loss:1.0569, Accuracy:0.6123
Epoch #364: Loss:1.0467, Accuracy:0.6230
Epoch #365: Loss:1.0552, Accuracy:0.6108
Epoch #366: Loss:1.0399, Accuracy:0.6230
Epoch #367: Loss:1.0473, Accuracy:0.6260
Epoch #368: Loss:1.0671, Accuracy:0.6162
Epoch #369: Loss:1.0819, Accuracy:0.6108
Epoch #370: Loss:1.0539, Accuracy:0.6104
Epoch #371: Loss:1.0370, Accuracy:0.6294
Epoch #372: Loss:1.0336, Accuracy:0.6240
Epoch #373: Loss:1.0276, Accuracy:0.6294
Epoch #374: Loss:1.0299, Accuracy:0.6289
Epoch #375: Loss:1.0545, Accuracy:0.6260
Epoch #376: Loss:1.0283, Accuracy:0.6226
Epoch #377: Loss:1.0307, Accuracy:0.6289
Epoch #378: Loss:1.0617, Accuracy:0.6104
Epoch #379: Loss:1.0296, Accuracy:0.6304
Epoch #380: Loss:1.0351, Accuracy:0.6206
Epoch #381: Loss:1.0527, Accuracy:0.6133
Epoch #382: Loss:1.0363, Accuracy:0.6304
Epoch #383: Loss:1.0379, Accuracy:0.6279
Epoch #384: Loss:1.0169, Accuracy:0.6309
Epoch #385: Loss:1.0226, Accuracy:0.6328
Epoch #386: Loss:1.0140, Accuracy:0.6299
Epoch #387: Loss:1.0100, Accuracy:0.6294
Epoch #388: Loss:1.0101, Accuracy:0.6338
Epoch #389: Loss:1.0146, Accuracy:0.6274
Epoch #390: Loss:1.0002, Accuracy:0.6426
Epoch #391: Loss:1.0049, Accuracy:0.6431
Epoch #392: Loss:1.0247, Accuracy:0.6284
Epoch #393: Loss:1.0198, Accuracy:0.6323
Epoch #394: Loss:1.0157, Accuracy:0.6304
Epoch #395: Loss:1.0144, Accuracy:0.6357
Epoch #396: Loss:1.0093, Accuracy:0.6294
Epoch #397: Loss:1.0122, Accuracy:0.6328
Epoch #398: Loss:0.9927, Accuracy:0.6406
Epoch #399: Loss:0.9940, Accuracy:0.6445
Epoch #400: Loss:0.9887, Accuracy:0.6450

Test:
Test Loss:1.1551, Accuracy:0.5786
Labels: ['sg', 'yd', 'ib', 'sk', 'mb', 'ce', 'my', 'eo', 'eb', 'ek', 'by', 'ck', 'ds']
              precision    recall  f1-score   support

           0       0.59      0.71      0.65        56
           1       0.60      0.96      0.74        68
           2       0.52      0.43      0.47        60
           3       0.39      0.56      0.46        36
           4       0.55      0.39      0.45        57
           5       0.47      0.23      0.31        30
           6       0.00      0.00      0.00        22
           7       0.94      0.81      0.87        37
           8       0.72      0.73      0.73        56
           9       0.54      0.81      0.65        53
          10       0.72      0.59      0.65        44
          11       0.38      0.48      0.42        25
          12       0.30      0.09      0.13        35

   micro avg       0.58      0.58      0.58       579
   macro avg       0.52      0.52      0.50       579
weighted avg       0.55      0.58      0.55       579

============ Config: 2/18 -> lstmKeras with stepSize: 4 ==============================================
Parameters: {'inputFolder': 'D:/atili/MMIExt/Audacity/METU Recordings/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'trainingEpoch': 400, 'stepSize': 4, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Sgd'}
================== 2019.06.13 05:37:08 =========================
Initial Scan.
Shuffling...
Reading:...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2627 Files with 13 Label(s): ['ek', 'yd', 'by', 'ib', 'ce', 'ck', 'sk', 'sg', 'eb', 'ds', 'eo', 'my', 'mb'].
Padding:............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
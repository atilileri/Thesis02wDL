======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: D:\atili\MMIExt\Python Projects\Thesis02wDL\confFiles\conf15.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.11.05 03:40:38 =======================================
Parameters: inputFolder : D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
sampRate : 48
featureMode : Mags
channelMode : 0
classificationMode : Speaker
trainingEpoch : 400
stepSize : 0
batchSize : 64
lengthCut : 600
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
clsVersion : 4
Loading from Previous Data Files...
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_inputs_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labels_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labelDict_Mags_0_Speaker_0_48_600_True.dat
Inputs Shape: (1989, 28800, 9)

Total of 1989 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
Total of 20 classes
1591 steps for training, 398 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (1591, 28800, 9)
Test Batch: (398, 28800, 9)
Classifier Version: 4
Model Layer Parameters:
Name: conv1d_1, Filters: 16, Kernel Size: (96,), Strides: (12,), Activation: linear.
Name: dropout_1, Rate: 0.5.
Name: conv1d_2, Filters: 32, Kernel Size: (48,), Strides: (6,), Activation: linear.
Name: dropout_2, Rate: 0.5.
Name: conv1d_3, Filters: 64, Kernel Size: (24,), Strides: (2,), Activation: linear.
Name: dropout_3, Rate: 0.5.
Name: dropout_4, Rate: 0.5.
Name: dropout_5, Rate: 0.5.
Optimizer: <keras.optimizers.Adam object at 0x0000022B9D2D04A8>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000022AA35C39D8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 2393, 16)          13840     
_________________________________________________________________
dropout_1 (Dropout)          (None, 2393, 16)          0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 391, 32)           24608     
_________________________________________________________________
dropout_2 (Dropout)          (None, 391, 32)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 184, 64)           49216     
_________________________________________________________________
dropout_3 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_1 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_4 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_2 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_5 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_3 (CuDNNGRU)       (None, 32)                9408      
_________________________________________________________________
dense_1 (Dense)              (None, 20)                660       
=================================================================
Total params: 147,652
Trainable params: 147,652
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.9907, Accuracy:0.0484, Validation Loss:2.9542, Validation Accuracy:0.0704
Epoch #2: Loss:2.9537, Accuracy:0.0654, Validation Loss:2.9144, Validation Accuracy:0.0729
Epoch #3: Loss:2.9328, Accuracy:0.0704, Validation Loss:2.8738, Validation Accuracy:0.0829
Epoch #4: Loss:2.9111, Accuracy:0.0698, Validation Loss:2.8624, Validation Accuracy:0.0804
Epoch #5: Loss:2.9051, Accuracy:0.0748, Validation Loss:2.8726, Validation Accuracy:0.0779
Epoch #6: Loss:2.8959, Accuracy:0.0729, Validation Loss:2.8714, Validation Accuracy:0.0779
Epoch #7: Loss:2.8614, Accuracy:0.0974, Validation Loss:2.8336, Validation Accuracy:0.1005
Epoch #8: Loss:2.9063, Accuracy:0.0893, Validation Loss:2.8779, Validation Accuracy:0.0779
Epoch #9: Loss:2.8903, Accuracy:0.0792, Validation Loss:2.8407, Validation Accuracy:0.0930
Epoch #10: Loss:2.8593, Accuracy:0.0823, Validation Loss:2.8456, Validation Accuracy:0.0955
Epoch #11: Loss:2.8530, Accuracy:0.0930, Validation Loss:2.8111, Validation Accuracy:0.0905
Epoch #12: Loss:2.8208, Accuracy:0.1069, Validation Loss:2.8162, Validation Accuracy:0.1005
Epoch #13: Loss:2.7996, Accuracy:0.1018, Validation Loss:2.7816, Validation Accuracy:0.1106
Epoch #14: Loss:2.7674, Accuracy:0.1295, Validation Loss:2.7696, Validation Accuracy:0.1307
Epoch #15: Loss:2.7493, Accuracy:0.1226, Validation Loss:2.7578, Validation Accuracy:0.1281
Epoch #16: Loss:2.7373, Accuracy:0.1314, Validation Loss:2.8060, Validation Accuracy:0.1181
Epoch #17: Loss:2.6676, Accuracy:0.1358, Validation Loss:2.8422, Validation Accuracy:0.0905
Epoch #18: Loss:2.6009, Accuracy:0.1747, Validation Loss:2.6691, Validation Accuracy:0.1734
Epoch #19: Loss:2.5479, Accuracy:0.1785, Validation Loss:2.7566, Validation Accuracy:0.1281
Epoch #20: Loss:2.5129, Accuracy:0.1735, Validation Loss:2.7010, Validation Accuracy:0.1256
Epoch #21: Loss:2.5234, Accuracy:0.1873, Validation Loss:2.7545, Validation Accuracy:0.1307
Epoch #22: Loss:2.4944, Accuracy:0.1942, Validation Loss:2.7556, Validation Accuracy:0.1156
Epoch #23: Loss:2.4482, Accuracy:0.2055, Validation Loss:2.6708, Validation Accuracy:0.1206
Epoch #24: Loss:2.4409, Accuracy:0.2062, Validation Loss:2.6598, Validation Accuracy:0.1231
Epoch #25: Loss:2.4195, Accuracy:0.2099, Validation Loss:2.5771, Validation Accuracy:0.1608
Epoch #26: Loss:2.3897, Accuracy:0.2150, Validation Loss:2.4709, Validation Accuracy:0.2136
Epoch #27: Loss:2.3662, Accuracy:0.2388, Validation Loss:2.4812, Validation Accuracy:0.2161
Epoch #28: Loss:2.3480, Accuracy:0.2376, Validation Loss:2.5967, Validation Accuracy:0.1533
Epoch #29: Loss:2.3160, Accuracy:0.2552, Validation Loss:2.5759, Validation Accuracy:0.1734
Epoch #30: Loss:2.3130, Accuracy:0.2464, Validation Loss:2.4640, Validation Accuracy:0.2035
Epoch #31: Loss:2.2784, Accuracy:0.2759, Validation Loss:2.4011, Validation Accuracy:0.2136
Epoch #32: Loss:2.2504, Accuracy:0.2678, Validation Loss:2.3503, Validation Accuracy:0.2487
Epoch #33: Loss:2.1905, Accuracy:0.2992, Validation Loss:2.3523, Validation Accuracy:0.2236
Epoch #34: Loss:2.1886, Accuracy:0.2847, Validation Loss:2.2963, Validation Accuracy:0.2513
Epoch #35: Loss:2.1857, Accuracy:0.2904, Validation Loss:2.3269, Validation Accuracy:0.2437
Epoch #36: Loss:2.1345, Accuracy:0.3030, Validation Loss:2.2953, Validation Accuracy:0.2663
Epoch #37: Loss:2.1023, Accuracy:0.3218, Validation Loss:2.2957, Validation Accuracy:0.2462
Epoch #38: Loss:2.0510, Accuracy:0.3325, Validation Loss:2.1921, Validation Accuracy:0.2739
Epoch #39: Loss:2.0276, Accuracy:0.3444, Validation Loss:2.1249, Validation Accuracy:0.2814
Epoch #40: Loss:1.9887, Accuracy:0.3520, Validation Loss:2.1295, Validation Accuracy:0.3040
Epoch #41: Loss:1.9630, Accuracy:0.3765, Validation Loss:2.3215, Validation Accuracy:0.2412
Epoch #42: Loss:1.9469, Accuracy:0.3677, Validation Loss:2.1224, Validation Accuracy:0.2940
Epoch #43: Loss:1.9060, Accuracy:0.3765, Validation Loss:2.1102, Validation Accuracy:0.3216
Epoch #44: Loss:1.8892, Accuracy:0.4067, Validation Loss:2.0742, Validation Accuracy:0.3166
Epoch #45: Loss:1.8781, Accuracy:0.3891, Validation Loss:2.1550, Validation Accuracy:0.2915
Epoch #46: Loss:1.8522, Accuracy:0.4023, Validation Loss:2.0198, Validation Accuracy:0.3492
Epoch #47: Loss:1.8134, Accuracy:0.4010, Validation Loss:2.1188, Validation Accuracy:0.3040
Epoch #48: Loss:1.8158, Accuracy:0.4305, Validation Loss:2.1457, Validation Accuracy:0.2990
Epoch #49: Loss:1.7933, Accuracy:0.4268, Validation Loss:2.0896, Validation Accuracy:0.2940
Epoch #50: Loss:1.7555, Accuracy:0.4412, Validation Loss:2.0440, Validation Accuracy:0.3266
Epoch #51: Loss:1.7659, Accuracy:0.4236, Validation Loss:1.9732, Validation Accuracy:0.3291
Epoch #52: Loss:1.7536, Accuracy:0.4337, Validation Loss:1.9710, Validation Accuracy:0.3241
Epoch #53: Loss:1.7698, Accuracy:0.4230, Validation Loss:2.0623, Validation Accuracy:0.3216
Epoch #54: Loss:1.7196, Accuracy:0.4268, Validation Loss:2.0573, Validation Accuracy:0.3141
Epoch #55: Loss:1.7057, Accuracy:0.4475, Validation Loss:2.0706, Validation Accuracy:0.3116
Epoch #56: Loss:1.6753, Accuracy:0.4513, Validation Loss:2.0490, Validation Accuracy:0.3291
Epoch #57: Loss:1.6674, Accuracy:0.4507, Validation Loss:1.9617, Validation Accuracy:0.3417
Epoch #58: Loss:1.6517, Accuracy:0.4595, Validation Loss:2.0553, Validation Accuracy:0.3317
Epoch #59: Loss:1.6963, Accuracy:0.4481, Validation Loss:2.0668, Validation Accuracy:0.3417
Epoch #60: Loss:1.6585, Accuracy:0.4532, Validation Loss:2.0746, Validation Accuracy:0.3166
Epoch #61: Loss:1.6610, Accuracy:0.4588, Validation Loss:1.9685, Validation Accuracy:0.3417
Epoch #62: Loss:1.6134, Accuracy:0.4689, Validation Loss:1.9344, Validation Accuracy:0.3693
Epoch #63: Loss:1.5991, Accuracy:0.4720, Validation Loss:2.0003, Validation Accuracy:0.3518
Epoch #64: Loss:1.6187, Accuracy:0.4607, Validation Loss:2.0282, Validation Accuracy:0.3568
Epoch #65: Loss:1.5652, Accuracy:0.5060, Validation Loss:2.0108, Validation Accuracy:0.3543
Epoch #66: Loss:1.5311, Accuracy:0.5116, Validation Loss:1.9455, Validation Accuracy:0.3643
Epoch #67: Loss:1.5484, Accuracy:0.4972, Validation Loss:2.1606, Validation Accuracy:0.2889
Epoch #68: Loss:1.5552, Accuracy:0.4991, Validation Loss:1.9482, Validation Accuracy:0.3794
Epoch #69: Loss:1.5096, Accuracy:0.5079, Validation Loss:2.0111, Validation Accuracy:0.3744
Epoch #70: Loss:1.4990, Accuracy:0.5028, Validation Loss:1.9513, Validation Accuracy:0.3744
Epoch #71: Loss:1.4837, Accuracy:0.5135, Validation Loss:1.9998, Validation Accuracy:0.3819
Epoch #72: Loss:1.5355, Accuracy:0.5041, Validation Loss:1.9512, Validation Accuracy:0.3744
Epoch #73: Loss:1.4618, Accuracy:0.5129, Validation Loss:1.9493, Validation Accuracy:0.3920
Epoch #74: Loss:1.4167, Accuracy:0.5361, Validation Loss:1.9051, Validation Accuracy:0.4045
Epoch #75: Loss:1.3958, Accuracy:0.5500, Validation Loss:1.9416, Validation Accuracy:0.3844
Epoch #76: Loss:1.3990, Accuracy:0.5462, Validation Loss:1.9137, Validation Accuracy:0.4020
Epoch #77: Loss:1.4116, Accuracy:0.5405, Validation Loss:2.0191, Validation Accuracy:0.3945
Epoch #78: Loss:1.4002, Accuracy:0.5437, Validation Loss:1.9911, Validation Accuracy:0.3819
Epoch #79: Loss:1.3916, Accuracy:0.5493, Validation Loss:1.9745, Validation Accuracy:0.3894
Epoch #80: Loss:1.3972, Accuracy:0.5412, Validation Loss:1.9369, Validation Accuracy:0.4296
Epoch #81: Loss:1.3711, Accuracy:0.5563, Validation Loss:1.9434, Validation Accuracy:0.3869
Epoch #82: Loss:1.3840, Accuracy:0.5512, Validation Loss:1.9027, Validation Accuracy:0.4171
Epoch #83: Loss:1.3609, Accuracy:0.5525, Validation Loss:1.9420, Validation Accuracy:0.4095
Epoch #84: Loss:1.3600, Accuracy:0.5575, Validation Loss:1.9743, Validation Accuracy:0.3794
Epoch #85: Loss:1.3337, Accuracy:0.5625, Validation Loss:1.9371, Validation Accuracy:0.4095
Epoch #86: Loss:1.3482, Accuracy:0.5581, Validation Loss:1.9325, Validation Accuracy:0.4070
Epoch #87: Loss:1.3317, Accuracy:0.5575, Validation Loss:1.9331, Validation Accuracy:0.4146
Epoch #88: Loss:1.3152, Accuracy:0.5745, Validation Loss:2.0193, Validation Accuracy:0.3819
Epoch #89: Loss:1.3558, Accuracy:0.5619, Validation Loss:1.9800, Validation Accuracy:0.4070
Epoch #90: Loss:1.3365, Accuracy:0.5669, Validation Loss:1.9613, Validation Accuracy:0.4045
Epoch #91: Loss:1.3027, Accuracy:0.5764, Validation Loss:1.9328, Validation Accuracy:0.4146
Epoch #92: Loss:1.3009, Accuracy:0.5682, Validation Loss:1.9869, Validation Accuracy:0.4121
Epoch #93: Loss:1.2862, Accuracy:0.5908, Validation Loss:1.9359, Validation Accuracy:0.4020
Epoch #94: Loss:1.2799, Accuracy:0.5783, Validation Loss:1.9447, Validation Accuracy:0.4296
Epoch #95: Loss:1.2662, Accuracy:0.5858, Validation Loss:1.9601, Validation Accuracy:0.4095
Epoch #96: Loss:1.2697, Accuracy:0.5839, Validation Loss:1.9864, Validation Accuracy:0.4171
Epoch #97: Loss:1.2500, Accuracy:0.5927, Validation Loss:1.9747, Validation Accuracy:0.4121
Epoch #98: Loss:1.2525, Accuracy:0.5940, Validation Loss:1.9798, Validation Accuracy:0.4146
Epoch #99: Loss:1.2459, Accuracy:0.5915, Validation Loss:1.9795, Validation Accuracy:0.4020
Epoch #100: Loss:1.2430, Accuracy:0.5984, Validation Loss:1.9723, Validation Accuracy:0.4171
Epoch #101: Loss:1.2349, Accuracy:0.6034, Validation Loss:1.9697, Validation Accuracy:0.4146
Epoch #102: Loss:1.2353, Accuracy:0.5965, Validation Loss:2.0179, Validation Accuracy:0.4070
Epoch #103: Loss:1.2240, Accuracy:0.6015, Validation Loss:1.9682, Validation Accuracy:0.4146
Epoch #104: Loss:1.2355, Accuracy:0.5921, Validation Loss:2.0191, Validation Accuracy:0.4070
Epoch #105: Loss:1.2415, Accuracy:0.5946, Validation Loss:1.9797, Validation Accuracy:0.4095
Epoch #106: Loss:1.2315, Accuracy:0.5908, Validation Loss:1.9827, Validation Accuracy:0.4146
Epoch #107: Loss:1.2250, Accuracy:0.5921, Validation Loss:1.9768, Validation Accuracy:0.4146
Epoch #108: Loss:1.2303, Accuracy:0.6003, Validation Loss:2.0049, Validation Accuracy:0.4070
Epoch #109: Loss:1.2084, Accuracy:0.6097, Validation Loss:1.9868, Validation Accuracy:0.4146
Epoch #110: Loss:1.2267, Accuracy:0.6103, Validation Loss:1.9924, Validation Accuracy:0.3970
Epoch #111: Loss:1.2029, Accuracy:0.6116, Validation Loss:2.0028, Validation Accuracy:0.4121
Epoch #112: Loss:1.2020, Accuracy:0.6109, Validation Loss:1.9928, Validation Accuracy:0.4095
Epoch #113: Loss:1.1907, Accuracy:0.6166, Validation Loss:1.9934, Validation Accuracy:0.4121
Epoch #114: Loss:1.1853, Accuracy:0.6166, Validation Loss:1.9773, Validation Accuracy:0.4121
Epoch #115: Loss:1.1897, Accuracy:0.6072, Validation Loss:2.0008, Validation Accuracy:0.4020
Epoch #116: Loss:1.1750, Accuracy:0.6216, Validation Loss:1.9875, Validation Accuracy:0.4095
Epoch #117: Loss:1.1808, Accuracy:0.6323, Validation Loss:1.9960, Validation Accuracy:0.4095
Epoch #118: Loss:1.1677, Accuracy:0.6141, Validation Loss:2.0032, Validation Accuracy:0.4121
Epoch #119: Loss:1.1840, Accuracy:0.6147, Validation Loss:1.9987, Validation Accuracy:0.4121
Epoch #120: Loss:1.1939, Accuracy:0.6204, Validation Loss:1.9952, Validation Accuracy:0.4045
Epoch #121: Loss:1.1767, Accuracy:0.6204, Validation Loss:1.9761, Validation Accuracy:0.4196
Epoch #122: Loss:1.1950, Accuracy:0.6091, Validation Loss:1.9780, Validation Accuracy:0.3970
Epoch #123: Loss:1.1823, Accuracy:0.6128, Validation Loss:1.9979, Validation Accuracy:0.3945
Epoch #124: Loss:1.1733, Accuracy:0.6109, Validation Loss:1.9987, Validation Accuracy:0.4121
Epoch #125: Loss:1.1726, Accuracy:0.6109, Validation Loss:1.9953, Validation Accuracy:0.4221
Epoch #126: Loss:1.1662, Accuracy:0.6323, Validation Loss:1.9908, Validation Accuracy:0.4171
Epoch #127: Loss:1.1792, Accuracy:0.6197, Validation Loss:1.9962, Validation Accuracy:0.4095

Restoring best model...
Test:
Test Loss:1.90274632, Accuracy:0.4171
Labels: ['ib', 'eg', 'yd', 'aa', 'my', 'kk', 'sg', 'sd', 'ck', 'eb', 'by', 'ce', 'am', 'eo', 'mb', 'ig', 'ek', 'sk', 'ds', 'ab']
Confusion Matrix:
      ib  eg  yd  aa  my  kk  sg  sd  ck  eb  by  ce  am  eo  mb  ig  ek  sk  ds  ab
t:ib   8   2   0   0   0   0   2   0   1   0   1   2   0   2   1   0   0   0   0   1
t:eg   1   8   0   3   0   0   0   0   0   1   0   1   3   0   0   0   1   1   1   0
t:yd   0   0   6   1   0   1   4   3   0   0   0   0   0   0   1   2   0   0   0   2
t:aa   0   0   0   6   2   0   0   0   2   0   0   0   5   0   1   1   1   2   0   0
t:my   0   0   0   0   3   0   0   0   1   2   0   0   0   0   2   0   2   4   4   0
t:kk   1   0   0   0   0   8   1   0   0   1   0   0   0   0   0   0   4   0   2   3
t:sg   1   1   3   0   0   1  10   0   0   0   0   0   1   0   2   1   0   0   0   0
t:sd   0   0   0   1   1   1   3  10   0   1   0   0   0   0   0   2   0   0   0   1
t:ck   0   0   0   1   1   0   0   0   5   2   0   0   1   0   5   0   0   0   5   0
t:eb   0   0   0   0   0   2   0   0   0  16   0   0   1   0   0   0   0   0   1   0
t:by   0   1   1   0   0   0   4   0   0   0  11   0   1   2   0   0   0   0   0   0
t:ce   1   3   0   0   0   0   0   1   5   1   1   6   0   0   2   0   0   0   0   0
t:am   0   0   0   0   0   1   0   0   0   0   0   0  12   0   2   0   5   0   0   0
t:eo   2   0   0   0   0   0   0   0   0   0   2   0   0  16   0   0   0   0   0   0
t:mb   0   0   0   1   0   0   0   0   1   0   0   0   0   0   8   0   0   2   2   6
t:ig   0   0   2   1   0   1   2   3   0   0   0   0   2   0   1   7   0   0   0   1
t:ek   0   0   0   1   0   1   0   0   0   1   0   0   2   0   0   0   8   2   1   4
t:sk   0   2   0   0   1   1   0   0   4   1   0   0   2   0   3   0   0   5   1   0
t:ds   0   0   0   0   1   0   0   0   2   3   0   0   1   0   0   0   4   1   8   0
t:ab   0   0   1   0   2   1   0   1   0   0   0   0   0   0   4   0   4   2   0   5
Classification Report:
              precision    recall  f1-score   support

          ib       0.57      0.40      0.47        20
          eg       0.47      0.40      0.43        20
          yd       0.46      0.30      0.36        20
          aa       0.40      0.30      0.34        20
          my       0.27      0.17      0.21        18
          kk       0.44      0.40      0.42        20
          sg       0.38      0.50      0.43        20
          sd       0.56      0.50      0.53        20
          ck       0.24      0.25      0.24        20
          eb       0.55      0.80      0.65        20
          by       0.73      0.55      0.63        20
          ce       0.67      0.30      0.41        20
          am       0.39      0.60      0.47        20
          eo       0.80      0.80      0.80        20
          mb       0.25      0.40      0.31        20
          ig       0.54      0.35      0.42        20
          ek       0.28      0.40      0.33        20
          sk       0.26      0.25      0.26        20
          ds       0.32      0.40      0.36        20
          ab       0.22      0.25      0.23        20

   micro avg       0.42      0.42      0.42       398
   macro avg       0.44      0.42      0.42       398
weighted avg       0.44      0.42      0.42       398

============ Config: 1/1 === End Time: 2019.11.05 03:53:41 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 13 minutes, 2 seconds =====================

Ending script after plotting results...

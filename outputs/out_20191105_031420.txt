======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: D:\atili\MMIExt\Python Projects\Thesis02wDL\confFiles\conf13.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.11.05 03:14:20 =======================================
Parameters: inputFolder : D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
sampRate : 48
featureMode : Mags
channelMode : 0
classificationMode : Speaker
trainingEpoch : 400
stepSize : 0
batchSize : 32
lengthCut : 600
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
clsVersion : 4
Loading from Previous Data Files...
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_inputs_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labels_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labelDict_Mags_0_Speaker_0_48_600_True.dat
Inputs Shape: (1989, 28800, 9)

Total of 1989 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
Total of 20 classes
1591 steps for training, 398 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (1591, 28800, 9)
Test Batch: (398, 28800, 9)
Classifier Version: 4
Model Layer Parameters:
Name: conv1d_1, Filters: 16, Kernel Size: (96,), Strides: (12,), Activation: linear.
Name: dropout_1, Rate: 0.5.
Name: conv1d_2, Filters: 32, Kernel Size: (48,), Strides: (6,), Activation: linear.
Name: dropout_2, Rate: 0.5.
Name: conv1d_3, Filters: 64, Kernel Size: (24,), Strides: (2,), Activation: linear.
Name: dropout_3, Rate: 0.5.
Name: dropout_4, Rate: 0.5.
Name: dropout_5, Rate: 0.5.
Optimizer: <keras.optimizers.Adam object at 0x000002081C2504A8>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000002073DE139D8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 2393, 16)          13840     
_________________________________________________________________
dropout_1 (Dropout)          (None, 2393, 16)          0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 391, 32)           24608     
_________________________________________________________________
dropout_2 (Dropout)          (None, 391, 32)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 184, 64)           49216     
_________________________________________________________________
dropout_3 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_1 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_4 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_2 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_5 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_3 (CuDNNGRU)       (None, 32)                9408      
_________________________________________________________________
dense_1 (Dense)              (None, 20)                660       
=================================================================
Total params: 147,652
Trainable params: 147,652
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.9638, Accuracy:0.0534, Validation Loss:2.9376, Validation Accuracy:0.0729
Epoch #2: Loss:2.9167, Accuracy:0.0729, Validation Loss:2.9149, Validation Accuracy:0.0754
Epoch #3: Loss:2.8967, Accuracy:0.0786, Validation Loss:2.9080, Validation Accuracy:0.0829
Epoch #4: Loss:2.8696, Accuracy:0.0849, Validation Loss:2.8947, Validation Accuracy:0.0804
Epoch #5: Loss:2.8351, Accuracy:0.0823, Validation Loss:2.8974, Validation Accuracy:0.0905
Epoch #6: Loss:2.8217, Accuracy:0.0899, Validation Loss:2.8285, Validation Accuracy:0.1106
Epoch #7: Loss:2.7883, Accuracy:0.0981, Validation Loss:2.8169, Validation Accuracy:0.1156
Epoch #8: Loss:2.7846, Accuracy:0.1131, Validation Loss:2.8478, Validation Accuracy:0.0930
Epoch #9: Loss:2.7760, Accuracy:0.1087, Validation Loss:2.8036, Validation Accuracy:0.1256
Epoch #10: Loss:2.7604, Accuracy:0.1175, Validation Loss:2.7875, Validation Accuracy:0.1231
Epoch #11: Loss:2.7554, Accuracy:0.1043, Validation Loss:2.7914, Validation Accuracy:0.1206
Epoch #12: Loss:2.7375, Accuracy:0.1207, Validation Loss:2.7631, Validation Accuracy:0.1508
Epoch #13: Loss:2.7396, Accuracy:0.1201, Validation Loss:2.7809, Validation Accuracy:0.1080
Epoch #14: Loss:2.7296, Accuracy:0.1175, Validation Loss:2.7581, Validation Accuracy:0.1256
Epoch #15: Loss:2.6991, Accuracy:0.1351, Validation Loss:2.7531, Validation Accuracy:0.1231
Epoch #16: Loss:2.6613, Accuracy:0.1527, Validation Loss:2.6632, Validation Accuracy:0.1734
Epoch #17: Loss:2.5865, Accuracy:0.1728, Validation Loss:2.6575, Validation Accuracy:0.1658
Epoch #18: Loss:2.5629, Accuracy:0.1678, Validation Loss:2.7150, Validation Accuracy:0.1382
Epoch #19: Loss:2.5238, Accuracy:0.1798, Validation Loss:2.5201, Validation Accuracy:0.1759
Epoch #20: Loss:2.4319, Accuracy:0.2074, Validation Loss:2.5273, Validation Accuracy:0.1834
Epoch #21: Loss:2.3971, Accuracy:0.1999, Validation Loss:2.5585, Validation Accuracy:0.1834
Epoch #22: Loss:2.3307, Accuracy:0.2175, Validation Loss:2.4401, Validation Accuracy:0.2060
Epoch #23: Loss:2.2703, Accuracy:0.2464, Validation Loss:2.2808, Validation Accuracy:0.2362
Epoch #24: Loss:2.2399, Accuracy:0.2451, Validation Loss:2.3967, Validation Accuracy:0.2161
Epoch #25: Loss:2.1749, Accuracy:0.2740, Validation Loss:2.3687, Validation Accuracy:0.2513
Epoch #26: Loss:2.1450, Accuracy:0.2935, Validation Loss:2.2762, Validation Accuracy:0.2739
Epoch #27: Loss:2.0775, Accuracy:0.3074, Validation Loss:2.2909, Validation Accuracy:0.2437
Epoch #28: Loss:2.0917, Accuracy:0.3017, Validation Loss:2.1512, Validation Accuracy:0.3090
Epoch #29: Loss:2.0153, Accuracy:0.3262, Validation Loss:2.2380, Validation Accuracy:0.2739
Epoch #30: Loss:2.0193, Accuracy:0.3325, Validation Loss:2.1454, Validation Accuracy:0.3241
Epoch #31: Loss:2.0040, Accuracy:0.3149, Validation Loss:2.1113, Validation Accuracy:0.3116
Epoch #32: Loss:1.9924, Accuracy:0.3407, Validation Loss:2.1827, Validation Accuracy:0.3015
Epoch #33: Loss:1.9693, Accuracy:0.3495, Validation Loss:2.0724, Validation Accuracy:0.3467
Epoch #34: Loss:1.9264, Accuracy:0.3639, Validation Loss:2.0426, Validation Accuracy:0.3518
Epoch #35: Loss:1.9077, Accuracy:0.3708, Validation Loss:2.0955, Validation Accuracy:0.3191
Epoch #36: Loss:1.9185, Accuracy:0.3526, Validation Loss:2.0512, Validation Accuracy:0.3643
Epoch #37: Loss:1.8868, Accuracy:0.3765, Validation Loss:1.9847, Validation Accuracy:0.3543
Epoch #38: Loss:1.8633, Accuracy:0.3960, Validation Loss:1.9876, Validation Accuracy:0.3769
Epoch #39: Loss:1.8263, Accuracy:0.3960, Validation Loss:2.0769, Validation Accuracy:0.3568
Epoch #40: Loss:1.8154, Accuracy:0.4016, Validation Loss:1.9890, Validation Accuracy:0.3668
Epoch #41: Loss:1.8155, Accuracy:0.4041, Validation Loss:1.9978, Validation Accuracy:0.3744
Epoch #42: Loss:1.7829, Accuracy:0.3991, Validation Loss:2.0430, Validation Accuracy:0.3618
Epoch #43: Loss:1.7575, Accuracy:0.4092, Validation Loss:1.9865, Validation Accuracy:0.3920
Epoch #44: Loss:1.7760, Accuracy:0.4155, Validation Loss:1.9981, Validation Accuracy:0.3819
Epoch #45: Loss:1.7516, Accuracy:0.4111, Validation Loss:1.9580, Validation Accuracy:0.3844
Epoch #46: Loss:1.7246, Accuracy:0.4324, Validation Loss:1.9693, Validation Accuracy:0.3819
Epoch #47: Loss:1.7420, Accuracy:0.4192, Validation Loss:2.0199, Validation Accuracy:0.3693
Epoch #48: Loss:1.7053, Accuracy:0.4261, Validation Loss:2.0080, Validation Accuracy:0.3819
Epoch #49: Loss:1.7078, Accuracy:0.4299, Validation Loss:1.9765, Validation Accuracy:0.3794
Epoch #50: Loss:1.6854, Accuracy:0.4343, Validation Loss:1.9848, Validation Accuracy:0.3894
Epoch #51: Loss:1.6788, Accuracy:0.4331, Validation Loss:1.8865, Validation Accuracy:0.4095
Epoch #52: Loss:1.6745, Accuracy:0.4507, Validation Loss:1.9524, Validation Accuracy:0.4045
Epoch #53: Loss:1.6582, Accuracy:0.4475, Validation Loss:1.9118, Validation Accuracy:0.4070
Epoch #54: Loss:1.6128, Accuracy:0.4651, Validation Loss:1.9585, Validation Accuracy:0.3819
Epoch #55: Loss:1.6219, Accuracy:0.4551, Validation Loss:1.8943, Validation Accuracy:0.4171
Epoch #56: Loss:1.6119, Accuracy:0.4626, Validation Loss:1.9516, Validation Accuracy:0.4045
Epoch #57: Loss:1.5684, Accuracy:0.4739, Validation Loss:1.9972, Validation Accuracy:0.3794
Epoch #58: Loss:1.6084, Accuracy:0.4569, Validation Loss:2.0409, Validation Accuracy:0.3869
Epoch #59: Loss:1.5587, Accuracy:0.4708, Validation Loss:2.0116, Validation Accuracy:0.4070
Epoch #60: Loss:1.5767, Accuracy:0.4745, Validation Loss:2.0017, Validation Accuracy:0.4121
Epoch #61: Loss:1.5183, Accuracy:0.4852, Validation Loss:1.8644, Validation Accuracy:0.4095
Epoch #62: Loss:1.5094, Accuracy:0.4815, Validation Loss:1.9185, Validation Accuracy:0.4045
Epoch #63: Loss:1.5241, Accuracy:0.4884, Validation Loss:1.8196, Validation Accuracy:0.4246
Epoch #64: Loss:1.4724, Accuracy:0.5072, Validation Loss:1.9283, Validation Accuracy:0.4246
Epoch #65: Loss:1.5300, Accuracy:0.4865, Validation Loss:1.9225, Validation Accuracy:0.4322
Epoch #66: Loss:1.4995, Accuracy:0.4915, Validation Loss:1.9040, Validation Accuracy:0.4146
Epoch #67: Loss:1.4932, Accuracy:0.4965, Validation Loss:1.9038, Validation Accuracy:0.4146
Epoch #68: Loss:1.4564, Accuracy:0.5135, Validation Loss:1.9060, Validation Accuracy:0.3945
Epoch #69: Loss:1.4264, Accuracy:0.5173, Validation Loss:1.8392, Validation Accuracy:0.4020
Epoch #70: Loss:1.4262, Accuracy:0.5148, Validation Loss:1.8888, Validation Accuracy:0.4095
Epoch #71: Loss:1.4045, Accuracy:0.5311, Validation Loss:1.9544, Validation Accuracy:0.3769
Epoch #72: Loss:1.3982, Accuracy:0.5248, Validation Loss:1.8370, Validation Accuracy:0.4271
Epoch #73: Loss:1.3785, Accuracy:0.5280, Validation Loss:1.8605, Validation Accuracy:0.4171
Epoch #74: Loss:1.3335, Accuracy:0.5456, Validation Loss:1.8901, Validation Accuracy:0.4322
Epoch #75: Loss:1.2989, Accuracy:0.5726, Validation Loss:1.9502, Validation Accuracy:0.4246
Epoch #76: Loss:1.3043, Accuracy:0.5607, Validation Loss:1.8926, Validation Accuracy:0.4447
Epoch #77: Loss:1.2841, Accuracy:0.5751, Validation Loss:1.9050, Validation Accuracy:0.4146
Epoch #78: Loss:1.2681, Accuracy:0.5864, Validation Loss:1.8552, Validation Accuracy:0.4447
Epoch #79: Loss:1.2562, Accuracy:0.5902, Validation Loss:1.8793, Validation Accuracy:0.4422
Epoch #80: Loss:1.2466, Accuracy:0.5940, Validation Loss:1.9142, Validation Accuracy:0.4221
Epoch #81: Loss:1.2587, Accuracy:0.5864, Validation Loss:1.8522, Validation Accuracy:0.4296
Epoch #82: Loss:1.2330, Accuracy:0.5833, Validation Loss:1.9021, Validation Accuracy:0.4472
Epoch #83: Loss:1.2306, Accuracy:0.5933, Validation Loss:1.9155, Validation Accuracy:0.4146
Epoch #84: Loss:1.2189, Accuracy:0.6116, Validation Loss:1.9019, Validation Accuracy:0.4146
Epoch #85: Loss:1.1846, Accuracy:0.6103, Validation Loss:1.9101, Validation Accuracy:0.4246
Epoch #86: Loss:1.1917, Accuracy:0.6166, Validation Loss:1.8791, Validation Accuracy:0.4347
Epoch #87: Loss:1.1831, Accuracy:0.6009, Validation Loss:1.9278, Validation Accuracy:0.4347
Epoch #88: Loss:1.1937, Accuracy:0.6160, Validation Loss:1.8790, Validation Accuracy:0.4447
Epoch #89: Loss:1.1660, Accuracy:0.6128, Validation Loss:1.9826, Validation Accuracy:0.4146
Epoch #90: Loss:1.1666, Accuracy:0.6248, Validation Loss:1.9280, Validation Accuracy:0.4623
Epoch #91: Loss:1.1826, Accuracy:0.6072, Validation Loss:1.8883, Validation Accuracy:0.4422
Epoch #92: Loss:1.1281, Accuracy:0.6292, Validation Loss:1.8798, Validation Accuracy:0.4497
Epoch #93: Loss:1.1341, Accuracy:0.6266, Validation Loss:1.9405, Validation Accuracy:0.4497
Epoch #94: Loss:1.0872, Accuracy:0.6512, Validation Loss:1.8975, Validation Accuracy:0.4548
Epoch #95: Loss:1.0928, Accuracy:0.6530, Validation Loss:1.8968, Validation Accuracy:0.4598
Epoch #96: Loss:1.0836, Accuracy:0.6461, Validation Loss:1.9441, Validation Accuracy:0.4422
Epoch #97: Loss:1.0739, Accuracy:0.6424, Validation Loss:1.9161, Validation Accuracy:0.4422
Epoch #98: Loss:1.0773, Accuracy:0.6512, Validation Loss:1.9327, Validation Accuracy:0.4422
Epoch #99: Loss:1.0755, Accuracy:0.6430, Validation Loss:1.9405, Validation Accuracy:0.4472
Epoch #100: Loss:1.0715, Accuracy:0.6493, Validation Loss:1.9032, Validation Accuracy:0.4422
Epoch #101: Loss:1.0634, Accuracy:0.6631, Validation Loss:1.9085, Validation Accuracy:0.4372
Epoch #102: Loss:1.0592, Accuracy:0.6405, Validation Loss:1.9218, Validation Accuracy:0.4296
Epoch #103: Loss:1.0616, Accuracy:0.6436, Validation Loss:1.9047, Validation Accuracy:0.4623
Epoch #104: Loss:1.0407, Accuracy:0.6612, Validation Loss:1.9340, Validation Accuracy:0.4422
Epoch #105: Loss:1.0613, Accuracy:0.6574, Validation Loss:1.9789, Validation Accuracy:0.4322
Epoch #106: Loss:1.0471, Accuracy:0.6524, Validation Loss:1.9275, Validation Accuracy:0.4372
Epoch #107: Loss:1.0496, Accuracy:0.6562, Validation Loss:1.9120, Validation Accuracy:0.4598
Epoch #108: Loss:1.0593, Accuracy:0.6449, Validation Loss:1.9501, Validation Accuracy:0.4422

Restoring best model...
Test:
Test Loss:1.81961918, Accuracy:0.4246
Labels: ['ib', 'eg', 'yd', 'aa', 'my', 'kk', 'sg', 'sd', 'ck', 'eb', 'by', 'ce', 'am', 'eo', 'mb', 'ig', 'ek', 'sk', 'ds', 'ab']
Confusion Matrix:
      ib  eg  yd  aa  my  kk  sg  sd  ck  eb  by  ce  am  eo  mb  ig  ek  sk  ds  ab
t:ib  10   2   0   2   1   0   1   0   0   0   1   0   2   0   0   0   0   1   0   0
t:eg   1   9   0   1   0   0   0   0   0   0   1   2   3   0   0   0   0   2   0   1
t:yd   0   1   1   0   0   1   6   1   0   0   0   0   0   0   1   6   0   0   0   3
t:aa   0   2   0   6   0   2   0   0   0   0   1   0   3   0   0   2   0   2   1   1
t:my   0   0   0   1   4   3   0   0   1   1   0   0   0   0   3   0   0   4   1   0
t:kk   0   0   0   0   0  14   1   0   0   0   0   0   0   0   0   1   2   0   0   2
t:sg   1   0   1   3   0   0  11   0   0   0   1   0   0   0   0   1   0   0   0   2
t:sd   1   1   2   1   0   1   0   7   0   0   0   1   0   0   1   2   0   1   0   2
t:ck   0   0   0   0   2   0   0   0  13   0   0   0   0   0   0   0   0   1   2   2
t:eb   2   0   0   0   0   1   0   0   0  13   0   0   0   0   0   0   0   2   1   1
t:by   0   3   0   0   0   0   5   0   0   0   7   1   0   4   0   0   0   0   0   0
t:ce   2   0   0   0   0   1   2   1   3   0   1   3   0   5   1   1   0   0   0   0
t:am   0   0   0   1   0   3   0   0   0   0   0   0  12   0   0   0   1   2   0   1
t:eo   3   0   0   0   0   0   0   1   0   1   0   0   0  15   0   0   0   0   0   0
t:mb   0   0   0   0   0   1   1   0   1   1   0   2   1   0   9   0   1   0   2   1
t:ig   1   0   1   0   0   0   2   1   0   0   0   0   0   0   0  14   0   0   0   1
t:ek   0   0   0   0   1   2   0   0   0   1   0   0   3   0   0   0   3   5   1   4
t:sk   0   1   0   0   0   3   0   0   3   3   0   0   2   0   0   0   1   6   1   0
t:ds   0   1   0   0   3   1   0   0   2   3   0   0   0   0   0   0   0   4   6   0
t:ab   0   0   0   1   0   3   0   0   0   1   0   0   2   0   3   0   2   2   0   6
Classification Report:
              precision    recall  f1-score   support

          ib       0.48      0.50      0.49        20
          eg       0.45      0.45      0.45        20
          yd       0.20      0.05      0.08        20
          aa       0.38      0.30      0.33        20
          my       0.36      0.22      0.28        18
          kk       0.39      0.70      0.50        20
          sg       0.38      0.55      0.45        20
          sd       0.64      0.35      0.45        20
          ck       0.57      0.65      0.60        20
          eb       0.54      0.65      0.59        20
          by       0.58      0.35      0.44        20
          ce       0.33      0.15      0.21        20
          am       0.43      0.60      0.50        20
          eo       0.62      0.75      0.68        20
          mb       0.50      0.45      0.47        20
          ig       0.52      0.70      0.60        20
          ek       0.30      0.15      0.20        20
          sk       0.19      0.30      0.23        20
          ds       0.40      0.30      0.34        20
          ab       0.22      0.30      0.26        20

   micro avg       0.42      0.42      0.42       398
   macro avg       0.42      0.42      0.41       398
weighted avg       0.42      0.42      0.41       398

============ Config: 1/1 === End Time: 2019.11.05 03:26:48 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 12 minutes, 27 seconds =====================

Ending script after plotting results...

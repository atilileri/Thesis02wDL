======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf44.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.24 06:13:03 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nFreqs', 'channelMode': '1Ov', 'classificationMode': 'Posture', 'trainingEpoch': 300, 'stepSize': 6, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 5 Label(s): ['03', '01', '04', '02', '05'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 5 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for nFreqs------
---LSTM Classifier---
Train Batch: (2436, 7989, 36)
Test Batch: (610, 7989, 36)
Optimizer: <keras.optimizers.Adam object at 0x000002BC80CF29B0>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000002BCE7256AE8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 65        
=================================================================
Total params: 22,697
Trainable params: 22,697
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.6121, Accuracy:0.1851 Validation Loss:1.6075, Validation Accuracy:0.2328
Epoch #2: Loss:1.6067, Accuracy:0.2332 Validation Loss:1.6060, Validation Accuracy:0.2328
Epoch #3: Loss:1.6060, Accuracy:0.2332 Validation Loss:1.6061, Validation Accuracy:0.2328
Epoch #4: Loss:1.6065, Accuracy:0.2332 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #5: Loss:1.6066, Accuracy:0.2332 Validation Loss:1.6056, Validation Accuracy:0.2328
Epoch #6: Loss:1.6060, Accuracy:0.2332 Validation Loss:1.6053, Validation Accuracy:0.2328
Epoch #7: Loss:1.6056, Accuracy:0.2332 Validation Loss:1.6053, Validation Accuracy:0.2328
Epoch #8: Loss:1.6055, Accuracy:0.2332 Validation Loss:1.6051, Validation Accuracy:0.2328
Epoch #9: Loss:1.6054, Accuracy:0.2332 Validation Loss:1.6050, Validation Accuracy:0.2328
Epoch #10: Loss:1.6053, Accuracy:0.2332 Validation Loss:1.6050, Validation Accuracy:0.2328
Epoch #11: Loss:1.6051, Accuracy:0.2332 Validation Loss:1.6049, Validation Accuracy:0.2328
Epoch #12: Loss:1.6048, Accuracy:0.2332 Validation Loss:1.6048, Validation Accuracy:0.2328
Epoch #13: Loss:1.6047, Accuracy:0.2332 Validation Loss:1.6048, Validation Accuracy:0.2328
Epoch #14: Loss:1.6044, Accuracy:0.2332 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #15: Loss:1.6041, Accuracy:0.2332 Validation Loss:1.6046, Validation Accuracy:0.2328
Epoch #16: Loss:1.6044, Accuracy:0.2332 Validation Loss:1.6050, Validation Accuracy:0.2328
Epoch #17: Loss:1.6038, Accuracy:0.2332 Validation Loss:1.6049, Validation Accuracy:0.2328
Epoch #18: Loss:1.6034, Accuracy:0.2332 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #19: Loss:1.6033, Accuracy:0.2332 Validation Loss:1.6048, Validation Accuracy:0.2328
Epoch #20: Loss:1.6031, Accuracy:0.2332 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #21: Loss:1.6032, Accuracy:0.2299 Validation Loss:1.6051, Validation Accuracy:0.2262
Epoch #22: Loss:1.6027, Accuracy:0.2393 Validation Loss:1.6056, Validation Accuracy:0.2443
Epoch #23: Loss:1.6029, Accuracy:0.2369 Validation Loss:1.6049, Validation Accuracy:0.2295
Epoch #24: Loss:1.6030, Accuracy:0.2344 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #25: Loss:1.6032, Accuracy:0.2369 Validation Loss:1.6045, Validation Accuracy:0.2246
Epoch #26: Loss:1.6022, Accuracy:0.2443 Validation Loss:1.6040, Validation Accuracy:0.2279
Epoch #27: Loss:1.6021, Accuracy:0.2443 Validation Loss:1.6041, Validation Accuracy:0.2328
Epoch #28: Loss:1.6019, Accuracy:0.2434 Validation Loss:1.6035, Validation Accuracy:0.2295
Epoch #29: Loss:1.6011, Accuracy:0.2438 Validation Loss:1.6035, Validation Accuracy:0.2295
Epoch #30: Loss:1.6010, Accuracy:0.2434 Validation Loss:1.6036, Validation Accuracy:0.2279
Epoch #31: Loss:1.6009, Accuracy:0.2397 Validation Loss:1.6041, Validation Accuracy:0.2213
Epoch #32: Loss:1.6011, Accuracy:0.2434 Validation Loss:1.6044, Validation Accuracy:0.2262
Epoch #33: Loss:1.6010, Accuracy:0.2410 Validation Loss:1.6039, Validation Accuracy:0.2230
Epoch #34: Loss:1.6007, Accuracy:0.2414 Validation Loss:1.6045, Validation Accuracy:0.2246
Epoch #35: Loss:1.6007, Accuracy:0.2463 Validation Loss:1.6038, Validation Accuracy:0.2230
Epoch #36: Loss:1.6000, Accuracy:0.2451 Validation Loss:1.6030, Validation Accuracy:0.2262
Epoch #37: Loss:1.6001, Accuracy:0.2397 Validation Loss:1.6037, Validation Accuracy:0.2262
Epoch #38: Loss:1.6000, Accuracy:0.2430 Validation Loss:1.6033, Validation Accuracy:0.2213
Epoch #39: Loss:1.5997, Accuracy:0.2455 Validation Loss:1.6030, Validation Accuracy:0.2246
Epoch #40: Loss:1.5998, Accuracy:0.2438 Validation Loss:1.6030, Validation Accuracy:0.2262
Epoch #41: Loss:1.5999, Accuracy:0.2389 Validation Loss:1.6030, Validation Accuracy:0.2213
Epoch #42: Loss:1.5993, Accuracy:0.2443 Validation Loss:1.6029, Validation Accuracy:0.2197
Epoch #43: Loss:1.5997, Accuracy:0.2443 Validation Loss:1.6030, Validation Accuracy:0.2213
Epoch #44: Loss:1.6000, Accuracy:0.2443 Validation Loss:1.6032, Validation Accuracy:0.2279
Epoch #45: Loss:1.5995, Accuracy:0.2434 Validation Loss:1.6033, Validation Accuracy:0.2279
Epoch #46: Loss:1.6000, Accuracy:0.2438 Validation Loss:1.6037, Validation Accuracy:0.2279
Epoch #47: Loss:1.5999, Accuracy:0.2447 Validation Loss:1.6032, Validation Accuracy:0.2197
Epoch #48: Loss:1.6000, Accuracy:0.2467 Validation Loss:1.6025, Validation Accuracy:0.2262
Epoch #49: Loss:1.6000, Accuracy:0.2430 Validation Loss:1.6028, Validation Accuracy:0.2262
Epoch #50: Loss:1.5996, Accuracy:0.2410 Validation Loss:1.6024, Validation Accuracy:0.2279
Epoch #51: Loss:1.5994, Accuracy:0.2447 Validation Loss:1.6026, Validation Accuracy:0.2279
Epoch #52: Loss:1.5997, Accuracy:0.2463 Validation Loss:1.6027, Validation Accuracy:0.2246
Epoch #53: Loss:1.5994, Accuracy:0.2455 Validation Loss:1.6029, Validation Accuracy:0.2279
Epoch #54: Loss:1.5994, Accuracy:0.2459 Validation Loss:1.6030, Validation Accuracy:0.2295
Epoch #55: Loss:1.5994, Accuracy:0.2459 Validation Loss:1.6027, Validation Accuracy:0.2230
Epoch #56: Loss:1.5988, Accuracy:0.2479 Validation Loss:1.6025, Validation Accuracy:0.2230
Epoch #57: Loss:1.5990, Accuracy:0.2406 Validation Loss:1.6014, Validation Accuracy:0.2311
Epoch #58: Loss:1.6008, Accuracy:0.2381 Validation Loss:1.6033, Validation Accuracy:0.2180
Epoch #59: Loss:1.6002, Accuracy:0.2401 Validation Loss:1.6044, Validation Accuracy:0.2197
Epoch #60: Loss:1.5997, Accuracy:0.2422 Validation Loss:1.6026, Validation Accuracy:0.2246
Epoch #61: Loss:1.5989, Accuracy:0.2471 Validation Loss:1.6029, Validation Accuracy:0.2246
Epoch #62: Loss:1.5987, Accuracy:0.2479 Validation Loss:1.6038, Validation Accuracy:0.2197
Epoch #63: Loss:1.5994, Accuracy:0.2434 Validation Loss:1.6038, Validation Accuracy:0.2262
Epoch #64: Loss:1.6003, Accuracy:0.2438 Validation Loss:1.6033, Validation Accuracy:0.2246
Epoch #65: Loss:1.6007, Accuracy:0.2451 Validation Loss:1.6027, Validation Accuracy:0.2262
Epoch #66: Loss:1.5998, Accuracy:0.2492 Validation Loss:1.6035, Validation Accuracy:0.2180
Epoch #67: Loss:1.6052, Accuracy:0.2303 Validation Loss:1.6071, Validation Accuracy:0.2016
Epoch #68: Loss:1.5999, Accuracy:0.2410 Validation Loss:1.6034, Validation Accuracy:0.2311
Epoch #69: Loss:1.6015, Accuracy:0.2397 Validation Loss:1.6038, Validation Accuracy:0.2344
Epoch #70: Loss:1.6011, Accuracy:0.2418 Validation Loss:1.6019, Validation Accuracy:0.2311
Epoch #71: Loss:1.5993, Accuracy:0.2422 Validation Loss:1.6046, Validation Accuracy:0.2328
Epoch #72: Loss:1.6011, Accuracy:0.2397 Validation Loss:1.6059, Validation Accuracy:0.2098
Epoch #73: Loss:1.6031, Accuracy:0.2377 Validation Loss:1.6039, Validation Accuracy:0.2246
Epoch #74: Loss:1.6028, Accuracy:0.2393 Validation Loss:1.6016, Validation Accuracy:0.2311
Epoch #75: Loss:1.6016, Accuracy:0.2393 Validation Loss:1.6011, Validation Accuracy:0.2311
Epoch #76: Loss:1.6012, Accuracy:0.2410 Validation Loss:1.6012, Validation Accuracy:0.2361
Epoch #77: Loss:1.6005, Accuracy:0.2447 Validation Loss:1.6012, Validation Accuracy:0.2344
Epoch #78: Loss:1.6002, Accuracy:0.2459 Validation Loss:1.6014, Validation Accuracy:0.2328
Epoch #79: Loss:1.6004, Accuracy:0.2451 Validation Loss:1.6020, Validation Accuracy:0.2311
Epoch #80: Loss:1.5999, Accuracy:0.2463 Validation Loss:1.6023, Validation Accuracy:0.2279
Epoch #81: Loss:1.5999, Accuracy:0.2467 Validation Loss:1.6027, Validation Accuracy:0.2279
Epoch #82: Loss:1.5998, Accuracy:0.2447 Validation Loss:1.6029, Validation Accuracy:0.2295
Epoch #83: Loss:1.5997, Accuracy:0.2459 Validation Loss:1.6029, Validation Accuracy:0.2279
Epoch #84: Loss:1.5995, Accuracy:0.2467 Validation Loss:1.6026, Validation Accuracy:0.2279
Epoch #85: Loss:1.5994, Accuracy:0.2467 Validation Loss:1.6025, Validation Accuracy:0.2311
Epoch #86: Loss:1.5993, Accuracy:0.2467 Validation Loss:1.6031, Validation Accuracy:0.2295
Epoch #87: Loss:1.5991, Accuracy:0.2455 Validation Loss:1.6033, Validation Accuracy:0.2295
Epoch #88: Loss:1.5990, Accuracy:0.2459 Validation Loss:1.6031, Validation Accuracy:0.2295
Epoch #89: Loss:1.5990, Accuracy:0.2463 Validation Loss:1.6032, Validation Accuracy:0.2295
Epoch #90: Loss:1.5989, Accuracy:0.2459 Validation Loss:1.6035, Validation Accuracy:0.2295
Epoch #91: Loss:1.5988, Accuracy:0.2471 Validation Loss:1.6034, Validation Accuracy:0.2295
Epoch #92: Loss:1.5986, Accuracy:0.2463 Validation Loss:1.6034, Validation Accuracy:0.2295
Epoch #93: Loss:1.5986, Accuracy:0.2463 Validation Loss:1.6034, Validation Accuracy:0.2295
Epoch #94: Loss:1.5986, Accuracy:0.2467 Validation Loss:1.6036, Validation Accuracy:0.2295
Epoch #95: Loss:1.5984, Accuracy:0.2467 Validation Loss:1.6035, Validation Accuracy:0.2295
Epoch #96: Loss:1.5984, Accuracy:0.2455 Validation Loss:1.6037, Validation Accuracy:0.2262
Epoch #97: Loss:1.5988, Accuracy:0.2471 Validation Loss:1.6039, Validation Accuracy:0.2279
Epoch #98: Loss:1.5986, Accuracy:0.2459 Validation Loss:1.6037, Validation Accuracy:0.2279
Epoch #99: Loss:1.5984, Accuracy:0.2488 Validation Loss:1.6036, Validation Accuracy:0.2295
Epoch #100: Loss:1.5982, Accuracy:0.2467 Validation Loss:1.6036, Validation Accuracy:0.2311
Epoch #101: Loss:1.5982, Accuracy:0.2467 Validation Loss:1.6038, Validation Accuracy:0.2311
Epoch #102: Loss:1.5982, Accuracy:0.2479 Validation Loss:1.6032, Validation Accuracy:0.2295
Epoch #103: Loss:1.5981, Accuracy:0.2484 Validation Loss:1.6033, Validation Accuracy:0.2295
Epoch #104: Loss:1.5979, Accuracy:0.2484 Validation Loss:1.6036, Validation Accuracy:0.2311
Epoch #105: Loss:1.5978, Accuracy:0.2475 Validation Loss:1.6037, Validation Accuracy:0.2311
Epoch #106: Loss:1.5982, Accuracy:0.2434 Validation Loss:1.6041, Validation Accuracy:0.2246
Epoch #107: Loss:1.5977, Accuracy:0.2459 Validation Loss:1.6037, Validation Accuracy:0.2311
Epoch #108: Loss:1.5979, Accuracy:0.2484 Validation Loss:1.6032, Validation Accuracy:0.2311
Epoch #109: Loss:1.5978, Accuracy:0.2488 Validation Loss:1.6034, Validation Accuracy:0.2295
Epoch #110: Loss:1.5978, Accuracy:0.2451 Validation Loss:1.6041, Validation Accuracy:0.2246
Epoch #111: Loss:1.5977, Accuracy:0.2451 Validation Loss:1.6041, Validation Accuracy:0.2311
Epoch #112: Loss:1.5975, Accuracy:0.2471 Validation Loss:1.6037, Validation Accuracy:0.2279
Epoch #113: Loss:1.5973, Accuracy:0.2484 Validation Loss:1.6035, Validation Accuracy:0.2295
Epoch #114: Loss:1.5976, Accuracy:0.2467 Validation Loss:1.6044, Validation Accuracy:0.2279
Epoch #115: Loss:1.5974, Accuracy:0.2475 Validation Loss:1.6046, Validation Accuracy:0.2262
Epoch #116: Loss:1.5975, Accuracy:0.2479 Validation Loss:1.6046, Validation Accuracy:0.2262
Epoch #117: Loss:1.5979, Accuracy:0.2451 Validation Loss:1.6050, Validation Accuracy:0.2262
Epoch #118: Loss:1.5977, Accuracy:0.2475 Validation Loss:1.6043, Validation Accuracy:0.2279
Epoch #119: Loss:1.5980, Accuracy:0.2467 Validation Loss:1.6041, Validation Accuracy:0.2279
Epoch #120: Loss:1.5982, Accuracy:0.2430 Validation Loss:1.6049, Validation Accuracy:0.2180
Epoch #121: Loss:1.5983, Accuracy:0.2443 Validation Loss:1.6043, Validation Accuracy:0.2246
Epoch #122: Loss:1.5982, Accuracy:0.2422 Validation Loss:1.6046, Validation Accuracy:0.2295
Epoch #123: Loss:1.5985, Accuracy:0.2418 Validation Loss:1.6051, Validation Accuracy:0.2180
Epoch #124: Loss:1.5976, Accuracy:0.2414 Validation Loss:1.6047, Validation Accuracy:0.2279
Epoch #125: Loss:1.5984, Accuracy:0.2426 Validation Loss:1.6043, Validation Accuracy:0.2230
Epoch #126: Loss:1.5990, Accuracy:0.2430 Validation Loss:1.6055, Validation Accuracy:0.2328
Epoch #127: Loss:1.6053, Accuracy:0.2352 Validation Loss:1.6027, Validation Accuracy:0.2262
Epoch #128: Loss:1.6014, Accuracy:0.2381 Validation Loss:1.6070, Validation Accuracy:0.2295
Epoch #129: Loss:1.6019, Accuracy:0.2303 Validation Loss:1.6036, Validation Accuracy:0.2180
Epoch #130: Loss:1.5995, Accuracy:0.2418 Validation Loss:1.6035, Validation Accuracy:0.2230
Epoch #131: Loss:1.5992, Accuracy:0.2426 Validation Loss:1.6040, Validation Accuracy:0.2230
Epoch #132: Loss:1.5988, Accuracy:0.2406 Validation Loss:1.6045, Validation Accuracy:0.2197
Epoch #133: Loss:1.5989, Accuracy:0.2377 Validation Loss:1.6047, Validation Accuracy:0.2230
Epoch #134: Loss:1.5988, Accuracy:0.2393 Validation Loss:1.6041, Validation Accuracy:0.2230
Epoch #135: Loss:1.5990, Accuracy:0.2426 Validation Loss:1.6044, Validation Accuracy:0.2180
Epoch #136: Loss:1.5989, Accuracy:0.2373 Validation Loss:1.6051, Validation Accuracy:0.2230
Epoch #137: Loss:1.5990, Accuracy:0.2377 Validation Loss:1.6040, Validation Accuracy:0.2230
Epoch #138: Loss:1.5989, Accuracy:0.2426 Validation Loss:1.6042, Validation Accuracy:0.2230
Epoch #139: Loss:1.5992, Accuracy:0.2393 Validation Loss:1.6049, Validation Accuracy:0.2246
Epoch #140: Loss:1.5991, Accuracy:0.2410 Validation Loss:1.6043, Validation Accuracy:0.2230
Epoch #141: Loss:1.5989, Accuracy:0.2418 Validation Loss:1.6050, Validation Accuracy:0.2246
Epoch #142: Loss:1.5988, Accuracy:0.2389 Validation Loss:1.6047, Validation Accuracy:0.2230
Epoch #143: Loss:1.5989, Accuracy:0.2426 Validation Loss:1.6047, Validation Accuracy:0.2230
Epoch #144: Loss:1.5988, Accuracy:0.2418 Validation Loss:1.6054, Validation Accuracy:0.2279
Epoch #145: Loss:1.5986, Accuracy:0.2426 Validation Loss:1.6055, Validation Accuracy:0.2295
Epoch #146: Loss:1.5987, Accuracy:0.2401 Validation Loss:1.6046, Validation Accuracy:0.2230
Epoch #147: Loss:1.5989, Accuracy:0.2426 Validation Loss:1.6039, Validation Accuracy:0.2246
Epoch #148: Loss:1.5987, Accuracy:0.2447 Validation Loss:1.6047, Validation Accuracy:0.2279
Epoch #149: Loss:1.5987, Accuracy:0.2426 Validation Loss:1.6042, Validation Accuracy:0.2279
Epoch #150: Loss:1.5988, Accuracy:0.2443 Validation Loss:1.6040, Validation Accuracy:0.2230
Epoch #151: Loss:1.5989, Accuracy:0.2430 Validation Loss:1.6039, Validation Accuracy:0.2230
Epoch #152: Loss:1.5987, Accuracy:0.2410 Validation Loss:1.6045, Validation Accuracy:0.2279
Epoch #153: Loss:1.5984, Accuracy:0.2430 Validation Loss:1.6042, Validation Accuracy:0.2279
Epoch #154: Loss:1.5983, Accuracy:0.2434 Validation Loss:1.6022, Validation Accuracy:0.2230
Epoch #155: Loss:1.5977, Accuracy:0.2426 Validation Loss:1.6028, Validation Accuracy:0.2262
Epoch #156: Loss:1.5979, Accuracy:0.2422 Validation Loss:1.6031, Validation Accuracy:0.2246
Epoch #157: Loss:1.5978, Accuracy:0.2434 Validation Loss:1.6023, Validation Accuracy:0.2246
Epoch #158: Loss:1.5978, Accuracy:0.2438 Validation Loss:1.6024, Validation Accuracy:0.2311
Epoch #159: Loss:1.5977, Accuracy:0.2426 Validation Loss:1.6027, Validation Accuracy:0.2246
Epoch #160: Loss:1.5977, Accuracy:0.2430 Validation Loss:1.6021, Validation Accuracy:0.2295
Epoch #161: Loss:1.5977, Accuracy:0.2410 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #162: Loss:1.5975, Accuracy:0.2430 Validation Loss:1.6014, Validation Accuracy:0.2246
Epoch #163: Loss:1.5985, Accuracy:0.2438 Validation Loss:1.6014, Validation Accuracy:0.2246
Epoch #164: Loss:1.5979, Accuracy:0.2455 Validation Loss:1.6028, Validation Accuracy:0.2377
Epoch #165: Loss:1.5979, Accuracy:0.2418 Validation Loss:1.6019, Validation Accuracy:0.2262
Epoch #166: Loss:1.5973, Accuracy:0.2401 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #167: Loss:1.5987, Accuracy:0.2447 Validation Loss:1.6014, Validation Accuracy:0.2246
Epoch #168: Loss:1.5973, Accuracy:0.2414 Validation Loss:1.6022, Validation Accuracy:0.2246
Epoch #169: Loss:1.5981, Accuracy:0.2426 Validation Loss:1.6031, Validation Accuracy:0.2262
Epoch #170: Loss:1.5979, Accuracy:0.2443 Validation Loss:1.6017, Validation Accuracy:0.2246
Epoch #171: Loss:1.5975, Accuracy:0.2438 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #172: Loss:1.5976, Accuracy:0.2410 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #173: Loss:1.5976, Accuracy:0.2401 Validation Loss:1.6022, Validation Accuracy:0.2262
Epoch #174: Loss:1.5977, Accuracy:0.2410 Validation Loss:1.6020, Validation Accuracy:0.2246
Epoch #175: Loss:1.5975, Accuracy:0.2430 Validation Loss:1.6021, Validation Accuracy:0.2262
Epoch #176: Loss:1.5974, Accuracy:0.2414 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #177: Loss:1.5977, Accuracy:0.2438 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #178: Loss:1.5976, Accuracy:0.2397 Validation Loss:1.6028, Validation Accuracy:0.2262
Epoch #179: Loss:1.5978, Accuracy:0.2434 Validation Loss:1.6017, Validation Accuracy:0.2197
Epoch #180: Loss:1.5974, Accuracy:0.2434 Validation Loss:1.6016, Validation Accuracy:0.2246
Epoch #181: Loss:1.5974, Accuracy:0.2422 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #182: Loss:1.5972, Accuracy:0.2410 Validation Loss:1.6017, Validation Accuracy:0.2262
Epoch #183: Loss:1.5977, Accuracy:0.2410 Validation Loss:1.6021, Validation Accuracy:0.2279
Epoch #184: Loss:1.5974, Accuracy:0.2430 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #185: Loss:1.5976, Accuracy:0.2438 Validation Loss:1.6017, Validation Accuracy:0.2246
Epoch #186: Loss:1.5975, Accuracy:0.2459 Validation Loss:1.6024, Validation Accuracy:0.2279
Epoch #187: Loss:1.5973, Accuracy:0.2426 Validation Loss:1.6025, Validation Accuracy:0.2377
Epoch #188: Loss:1.5976, Accuracy:0.2414 Validation Loss:1.6022, Validation Accuracy:0.2377
Epoch #189: Loss:1.5971, Accuracy:0.2410 Validation Loss:1.6017, Validation Accuracy:0.2246
Epoch #190: Loss:1.5975, Accuracy:0.2406 Validation Loss:1.6019, Validation Accuracy:0.2279
Epoch #191: Loss:1.5973, Accuracy:0.2414 Validation Loss:1.6018, Validation Accuracy:0.2197
Epoch #192: Loss:1.5972, Accuracy:0.2410 Validation Loss:1.6015, Validation Accuracy:0.2230
Epoch #193: Loss:1.5973, Accuracy:0.2422 Validation Loss:1.6020, Validation Accuracy:0.2393
Epoch #194: Loss:1.5978, Accuracy:0.2430 Validation Loss:1.6019, Validation Accuracy:0.2393
Epoch #195: Loss:1.5972, Accuracy:0.2426 Validation Loss:1.6018, Validation Accuracy:0.2246
Epoch #196: Loss:1.5980, Accuracy:0.2434 Validation Loss:1.6018, Validation Accuracy:0.2230
Epoch #197: Loss:1.5971, Accuracy:0.2377 Validation Loss:1.6019, Validation Accuracy:0.2295
Epoch #198: Loss:1.5972, Accuracy:0.2410 Validation Loss:1.6021, Validation Accuracy:0.2393
Epoch #199: Loss:1.5973, Accuracy:0.2426 Validation Loss:1.6016, Validation Accuracy:0.2410
Epoch #200: Loss:1.5971, Accuracy:0.2389 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #201: Loss:1.5971, Accuracy:0.2479 Validation Loss:1.6014, Validation Accuracy:0.2393
Epoch #202: Loss:1.5971, Accuracy:0.2438 Validation Loss:1.6022, Validation Accuracy:0.2393
Epoch #203: Loss:1.5974, Accuracy:0.2430 Validation Loss:1.6017, Validation Accuracy:0.2393
Epoch #204: Loss:1.5972, Accuracy:0.2414 Validation Loss:1.6014, Validation Accuracy:0.2246
Epoch #205: Loss:1.5974, Accuracy:0.2434 Validation Loss:1.6017, Validation Accuracy:0.2262
Epoch #206: Loss:1.5969, Accuracy:0.2430 Validation Loss:1.6020, Validation Accuracy:0.2410
Epoch #207: Loss:1.5971, Accuracy:0.2426 Validation Loss:1.6021, Validation Accuracy:0.2410
Epoch #208: Loss:1.5973, Accuracy:0.2430 Validation Loss:1.6020, Validation Accuracy:0.2393
Epoch #209: Loss:1.5972, Accuracy:0.2422 Validation Loss:1.6017, Validation Accuracy:0.2361
Epoch #210: Loss:1.5970, Accuracy:0.2410 Validation Loss:1.6015, Validation Accuracy:0.2410
Epoch #211: Loss:1.5970, Accuracy:0.2426 Validation Loss:1.6016, Validation Accuracy:0.2426
Epoch #212: Loss:1.5971, Accuracy:0.2422 Validation Loss:1.6017, Validation Accuracy:0.2393
Epoch #213: Loss:1.5970, Accuracy:0.2422 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #214: Loss:1.5969, Accuracy:0.2418 Validation Loss:1.6018, Validation Accuracy:0.2279
Epoch #215: Loss:1.5974, Accuracy:0.2410 Validation Loss:1.6024, Validation Accuracy:0.2279
Epoch #216: Loss:1.5972, Accuracy:0.2418 Validation Loss:1.6017, Validation Accuracy:0.2246
Epoch #217: Loss:1.5968, Accuracy:0.2443 Validation Loss:1.6017, Validation Accuracy:0.2426
Epoch #218: Loss:1.5974, Accuracy:0.2434 Validation Loss:1.6020, Validation Accuracy:0.2426
Epoch #219: Loss:1.5969, Accuracy:0.2434 Validation Loss:1.6016, Validation Accuracy:0.2426
Epoch #220: Loss:1.5967, Accuracy:0.2389 Validation Loss:1.6018, Validation Accuracy:0.2262
Epoch #221: Loss:1.5973, Accuracy:0.2422 Validation Loss:1.6022, Validation Accuracy:0.2295
Epoch #222: Loss:1.5969, Accuracy:0.2418 Validation Loss:1.6017, Validation Accuracy:0.2410
Epoch #223: Loss:1.5968, Accuracy:0.2443 Validation Loss:1.6018, Validation Accuracy:0.2426
Epoch #224: Loss:1.5973, Accuracy:0.2360 Validation Loss:1.6017, Validation Accuracy:0.2262
Epoch #225: Loss:1.5966, Accuracy:0.2426 Validation Loss:1.6024, Validation Accuracy:0.2410
Epoch #226: Loss:1.5970, Accuracy:0.2443 Validation Loss:1.6023, Validation Accuracy:0.2410
Epoch #227: Loss:1.5969, Accuracy:0.2430 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #228: Loss:1.5972, Accuracy:0.2447 Validation Loss:1.6017, Validation Accuracy:0.2246
Epoch #229: Loss:1.5967, Accuracy:0.2426 Validation Loss:1.6020, Validation Accuracy:0.2410
Epoch #230: Loss:1.5970, Accuracy:0.2430 Validation Loss:1.6017, Validation Accuracy:0.2426
Epoch #231: Loss:1.5966, Accuracy:0.2422 Validation Loss:1.6015, Validation Accuracy:0.2410
Epoch #232: Loss:1.5971, Accuracy:0.2451 Validation Loss:1.6015, Validation Accuracy:0.2262
Epoch #233: Loss:1.5970, Accuracy:0.2426 Validation Loss:1.6019, Validation Accuracy:0.2426
Epoch #234: Loss:1.5971, Accuracy:0.2434 Validation Loss:1.6019, Validation Accuracy:0.2377
Epoch #235: Loss:1.5965, Accuracy:0.2451 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #236: Loss:1.5970, Accuracy:0.2438 Validation Loss:1.6015, Validation Accuracy:0.2246
Epoch #237: Loss:1.5970, Accuracy:0.2451 Validation Loss:1.6019, Validation Accuracy:0.2311
Epoch #238: Loss:1.5969, Accuracy:0.2434 Validation Loss:1.6022, Validation Accuracy:0.2426
Epoch #239: Loss:1.5968, Accuracy:0.2451 Validation Loss:1.6016, Validation Accuracy:0.2377
Epoch #240: Loss:1.5968, Accuracy:0.2430 Validation Loss:1.6015, Validation Accuracy:0.2426
Epoch #241: Loss:1.5966, Accuracy:0.2430 Validation Loss:1.6014, Validation Accuracy:0.2426
Epoch #242: Loss:1.5966, Accuracy:0.2443 Validation Loss:1.6016, Validation Accuracy:0.2295
Epoch #243: Loss:1.5965, Accuracy:0.2414 Validation Loss:1.6014, Validation Accuracy:0.2426
Epoch #244: Loss:1.5965, Accuracy:0.2434 Validation Loss:1.6015, Validation Accuracy:0.2426
Epoch #245: Loss:1.5967, Accuracy:0.2434 Validation Loss:1.6018, Validation Accuracy:0.2426
Epoch #246: Loss:1.5965, Accuracy:0.2434 Validation Loss:1.6015, Validation Accuracy:0.2426
Epoch #247: Loss:1.5964, Accuracy:0.2418 Validation Loss:1.6013, Validation Accuracy:0.2295
Epoch #248: Loss:1.5969, Accuracy:0.2438 Validation Loss:1.6012, Validation Accuracy:0.2410
Epoch #249: Loss:1.5964, Accuracy:0.2418 Validation Loss:1.6016, Validation Accuracy:0.2426
Epoch #250: Loss:1.5966, Accuracy:0.2434 Validation Loss:1.6019, Validation Accuracy:0.2393
Epoch #251: Loss:1.5965, Accuracy:0.2438 Validation Loss:1.6013, Validation Accuracy:0.2393
Epoch #252: Loss:1.5963, Accuracy:0.2422 Validation Loss:1.6011, Validation Accuracy:0.2393
Epoch #253: Loss:1.5963, Accuracy:0.2406 Validation Loss:1.6011, Validation Accuracy:0.2426
Epoch #254: Loss:1.5964, Accuracy:0.2438 Validation Loss:1.6013, Validation Accuracy:0.2443
Epoch #255: Loss:1.5963, Accuracy:0.2455 Validation Loss:1.6011, Validation Accuracy:0.2393
Epoch #256: Loss:1.5965, Accuracy:0.2438 Validation Loss:1.6011, Validation Accuracy:0.2262
Epoch #257: Loss:1.5963, Accuracy:0.2434 Validation Loss:1.6010, Validation Accuracy:0.2459
Epoch #258: Loss:1.5963, Accuracy:0.2443 Validation Loss:1.6012, Validation Accuracy:0.2443
Epoch #259: Loss:1.5964, Accuracy:0.2463 Validation Loss:1.6013, Validation Accuracy:0.2443
Epoch #260: Loss:1.5965, Accuracy:0.2443 Validation Loss:1.6012, Validation Accuracy:0.2459
Epoch #261: Loss:1.5962, Accuracy:0.2455 Validation Loss:1.6013, Validation Accuracy:0.2393
Epoch #262: Loss:1.5963, Accuracy:0.2447 Validation Loss:1.6012, Validation Accuracy:0.2459
Epoch #263: Loss:1.5963, Accuracy:0.2447 Validation Loss:1.6011, Validation Accuracy:0.2459
Epoch #264: Loss:1.5962, Accuracy:0.2479 Validation Loss:1.6010, Validation Accuracy:0.2443
Epoch #265: Loss:1.5963, Accuracy:0.2463 Validation Loss:1.6010, Validation Accuracy:0.2475
Epoch #266: Loss:1.5962, Accuracy:0.2434 Validation Loss:1.6010, Validation Accuracy:0.2426
Epoch #267: Loss:1.5967, Accuracy:0.2467 Validation Loss:1.6018, Validation Accuracy:0.2393
Epoch #268: Loss:1.5962, Accuracy:0.2447 Validation Loss:1.6008, Validation Accuracy:0.2311
Epoch #269: Loss:1.5963, Accuracy:0.2471 Validation Loss:1.6006, Validation Accuracy:0.2410
Epoch #270: Loss:1.5961, Accuracy:0.2484 Validation Loss:1.6008, Validation Accuracy:0.2410
Epoch #271: Loss:1.5962, Accuracy:0.2467 Validation Loss:1.6008, Validation Accuracy:0.2443
Epoch #272: Loss:1.5965, Accuracy:0.2455 Validation Loss:1.6006, Validation Accuracy:0.2393
Epoch #273: Loss:1.5962, Accuracy:0.2447 Validation Loss:1.6012, Validation Accuracy:0.2410
Epoch #274: Loss:1.5962, Accuracy:0.2451 Validation Loss:1.6011, Validation Accuracy:0.2459
Epoch #275: Loss:1.5963, Accuracy:0.2434 Validation Loss:1.6010, Validation Accuracy:0.2426
Epoch #276: Loss:1.5961, Accuracy:0.2447 Validation Loss:1.6009, Validation Accuracy:0.2410
Epoch #277: Loss:1.5966, Accuracy:0.2455 Validation Loss:1.6013, Validation Accuracy:0.2410
Epoch #278: Loss:1.5961, Accuracy:0.2463 Validation Loss:1.6005, Validation Accuracy:0.2475
Epoch #279: Loss:1.5960, Accuracy:0.2488 Validation Loss:1.6003, Validation Accuracy:0.2475
Epoch #280: Loss:1.5960, Accuracy:0.2463 Validation Loss:1.6009, Validation Accuracy:0.2410
Epoch #281: Loss:1.5960, Accuracy:0.2438 Validation Loss:1.6006, Validation Accuracy:0.2459
Epoch #282: Loss:1.5960, Accuracy:0.2443 Validation Loss:1.6003, Validation Accuracy:0.2410
Epoch #283: Loss:1.5964, Accuracy:0.2447 Validation Loss:1.6009, Validation Accuracy:0.2410
Epoch #284: Loss:1.5960, Accuracy:0.2467 Validation Loss:1.6007, Validation Accuracy:0.2475
Epoch #285: Loss:1.5964, Accuracy:0.2451 Validation Loss:1.6003, Validation Accuracy:0.2410
Epoch #286: Loss:1.5960, Accuracy:0.2479 Validation Loss:1.6010, Validation Accuracy:0.2410
Epoch #287: Loss:1.5963, Accuracy:0.2463 Validation Loss:1.6010, Validation Accuracy:0.2410
Epoch #288: Loss:1.5958, Accuracy:0.2467 Validation Loss:1.6007, Validation Accuracy:0.2475
Epoch #289: Loss:1.5959, Accuracy:0.2463 Validation Loss:1.6005, Validation Accuracy:0.2393
Epoch #290: Loss:1.5961, Accuracy:0.2467 Validation Loss:1.6007, Validation Accuracy:0.2410
Epoch #291: Loss:1.5957, Accuracy:0.2475 Validation Loss:1.6001, Validation Accuracy:0.2443
Epoch #292: Loss:1.5956, Accuracy:0.2488 Validation Loss:1.6001, Validation Accuracy:0.2410
Epoch #293: Loss:1.5957, Accuracy:0.2475 Validation Loss:1.6000, Validation Accuracy:0.2426
Epoch #294: Loss:1.5954, Accuracy:0.2500 Validation Loss:1.6002, Validation Accuracy:0.2443
Epoch #295: Loss:1.5958, Accuracy:0.2471 Validation Loss:1.6005, Validation Accuracy:0.2410
Epoch #296: Loss:1.5957, Accuracy:0.2467 Validation Loss:1.6004, Validation Accuracy:0.2443
Epoch #297: Loss:1.5955, Accuracy:0.2504 Validation Loss:1.6001, Validation Accuracy:0.2426
Epoch #298: Loss:1.5962, Accuracy:0.2479 Validation Loss:1.6003, Validation Accuracy:0.2426
Epoch #299: Loss:1.5956, Accuracy:0.2418 Validation Loss:1.6004, Validation Accuracy:0.2410
Epoch #300: Loss:1.5955, Accuracy:0.2471 Validation Loss:1.6000, Validation Accuracy:0.2443

Test:
Test Loss:1.60000134, Accuracy:0.2443
Labels: ['03', '01', '04', '02', '05']
Confusion Matrix:
[[  0   1  21   0  93]
 [  0   2  27   0  97]
 [  0   0  33   0  80]
 [  0   1  27   0  86]
 [  0   0  28   0 114]]
Classification Report:
              precision    recall  f1-score   support

          03       0.00      0.00      0.00       115
          01       0.50      0.02      0.03       126
          04       0.24      0.29      0.27       113
          02       0.00      0.00      0.00       114
          05       0.24      0.80      0.37       142

    accuracy                           0.24       610
   macro avg       0.20      0.22      0.13       610
weighted avg       0.20      0.24      0.14       610

============ Config: 1/1 === End Time: 2019.07.24 07:06:43 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 53 minutes, 40 seconds =====================


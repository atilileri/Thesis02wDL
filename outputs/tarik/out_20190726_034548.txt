======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf18.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.26 03:45:48 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'channelMode': '1', 'classificationMode': 'Posture3', 'trainingEpoch': 300, 'stepSize': 1, 'sampRate': 8, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3044 Files with 3 Label(s): ['02', '01', '03'].
Padding:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3044 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 3 classes
2435 steps for training, 609 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (2435, 7991, 7)
Test Batch: (609, 7991, 7)
Optimizer: <keras.optimizers.Adam object at 0x000001BE3B745E80>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001BE5B5C7EA0>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            2696      
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 39        
=================================================================
Total params: 11,535
Trainable params: 11,535
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.0956, Accuracy:0.3729, Validation Loss:1.0860, Validation Accuracy:0.3727
Epoch #2: Loss:1.0812, Accuracy:0.3729, Validation Loss:1.0767, Validation Accuracy:0.3941
Epoch #3: Loss:1.0756, Accuracy:0.3943, Validation Loss:1.0743, Validation Accuracy:0.3941
Epoch #4: Loss:1.0747, Accuracy:0.3943, Validation Loss:1.0753, Validation Accuracy:0.3941
Epoch #5: Loss:1.0752, Accuracy:0.3943, Validation Loss:1.0752, Validation Accuracy:0.3941
Epoch #6: Loss:1.0750, Accuracy:0.3943, Validation Loss:1.0747, Validation Accuracy:0.3941
Epoch #7: Loss:1.0745, Accuracy:0.3943, Validation Loss:1.0744, Validation Accuracy:0.3941
Epoch #8: Loss:1.0741, Accuracy:0.3943, Validation Loss:1.0743, Validation Accuracy:0.3941
Epoch #9: Loss:1.0741, Accuracy:0.3943, Validation Loss:1.0742, Validation Accuracy:0.3941
Epoch #10: Loss:1.0741, Accuracy:0.3943, Validation Loss:1.0742, Validation Accuracy:0.3941
Epoch #11: Loss:1.0741, Accuracy:0.3943, Validation Loss:1.0742, Validation Accuracy:0.3941
Epoch #12: Loss:1.0741, Accuracy:0.3943, Validation Loss:1.0741, Validation Accuracy:0.3941
Epoch #13: Loss:1.0739, Accuracy:0.3943, Validation Loss:1.0739, Validation Accuracy:0.3941
Epoch #14: Loss:1.0738, Accuracy:0.3943, Validation Loss:1.0738, Validation Accuracy:0.3941
Epoch #15: Loss:1.0737, Accuracy:0.3943, Validation Loss:1.0736, Validation Accuracy:0.3941
Epoch #16: Loss:1.0735, Accuracy:0.3943, Validation Loss:1.0734, Validation Accuracy:0.3941
Epoch #17: Loss:1.0733, Accuracy:0.3943, Validation Loss:1.0731, Validation Accuracy:0.3941
Epoch #18: Loss:1.0729, Accuracy:0.3943, Validation Loss:1.0726, Validation Accuracy:0.3941
Epoch #19: Loss:1.0723, Accuracy:0.3943, Validation Loss:1.0719, Validation Accuracy:0.3941
Epoch #20: Loss:1.0714, Accuracy:0.3955, Validation Loss:1.0708, Validation Accuracy:0.3990
Epoch #21: Loss:1.0701, Accuracy:0.4086, Validation Loss:1.0689, Validation Accuracy:0.4417
Epoch #22: Loss:1.0679, Accuracy:0.4329, Validation Loss:1.0657, Validation Accuracy:0.4499
Epoch #23: Loss:1.0640, Accuracy:0.4460, Validation Loss:1.0600, Validation Accuracy:0.4565
Epoch #24: Loss:1.0568, Accuracy:0.4517, Validation Loss:1.0498, Validation Accuracy:0.4631
Epoch #25: Loss:1.0447, Accuracy:0.4665, Validation Loss:1.0320, Validation Accuracy:0.4680
Epoch #26: Loss:1.0248, Accuracy:0.4645, Validation Loss:1.0067, Validation Accuracy:0.4565
Epoch #27: Loss:0.9974, Accuracy:0.4678, Validation Loss:0.9797, Validation Accuracy:0.4614
Epoch #28: Loss:0.9740, Accuracy:0.4682, Validation Loss:0.9656, Validation Accuracy:0.5140
Epoch #29: Loss:0.9597, Accuracy:0.5125, Validation Loss:0.9513, Validation Accuracy:0.5123
Epoch #30: Loss:0.9506, Accuracy:0.5253, Validation Loss:0.9523, Validation Accuracy:0.5156
Epoch #31: Loss:0.9488, Accuracy:0.5133, Validation Loss:0.9388, Validation Accuracy:0.5222
Epoch #32: Loss:0.9490, Accuracy:0.5158, Validation Loss:0.9474, Validation Accuracy:0.5107
Epoch #33: Loss:0.9433, Accuracy:0.5170, Validation Loss:0.9348, Validation Accuracy:0.5271
Epoch #34: Loss:0.9402, Accuracy:0.5240, Validation Loss:0.9304, Validation Accuracy:0.5189
Epoch #35: Loss:0.9400, Accuracy:0.5285, Validation Loss:0.9348, Validation Accuracy:0.5172
Epoch #36: Loss:0.9422, Accuracy:0.5199, Validation Loss:0.9350, Validation Accuracy:0.5205
Epoch #37: Loss:0.9360, Accuracy:0.5351, Validation Loss:0.9318, Validation Accuracy:0.5156
Epoch #38: Loss:0.9353, Accuracy:0.5285, Validation Loss:0.9280, Validation Accuracy:0.5255
Epoch #39: Loss:0.9322, Accuracy:0.5294, Validation Loss:0.9234, Validation Accuracy:0.5402
Epoch #40: Loss:0.9315, Accuracy:0.5285, Validation Loss:0.9212, Validation Accuracy:0.5419
Epoch #41: Loss:0.9320, Accuracy:0.5211, Validation Loss:0.9230, Validation Accuracy:0.5353
Epoch #42: Loss:0.9310, Accuracy:0.5273, Validation Loss:0.9196, Validation Accuracy:0.5369
Epoch #43: Loss:0.9279, Accuracy:0.5306, Validation Loss:0.9203, Validation Accuracy:0.5402
Epoch #44: Loss:0.9268, Accuracy:0.5343, Validation Loss:0.9193, Validation Accuracy:0.5369
Epoch #45: Loss:0.9273, Accuracy:0.5306, Validation Loss:0.9198, Validation Accuracy:0.5337
Epoch #46: Loss:0.9283, Accuracy:0.5298, Validation Loss:0.9172, Validation Accuracy:0.5402
Epoch #47: Loss:0.9277, Accuracy:0.5290, Validation Loss:0.9164, Validation Accuracy:0.5419
Epoch #48: Loss:0.9268, Accuracy:0.5335, Validation Loss:0.9213, Validation Accuracy:0.5402
Epoch #49: Loss:0.9276, Accuracy:0.5232, Validation Loss:0.9158, Validation Accuracy:0.5402
Epoch #50: Loss:0.9257, Accuracy:0.5343, Validation Loss:0.9165, Validation Accuracy:0.5337
Epoch #51: Loss:0.9302, Accuracy:0.5240, Validation Loss:0.9364, Validation Accuracy:0.5337
Epoch #52: Loss:0.9323, Accuracy:0.5351, Validation Loss:0.9284, Validation Accuracy:0.5337
Epoch #53: Loss:0.9313, Accuracy:0.5273, Validation Loss:0.9310, Validation Accuracy:0.5320
Epoch #54: Loss:0.9299, Accuracy:0.5368, Validation Loss:0.9246, Validation Accuracy:0.5320
Epoch #55: Loss:0.9301, Accuracy:0.5162, Validation Loss:0.9256, Validation Accuracy:0.5287
Epoch #56: Loss:0.9276, Accuracy:0.5376, Validation Loss:0.9152, Validation Accuracy:0.5369
Epoch #57: Loss:0.9232, Accuracy:0.5363, Validation Loss:0.9158, Validation Accuracy:0.5337
Epoch #58: Loss:0.9229, Accuracy:0.5368, Validation Loss:0.9143, Validation Accuracy:0.5337
Epoch #59: Loss:0.9222, Accuracy:0.5326, Validation Loss:0.9145, Validation Accuracy:0.5337
Epoch #60: Loss:0.9223, Accuracy:0.5306, Validation Loss:0.9152, Validation Accuracy:0.5402
Epoch #61: Loss:0.9260, Accuracy:0.5347, Validation Loss:0.9153, Validation Accuracy:0.5304
Epoch #62: Loss:0.9259, Accuracy:0.5306, Validation Loss:0.9187, Validation Accuracy:0.5468
Epoch #63: Loss:0.9220, Accuracy:0.5396, Validation Loss:0.9135, Validation Accuracy:0.5337
Epoch #64: Loss:0.9206, Accuracy:0.5355, Validation Loss:0.9217, Validation Accuracy:0.5402
Epoch #65: Loss:0.9248, Accuracy:0.5363, Validation Loss:0.9152, Validation Accuracy:0.5320
Epoch #66: Loss:0.9223, Accuracy:0.5343, Validation Loss:0.9249, Validation Accuracy:0.5435
Epoch #67: Loss:0.9233, Accuracy:0.5433, Validation Loss:0.9169, Validation Accuracy:0.5271
Epoch #68: Loss:0.9262, Accuracy:0.5351, Validation Loss:0.9190, Validation Accuracy:0.5452
Epoch #69: Loss:0.9211, Accuracy:0.5326, Validation Loss:0.9122, Validation Accuracy:0.5271
Epoch #70: Loss:0.9192, Accuracy:0.5405, Validation Loss:0.9133, Validation Accuracy:0.5369
Epoch #71: Loss:0.9193, Accuracy:0.5396, Validation Loss:0.9122, Validation Accuracy:0.5304
Epoch #72: Loss:0.9185, Accuracy:0.5417, Validation Loss:0.9126, Validation Accuracy:0.5304
Epoch #73: Loss:0.9188, Accuracy:0.5368, Validation Loss:0.9152, Validation Accuracy:0.5419
Epoch #74: Loss:0.9190, Accuracy:0.5421, Validation Loss:0.9106, Validation Accuracy:0.5386
Epoch #75: Loss:0.9170, Accuracy:0.5396, Validation Loss:0.9116, Validation Accuracy:0.5369
Epoch #76: Loss:0.9163, Accuracy:0.5405, Validation Loss:0.9103, Validation Accuracy:0.5369
Epoch #77: Loss:0.9160, Accuracy:0.5425, Validation Loss:0.9155, Validation Accuracy:0.5452
Epoch #78: Loss:0.9203, Accuracy:0.5425, Validation Loss:0.9150, Validation Accuracy:0.5468
Epoch #79: Loss:0.9175, Accuracy:0.5470, Validation Loss:0.9135, Validation Accuracy:0.5337
Epoch #80: Loss:0.9195, Accuracy:0.5384, Validation Loss:0.9255, Validation Accuracy:0.5287
Epoch #81: Loss:0.9226, Accuracy:0.5302, Validation Loss:0.9329, Validation Accuracy:0.5369
Epoch #82: Loss:0.9324, Accuracy:0.5368, Validation Loss:0.9317, Validation Accuracy:0.5369
Epoch #83: Loss:0.9185, Accuracy:0.5437, Validation Loss:0.9230, Validation Accuracy:0.5353
Epoch #84: Loss:0.9232, Accuracy:0.5359, Validation Loss:0.9218, Validation Accuracy:0.5337
Epoch #85: Loss:0.9239, Accuracy:0.5372, Validation Loss:0.9106, Validation Accuracy:0.5320
Epoch #86: Loss:0.9233, Accuracy:0.5437, Validation Loss:0.9114, Validation Accuracy:0.5419
Epoch #87: Loss:0.9226, Accuracy:0.5335, Validation Loss:0.9123, Validation Accuracy:0.5402
Epoch #88: Loss:0.9214, Accuracy:0.5400, Validation Loss:0.9108, Validation Accuracy:0.5353
Epoch #89: Loss:0.9172, Accuracy:0.5437, Validation Loss:0.9114, Validation Accuracy:0.5369
Epoch #90: Loss:0.9159, Accuracy:0.5417, Validation Loss:0.9110, Validation Accuracy:0.5353
Epoch #91: Loss:0.9145, Accuracy:0.5433, Validation Loss:0.9106, Validation Accuracy:0.5386
Epoch #92: Loss:0.9156, Accuracy:0.5437, Validation Loss:0.9095, Validation Accuracy:0.5255
Epoch #93: Loss:0.9162, Accuracy:0.5446, Validation Loss:0.9148, Validation Accuracy:0.5468
Epoch #94: Loss:0.9153, Accuracy:0.5396, Validation Loss:0.9092, Validation Accuracy:0.5271
Epoch #95: Loss:0.9155, Accuracy:0.5425, Validation Loss:0.9128, Validation Accuracy:0.5435
Epoch #96: Loss:0.9129, Accuracy:0.5388, Validation Loss:0.9086, Validation Accuracy:0.5337
Epoch #97: Loss:0.9118, Accuracy:0.5433, Validation Loss:0.9092, Validation Accuracy:0.5435
Epoch #98: Loss:0.9119, Accuracy:0.5417, Validation Loss:0.9093, Validation Accuracy:0.5452
Epoch #99: Loss:0.9107, Accuracy:0.5446, Validation Loss:0.9086, Validation Accuracy:0.5402
Epoch #100: Loss:0.9106, Accuracy:0.5454, Validation Loss:0.9076, Validation Accuracy:0.5287
Epoch #101: Loss:0.9169, Accuracy:0.5413, Validation Loss:0.9143, Validation Accuracy:0.5484
Epoch #102: Loss:0.9120, Accuracy:0.5446, Validation Loss:0.9070, Validation Accuracy:0.5369
Epoch #103: Loss:0.9142, Accuracy:0.5429, Validation Loss:0.9077, Validation Accuracy:0.5271
Epoch #104: Loss:0.9114, Accuracy:0.5454, Validation Loss:0.9155, Validation Accuracy:0.5435
Epoch #105: Loss:0.9139, Accuracy:0.5425, Validation Loss:0.9066, Validation Accuracy:0.5320
Epoch #106: Loss:0.9113, Accuracy:0.5400, Validation Loss:0.9068, Validation Accuracy:0.5353
Epoch #107: Loss:0.9089, Accuracy:0.5454, Validation Loss:0.9108, Validation Accuracy:0.5468
Epoch #108: Loss:0.9116, Accuracy:0.5421, Validation Loss:0.9074, Validation Accuracy:0.5287
Epoch #109: Loss:0.9124, Accuracy:0.5437, Validation Loss:0.9149, Validation Accuracy:0.5435
Epoch #110: Loss:0.9084, Accuracy:0.5478, Validation Loss:0.9060, Validation Accuracy:0.5320
Epoch #111: Loss:0.9120, Accuracy:0.5421, Validation Loss:0.9055, Validation Accuracy:0.5337
Epoch #112: Loss:0.9106, Accuracy:0.5396, Validation Loss:0.9153, Validation Accuracy:0.5353
Epoch #113: Loss:0.9099, Accuracy:0.5413, Validation Loss:0.9071, Validation Accuracy:0.5320
Epoch #114: Loss:0.9069, Accuracy:0.5409, Validation Loss:0.9098, Validation Accuracy:0.5452
Epoch #115: Loss:0.9059, Accuracy:0.5425, Validation Loss:0.9064, Validation Accuracy:0.5320
Epoch #116: Loss:0.9067, Accuracy:0.5487, Validation Loss:0.9088, Validation Accuracy:0.5435
Epoch #117: Loss:0.9061, Accuracy:0.5474, Validation Loss:0.9045, Validation Accuracy:0.5402
Epoch #118: Loss:0.9057, Accuracy:0.5437, Validation Loss:0.9049, Validation Accuracy:0.5452
Epoch #119: Loss:0.9058, Accuracy:0.5483, Validation Loss:0.9045, Validation Accuracy:0.5287
Epoch #120: Loss:0.9063, Accuracy:0.5433, Validation Loss:0.9041, Validation Accuracy:0.5304
Epoch #121: Loss:0.9052, Accuracy:0.5462, Validation Loss:0.9038, Validation Accuracy:0.5402
Epoch #122: Loss:0.9053, Accuracy:0.5441, Validation Loss:0.9144, Validation Accuracy:0.5353
Epoch #123: Loss:0.9084, Accuracy:0.5450, Validation Loss:0.9077, Validation Accuracy:0.5419
Epoch #124: Loss:0.9130, Accuracy:0.5499, Validation Loss:0.9177, Validation Accuracy:0.5353
Epoch #125: Loss:0.9180, Accuracy:0.5351, Validation Loss:0.9119, Validation Accuracy:0.5369
Epoch #126: Loss:0.9068, Accuracy:0.5446, Validation Loss:0.9037, Validation Accuracy:0.5320
Epoch #127: Loss:0.9062, Accuracy:0.5499, Validation Loss:0.9043, Validation Accuracy:0.5386
Epoch #128: Loss:0.9030, Accuracy:0.5437, Validation Loss:0.9086, Validation Accuracy:0.5386
Epoch #129: Loss:0.9033, Accuracy:0.5474, Validation Loss:0.9046, Validation Accuracy:0.5304
Epoch #130: Loss:0.9055, Accuracy:0.5425, Validation Loss:0.9132, Validation Accuracy:0.5353
Epoch #131: Loss:0.9055, Accuracy:0.5417, Validation Loss:0.9028, Validation Accuracy:0.5452
Epoch #132: Loss:0.9033, Accuracy:0.5507, Validation Loss:0.9026, Validation Accuracy:0.5353
Epoch #133: Loss:0.9021, Accuracy:0.5437, Validation Loss:0.9085, Validation Accuracy:0.5320
Epoch #134: Loss:0.9019, Accuracy:0.5495, Validation Loss:0.9073, Validation Accuracy:0.5337
Epoch #135: Loss:0.9045, Accuracy:0.5405, Validation Loss:0.9111, Validation Accuracy:0.5369
Epoch #136: Loss:0.9059, Accuracy:0.5454, Validation Loss:0.9057, Validation Accuracy:0.5369
Epoch #137: Loss:0.9074, Accuracy:0.5474, Validation Loss:0.9027, Validation Accuracy:0.5271
Epoch #138: Loss:0.9054, Accuracy:0.5400, Validation Loss:0.9049, Validation Accuracy:0.5353
Epoch #139: Loss:0.9054, Accuracy:0.5409, Validation Loss:0.9076, Validation Accuracy:0.5369
Epoch #140: Loss:0.9022, Accuracy:0.5470, Validation Loss:0.9034, Validation Accuracy:0.5369
Epoch #141: Loss:0.9003, Accuracy:0.5446, Validation Loss:0.9023, Validation Accuracy:0.5337
Epoch #142: Loss:0.9007, Accuracy:0.5478, Validation Loss:0.9025, Validation Accuracy:0.5337
Epoch #143: Loss:0.9012, Accuracy:0.5458, Validation Loss:0.9071, Validation Accuracy:0.5353
Epoch #144: Loss:0.9020, Accuracy:0.5450, Validation Loss:0.9032, Validation Accuracy:0.5287
Epoch #145: Loss:0.9030, Accuracy:0.5515, Validation Loss:0.9104, Validation Accuracy:0.5353
Epoch #146: Loss:0.9051, Accuracy:0.5478, Validation Loss:0.9189, Validation Accuracy:0.5337
Epoch #147: Loss:0.9084, Accuracy:0.5441, Validation Loss:0.9036, Validation Accuracy:0.5337
Epoch #148: Loss:0.9119, Accuracy:0.5441, Validation Loss:0.9017, Validation Accuracy:0.5369
Epoch #149: Loss:0.9030, Accuracy:0.5437, Validation Loss:0.9095, Validation Accuracy:0.5402
Epoch #150: Loss:0.9077, Accuracy:0.5483, Validation Loss:0.9058, Validation Accuracy:0.5304
Epoch #151: Loss:0.9062, Accuracy:0.5454, Validation Loss:0.9108, Validation Accuracy:0.5337
Epoch #152: Loss:0.9013, Accuracy:0.5446, Validation Loss:0.9046, Validation Accuracy:0.5353
Epoch #153: Loss:0.9017, Accuracy:0.5483, Validation Loss:0.9126, Validation Accuracy:0.5320
Epoch #154: Loss:0.9019, Accuracy:0.5450, Validation Loss:0.9020, Validation Accuracy:0.5386
Epoch #155: Loss:0.9009, Accuracy:0.5520, Validation Loss:0.9017, Validation Accuracy:0.5386
Epoch #156: Loss:0.8976, Accuracy:0.5425, Validation Loss:0.9012, Validation Accuracy:0.5337
Epoch #157: Loss:0.8977, Accuracy:0.5462, Validation Loss:0.9025, Validation Accuracy:0.5304
Epoch #158: Loss:0.8970, Accuracy:0.5450, Validation Loss:0.9023, Validation Accuracy:0.5304
Epoch #159: Loss:0.8972, Accuracy:0.5429, Validation Loss:0.9027, Validation Accuracy:0.5353
Epoch #160: Loss:0.8973, Accuracy:0.5474, Validation Loss:0.9060, Validation Accuracy:0.5353
Epoch #161: Loss:0.8997, Accuracy:0.5409, Validation Loss:0.9007, Validation Accuracy:0.5419
Epoch #162: Loss:0.8979, Accuracy:0.5483, Validation Loss:0.9020, Validation Accuracy:0.5419
Epoch #163: Loss:0.8993, Accuracy:0.5433, Validation Loss:0.9258, Validation Accuracy:0.5271
Epoch #164: Loss:0.9037, Accuracy:0.5450, Validation Loss:0.9154, Validation Accuracy:0.5255
Epoch #165: Loss:0.9067, Accuracy:0.5446, Validation Loss:0.9082, Validation Accuracy:0.5353
Epoch #166: Loss:0.9020, Accuracy:0.5454, Validation Loss:0.9003, Validation Accuracy:0.5386
Epoch #167: Loss:0.9002, Accuracy:0.5454, Validation Loss:0.9004, Validation Accuracy:0.5419
Epoch #168: Loss:0.8989, Accuracy:0.5458, Validation Loss:0.9078, Validation Accuracy:0.5337
Epoch #169: Loss:0.8987, Accuracy:0.5478, Validation Loss:0.9010, Validation Accuracy:0.5419
Epoch #170: Loss:0.8949, Accuracy:0.5474, Validation Loss:0.9043, Validation Accuracy:0.5304
Epoch #171: Loss:0.8946, Accuracy:0.5470, Validation Loss:0.9032, Validation Accuracy:0.5337
Epoch #172: Loss:0.8983, Accuracy:0.5483, Validation Loss:0.9097, Validation Accuracy:0.5337
Epoch #173: Loss:0.8980, Accuracy:0.5450, Validation Loss:0.9001, Validation Accuracy:0.5419
Epoch #174: Loss:0.8971, Accuracy:0.5474, Validation Loss:0.9020, Validation Accuracy:0.5353
Epoch #175: Loss:0.8966, Accuracy:0.5499, Validation Loss:0.9101, Validation Accuracy:0.5304
Epoch #176: Loss:0.8963, Accuracy:0.5520, Validation Loss:0.9114, Validation Accuracy:0.5271
Epoch #177: Loss:0.9002, Accuracy:0.5417, Validation Loss:0.9126, Validation Accuracy:0.5386
Epoch #178: Loss:0.8961, Accuracy:0.5577, Validation Loss:0.9033, Validation Accuracy:0.5337
Epoch #179: Loss:0.8964, Accuracy:0.5515, Validation Loss:0.9018, Validation Accuracy:0.5287
Epoch #180: Loss:0.8946, Accuracy:0.5441, Validation Loss:0.9013, Validation Accuracy:0.5287
Epoch #181: Loss:0.8962, Accuracy:0.5487, Validation Loss:0.9030, Validation Accuracy:0.5386
Epoch #182: Loss:0.8998, Accuracy:0.5483, Validation Loss:0.9022, Validation Accuracy:0.5320
Epoch #183: Loss:0.8977, Accuracy:0.5483, Validation Loss:0.9045, Validation Accuracy:0.5320
Epoch #184: Loss:0.8932, Accuracy:0.5487, Validation Loss:0.9009, Validation Accuracy:0.5369
Epoch #185: Loss:0.8942, Accuracy:0.5532, Validation Loss:0.9147, Validation Accuracy:0.5304
Epoch #186: Loss:0.8971, Accuracy:0.5503, Validation Loss:0.9069, Validation Accuracy:0.5369
Epoch #187: Loss:0.8964, Accuracy:0.5528, Validation Loss:0.9100, Validation Accuracy:0.5337
Epoch #188: Loss:0.8961, Accuracy:0.5524, Validation Loss:0.9001, Validation Accuracy:0.5337
Epoch #189: Loss:0.8946, Accuracy:0.5478, Validation Loss:0.8996, Validation Accuracy:0.5386
Epoch #190: Loss:0.8927, Accuracy:0.5520, Validation Loss:0.9032, Validation Accuracy:0.5353
Epoch #191: Loss:0.8937, Accuracy:0.5474, Validation Loss:0.9010, Validation Accuracy:0.5402
Epoch #192: Loss:0.8969, Accuracy:0.5491, Validation Loss:0.8995, Validation Accuracy:0.5369
Epoch #193: Loss:0.9002, Accuracy:0.5470, Validation Loss:0.9217, Validation Accuracy:0.5353
Epoch #194: Loss:0.9046, Accuracy:0.5417, Validation Loss:0.9175, Validation Accuracy:0.5287
Epoch #195: Loss:0.9031, Accuracy:0.5429, Validation Loss:0.9273, Validation Accuracy:0.5238
Epoch #196: Loss:0.9073, Accuracy:0.5405, Validation Loss:0.9045, Validation Accuracy:0.5271
Epoch #197: Loss:0.8978, Accuracy:0.5487, Validation Loss:0.9013, Validation Accuracy:0.5320
Epoch #198: Loss:0.8928, Accuracy:0.5499, Validation Loss:0.8996, Validation Accuracy:0.5419
Epoch #199: Loss:0.8915, Accuracy:0.5511, Validation Loss:0.9041, Validation Accuracy:0.5304
Epoch #200: Loss:0.8929, Accuracy:0.5573, Validation Loss:0.8999, Validation Accuracy:0.5320
Epoch #201: Loss:0.8936, Accuracy:0.5540, Validation Loss:0.9070, Validation Accuracy:0.5369
Epoch #202: Loss:0.8953, Accuracy:0.5491, Validation Loss:0.8999, Validation Accuracy:0.5369
Epoch #203: Loss:0.8904, Accuracy:0.5524, Validation Loss:0.9033, Validation Accuracy:0.5287
Epoch #204: Loss:0.8923, Accuracy:0.5495, Validation Loss:0.8989, Validation Accuracy:0.5353
Epoch #205: Loss:0.8912, Accuracy:0.5520, Validation Loss:0.8989, Validation Accuracy:0.5386
Epoch #206: Loss:0.8907, Accuracy:0.5524, Validation Loss:0.9030, Validation Accuracy:0.5271
Epoch #207: Loss:0.8887, Accuracy:0.5540, Validation Loss:0.9084, Validation Accuracy:0.5386
Epoch #208: Loss:0.8989, Accuracy:0.5413, Validation Loss:0.9097, Validation Accuracy:0.5337
Epoch #209: Loss:0.8932, Accuracy:0.5478, Validation Loss:0.8993, Validation Accuracy:0.5304
Epoch #210: Loss:0.8897, Accuracy:0.5462, Validation Loss:0.8987, Validation Accuracy:0.5386
Epoch #211: Loss:0.8913, Accuracy:0.5495, Validation Loss:0.8984, Validation Accuracy:0.5386
Epoch #212: Loss:0.8887, Accuracy:0.5536, Validation Loss:0.8996, Validation Accuracy:0.5386
Epoch #213: Loss:0.8889, Accuracy:0.5515, Validation Loss:0.8989, Validation Accuracy:0.5386
Epoch #214: Loss:0.8898, Accuracy:0.5544, Validation Loss:0.9001, Validation Accuracy:0.5402
Epoch #215: Loss:0.8904, Accuracy:0.5524, Validation Loss:0.8996, Validation Accuracy:0.5386
Epoch #216: Loss:0.8917, Accuracy:0.5515, Validation Loss:0.8992, Validation Accuracy:0.5369
Epoch #217: Loss:0.8884, Accuracy:0.5536, Validation Loss:0.9031, Validation Accuracy:0.5255
Epoch #218: Loss:0.8887, Accuracy:0.5503, Validation Loss:0.8988, Validation Accuracy:0.5386
Epoch #219: Loss:0.8884, Accuracy:0.5515, Validation Loss:0.9055, Validation Accuracy:0.5452
Epoch #220: Loss:0.8990, Accuracy:0.5450, Validation Loss:0.9015, Validation Accuracy:0.5271
Epoch #221: Loss:0.8938, Accuracy:0.5466, Validation Loss:0.9090, Validation Accuracy:0.5255
Epoch #222: Loss:0.8954, Accuracy:0.5536, Validation Loss:0.9101, Validation Accuracy:0.5402
Epoch #223: Loss:0.8931, Accuracy:0.5540, Validation Loss:0.9120, Validation Accuracy:0.5320
Epoch #224: Loss:0.8953, Accuracy:0.5499, Validation Loss:0.8985, Validation Accuracy:0.5337
Epoch #225: Loss:0.8911, Accuracy:0.5503, Validation Loss:0.8974, Validation Accuracy:0.5337
Epoch #226: Loss:0.8916, Accuracy:0.5503, Validation Loss:0.9085, Validation Accuracy:0.5320
Epoch #227: Loss:0.8976, Accuracy:0.5429, Validation Loss:0.9015, Validation Accuracy:0.5419
Epoch #228: Loss:0.8915, Accuracy:0.5515, Validation Loss:0.9049, Validation Accuracy:0.5304
Epoch #229: Loss:0.8894, Accuracy:0.5499, Validation Loss:0.9033, Validation Accuracy:0.5386
Epoch #230: Loss:0.8961, Accuracy:0.5581, Validation Loss:0.8989, Validation Accuracy:0.5255
Epoch #231: Loss:0.8879, Accuracy:0.5544, Validation Loss:0.8976, Validation Accuracy:0.5320
Epoch #232: Loss:0.8887, Accuracy:0.5503, Validation Loss:0.8976, Validation Accuracy:0.5353
Epoch #233: Loss:0.8864, Accuracy:0.5507, Validation Loss:0.9015, Validation Accuracy:0.5304
Epoch #234: Loss:0.8858, Accuracy:0.5556, Validation Loss:0.8971, Validation Accuracy:0.5353
Epoch #235: Loss:0.8854, Accuracy:0.5503, Validation Loss:0.8984, Validation Accuracy:0.5287
Epoch #236: Loss:0.8850, Accuracy:0.5548, Validation Loss:0.8969, Validation Accuracy:0.5353
Epoch #237: Loss:0.8842, Accuracy:0.5532, Validation Loss:0.8968, Validation Accuracy:0.5337
Epoch #238: Loss:0.8839, Accuracy:0.5511, Validation Loss:0.8973, Validation Accuracy:0.5304
Epoch #239: Loss:0.8842, Accuracy:0.5495, Validation Loss:0.8978, Validation Accuracy:0.5304
Epoch #240: Loss:0.8837, Accuracy:0.5524, Validation Loss:0.8982, Validation Accuracy:0.5353
Epoch #241: Loss:0.8870, Accuracy:0.5561, Validation Loss:0.9005, Validation Accuracy:0.5287
Epoch #242: Loss:0.8849, Accuracy:0.5515, Validation Loss:0.8983, Validation Accuracy:0.5304
Epoch #243: Loss:0.8820, Accuracy:0.5495, Validation Loss:0.8961, Validation Accuracy:0.5369
Epoch #244: Loss:0.8848, Accuracy:0.5503, Validation Loss:0.9006, Validation Accuracy:0.5337
Epoch #245: Loss:0.8847, Accuracy:0.5524, Validation Loss:0.9012, Validation Accuracy:0.5287
Epoch #246: Loss:0.8847, Accuracy:0.5524, Validation Loss:0.8984, Validation Accuracy:0.5402
Epoch #247: Loss:0.8842, Accuracy:0.5552, Validation Loss:0.8950, Validation Accuracy:0.5369
Epoch #248: Loss:0.8836, Accuracy:0.5540, Validation Loss:0.8981, Validation Accuracy:0.5419
Epoch #249: Loss:0.8877, Accuracy:0.5441, Validation Loss:0.8950, Validation Accuracy:0.5320
Epoch #250: Loss:0.8865, Accuracy:0.5478, Validation Loss:0.9109, Validation Accuracy:0.5304
Epoch #251: Loss:0.8908, Accuracy:0.5487, Validation Loss:0.8955, Validation Accuracy:0.5386
Epoch #252: Loss:0.8805, Accuracy:0.5520, Validation Loss:0.8948, Validation Accuracy:0.5271
Epoch #253: Loss:0.8833, Accuracy:0.5528, Validation Loss:0.8944, Validation Accuracy:0.5304
Epoch #254: Loss:0.8806, Accuracy:0.5544, Validation Loss:0.8932, Validation Accuracy:0.5304
Epoch #255: Loss:0.8804, Accuracy:0.5532, Validation Loss:0.8937, Validation Accuracy:0.5238
Epoch #256: Loss:0.8776, Accuracy:0.5532, Validation Loss:0.8927, Validation Accuracy:0.5337
Epoch #257: Loss:0.8831, Accuracy:0.5581, Validation Loss:0.8919, Validation Accuracy:0.5320
Epoch #258: Loss:0.8779, Accuracy:0.5569, Validation Loss:0.8934, Validation Accuracy:0.5238
Epoch #259: Loss:0.8765, Accuracy:0.5565, Validation Loss:0.8941, Validation Accuracy:0.5468
Epoch #260: Loss:0.8781, Accuracy:0.5524, Validation Loss:0.8966, Validation Accuracy:0.5337
Epoch #261: Loss:0.8796, Accuracy:0.5544, Validation Loss:0.8931, Validation Accuracy:0.5271
Epoch #262: Loss:0.8795, Accuracy:0.5585, Validation Loss:0.8919, Validation Accuracy:0.5369
Epoch #263: Loss:0.8803, Accuracy:0.5507, Validation Loss:0.8902, Validation Accuracy:0.5337
Epoch #264: Loss:0.8761, Accuracy:0.5515, Validation Loss:0.8901, Validation Accuracy:0.5353
Epoch #265: Loss:0.8749, Accuracy:0.5532, Validation Loss:0.8883, Validation Accuracy:0.5287
Epoch #266: Loss:0.8744, Accuracy:0.5536, Validation Loss:0.8882, Validation Accuracy:0.5337
Epoch #267: Loss:0.8738, Accuracy:0.5524, Validation Loss:0.8878, Validation Accuracy:0.5304
Epoch #268: Loss:0.8731, Accuracy:0.5544, Validation Loss:0.8920, Validation Accuracy:0.5337
Epoch #269: Loss:0.8752, Accuracy:0.5544, Validation Loss:0.8870, Validation Accuracy:0.5271
Epoch #270: Loss:0.8728, Accuracy:0.5528, Validation Loss:0.8865, Validation Accuracy:0.5287
Epoch #271: Loss:0.8715, Accuracy:0.5540, Validation Loss:0.8857, Validation Accuracy:0.5369
Epoch #272: Loss:0.8700, Accuracy:0.5561, Validation Loss:0.8881, Validation Accuracy:0.5304
Epoch #273: Loss:0.8724, Accuracy:0.5544, Validation Loss:0.8882, Validation Accuracy:0.5271
Epoch #274: Loss:0.8709, Accuracy:0.5515, Validation Loss:0.8856, Validation Accuracy:0.5337
Epoch #275: Loss:0.8725, Accuracy:0.5536, Validation Loss:0.8866, Validation Accuracy:0.5287
Epoch #276: Loss:0.8732, Accuracy:0.5458, Validation Loss:0.9057, Validation Accuracy:0.5287
Epoch #277: Loss:0.8817, Accuracy:0.5499, Validation Loss:0.8862, Validation Accuracy:0.5468
Epoch #278: Loss:0.8752, Accuracy:0.5593, Validation Loss:0.8860, Validation Accuracy:0.5419
Epoch #279: Loss:0.8770, Accuracy:0.5507, Validation Loss:0.9093, Validation Accuracy:0.5222
Epoch #280: Loss:0.8819, Accuracy:0.5515, Validation Loss:0.9044, Validation Accuracy:0.5320
Epoch #281: Loss:0.8798, Accuracy:0.5466, Validation Loss:0.8930, Validation Accuracy:0.5402
Epoch #282: Loss:0.8734, Accuracy:0.5593, Validation Loss:0.8908, Validation Accuracy:0.5419
Epoch #283: Loss:0.8734, Accuracy:0.5569, Validation Loss:0.8907, Validation Accuracy:0.5402
Epoch #284: Loss:0.8716, Accuracy:0.5528, Validation Loss:0.8843, Validation Accuracy:0.5386
Epoch #285: Loss:0.8722, Accuracy:0.5536, Validation Loss:0.8864, Validation Accuracy:0.5353
Epoch #286: Loss:0.8713, Accuracy:0.5540, Validation Loss:0.8837, Validation Accuracy:0.5386
Epoch #287: Loss:0.8762, Accuracy:0.5598, Validation Loss:0.8850, Validation Accuracy:0.5435
Epoch #288: Loss:0.8704, Accuracy:0.5528, Validation Loss:0.8834, Validation Accuracy:0.5287
Epoch #289: Loss:0.8662, Accuracy:0.5593, Validation Loss:0.8849, Validation Accuracy:0.5320
Epoch #290: Loss:0.8667, Accuracy:0.5598, Validation Loss:0.8826, Validation Accuracy:0.5369
Epoch #291: Loss:0.8660, Accuracy:0.5581, Validation Loss:0.8861, Validation Accuracy:0.5271
Epoch #292: Loss:0.8669, Accuracy:0.5540, Validation Loss:0.8929, Validation Accuracy:0.5238
Epoch #293: Loss:0.8721, Accuracy:0.5565, Validation Loss:0.8855, Validation Accuracy:0.5337
Epoch #294: Loss:0.8664, Accuracy:0.5618, Validation Loss:0.8820, Validation Accuracy:0.5304
Epoch #295: Loss:0.8649, Accuracy:0.5565, Validation Loss:0.8820, Validation Accuracy:0.5287
Epoch #296: Loss:0.8636, Accuracy:0.5598, Validation Loss:0.8869, Validation Accuracy:0.5369
Epoch #297: Loss:0.8680, Accuracy:0.5634, Validation Loss:0.8820, Validation Accuracy:0.5353
Epoch #298: Loss:0.8634, Accuracy:0.5598, Validation Loss:0.8824, Validation Accuracy:0.5205
Epoch #299: Loss:0.8625, Accuracy:0.5610, Validation Loss:0.8817, Validation Accuracy:0.5402
Epoch #300: Loss:0.8621, Accuracy:0.5647, Validation Loss:0.8838, Validation Accuracy:0.5468

Test:
Test Loss:0.88378084, Accuracy:0.5468
Labels: ['02', '01', '03']
Confusion Matrix:
       02   01  03
t:02  138   80   9
t:01   83  117  40
t:03   14   50  78
Classification Report:
              precision    recall  f1-score   support

          02       0.59      0.61      0.60       227
          01       0.47      0.49      0.48       240
          03       0.61      0.55      0.58       142

    accuracy                           0.55       609
   macro avg       0.56      0.55      0.55       609
weighted avg       0.55      0.55      0.55       609

============ Config: 1/1 === End Time: 2019.07.26 04:01:34 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 15 minutes, 46 seconds =====================

Ending script after plotting results...

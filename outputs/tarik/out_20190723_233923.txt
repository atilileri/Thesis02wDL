======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf37.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.23 23:39:23 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Specto', 'channelMode': '2Ov', 'classificationMode': 'Speaker', 'trainingEpoch': 300, 'stepSize': 6, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 15 Label(s): ['sg', 'mb', 'eg', 'eb', 'eo', 'yd', 'ds', 'sk', 'ck', 'my', 'by', 'ib', 'ek', 'ce', 'aa'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for Specto------
---LSTM Classifier---
Train Batch: (2436, 373, 516)
Test Batch: (610, 373, 516)
Optimizer: <keras.optimizers.Adam object at 0x00000259AB97C6D8>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000025963406AE8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 373, 24)           51936     
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 53,907
Trainable params: 53,907
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.7073, Accuracy:0.0928 Validation Loss:2.7058, Validation Accuracy:0.1016
Epoch #2: Loss:2.7048, Accuracy:0.1022 Validation Loss:2.7028, Validation Accuracy:0.1016
Epoch #3: Loss:2.7015, Accuracy:0.1022 Validation Loss:2.6991, Validation Accuracy:0.1016
Epoch #4: Loss:2.6975, Accuracy:0.1022 Validation Loss:2.6943, Validation Accuracy:0.1016
Epoch #5: Loss:2.6921, Accuracy:0.1022 Validation Loss:2.6879, Validation Accuracy:0.1016
Epoch #6: Loss:2.6850, Accuracy:0.1022 Validation Loss:2.6805, Validation Accuracy:0.1016
Epoch #7: Loss:2.6782, Accuracy:0.1022 Validation Loss:2.6761, Validation Accuracy:0.1016
Epoch #8: Loss:2.6750, Accuracy:0.1022 Validation Loss:2.6715, Validation Accuracy:0.1016
Epoch #9: Loss:2.6707, Accuracy:0.1022 Validation Loss:2.6682, Validation Accuracy:0.1016
Epoch #10: Loss:2.6680, Accuracy:0.1022 Validation Loss:2.6658, Validation Accuracy:0.1016
Epoch #11: Loss:2.6662, Accuracy:0.1022 Validation Loss:2.6645, Validation Accuracy:0.1016
Epoch #12: Loss:2.6644, Accuracy:0.1022 Validation Loss:2.6630, Validation Accuracy:0.1016
Epoch #13: Loss:2.6632, Accuracy:0.1022 Validation Loss:2.6623, Validation Accuracy:0.1016
Epoch #14: Loss:2.6627, Accuracy:0.1022 Validation Loss:2.6615, Validation Accuracy:0.1016
Epoch #15: Loss:2.6618, Accuracy:0.1022 Validation Loss:2.6612, Validation Accuracy:0.1016
Epoch #16: Loss:2.6617, Accuracy:0.1022 Validation Loss:2.6608, Validation Accuracy:0.1016
Epoch #17: Loss:2.6611, Accuracy:0.1022 Validation Loss:2.6606, Validation Accuracy:0.1016
Epoch #18: Loss:2.6613, Accuracy:0.1022 Validation Loss:2.6606, Validation Accuracy:0.1016
Epoch #19: Loss:2.6611, Accuracy:0.1022 Validation Loss:2.6606, Validation Accuracy:0.1016
Epoch #20: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #21: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6605, Validation Accuracy:0.1016
Epoch #22: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #23: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6605, Validation Accuracy:0.1016
Epoch #24: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #25: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6605, Validation Accuracy:0.1016
Epoch #26: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #27: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #28: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6605, Validation Accuracy:0.1016
Epoch #29: Loss:2.6611, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #30: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #31: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #32: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #33: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #34: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #35: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #36: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #37: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #38: Loss:2.6611, Accuracy:0.1022 Validation Loss:2.6605, Validation Accuracy:0.1016
Epoch #39: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #40: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #41: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #42: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #43: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #44: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #45: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #46: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #47: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #48: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #49: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #50: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #51: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #52: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #53: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #54: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #55: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #56: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #57: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #58: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #59: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #60: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #61: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #62: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #63: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #64: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #65: Loss:2.6612, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #66: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #67: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #68: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #69: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6604, Validation Accuracy:0.1016
Epoch #70: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #71: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #72: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #73: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #74: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #75: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #76: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #77: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #78: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #79: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #80: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #81: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #82: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #83: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #84: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #85: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6603, Validation Accuracy:0.1016
Epoch #86: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #87: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #88: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #89: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #90: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #91: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #92: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #93: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #94: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #95: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #96: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #97: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #98: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #99: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #100: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #101: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #102: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #103: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #104: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #105: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #106: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #107: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #108: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #109: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #110: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #111: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #112: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #113: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #114: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #115: Loss:2.6604, Accuracy:0.1022 Validation Loss:2.6598, Validation Accuracy:0.1016
Epoch #116: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6598, Validation Accuracy:0.1016
Epoch #117: Loss:2.6604, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #118: Loss:2.6609, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #119: Loss:2.6604, Accuracy:0.1022 Validation Loss:2.6599, Validation Accuracy:0.1016
Epoch #120: Loss:2.6604, Accuracy:0.1022 Validation Loss:2.6597, Validation Accuracy:0.1016
Epoch #121: Loss:2.6601, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #122: Loss:2.6603, Accuracy:0.1022 Validation Loss:2.6594, Validation Accuracy:0.1016
Epoch #123: Loss:2.6600, Accuracy:0.1022 Validation Loss:2.6592, Validation Accuracy:0.1016
Epoch #124: Loss:2.6598, Accuracy:0.1022 Validation Loss:2.6588, Validation Accuracy:0.1016
Epoch #125: Loss:2.6608, Accuracy:0.1022 Validation Loss:2.6581, Validation Accuracy:0.1016
Epoch #126: Loss:2.6615, Accuracy:0.1022 Validation Loss:2.6597, Validation Accuracy:0.1016
Epoch #127: Loss:2.6584, Accuracy:0.1022 Validation Loss:2.6579, Validation Accuracy:0.1016
Epoch #128: Loss:2.6560, Accuracy:0.1022 Validation Loss:2.6613, Validation Accuracy:0.1016
Epoch #129: Loss:2.6545, Accuracy:0.1022 Validation Loss:2.6527, Validation Accuracy:0.1016
Epoch #130: Loss:2.6466, Accuracy:0.1026 Validation Loss:2.6345, Validation Accuracy:0.1016
Epoch #131: Loss:2.6426, Accuracy:0.1030 Validation Loss:2.6594, Validation Accuracy:0.1033
Epoch #132: Loss:2.6440, Accuracy:0.1076 Validation Loss:2.6456, Validation Accuracy:0.1082
Epoch #133: Loss:2.6506, Accuracy:0.1047 Validation Loss:2.6657, Validation Accuracy:0.1033
Epoch #134: Loss:2.6637, Accuracy:0.1034 Validation Loss:2.6615, Validation Accuracy:0.1016
Epoch #135: Loss:2.6590, Accuracy:0.1034 Validation Loss:2.6583, Validation Accuracy:0.1016
Epoch #136: Loss:2.6573, Accuracy:0.1039 Validation Loss:2.6574, Validation Accuracy:0.1033
Epoch #137: Loss:2.6563, Accuracy:0.1067 Validation Loss:2.6566, Validation Accuracy:0.1033
Epoch #138: Loss:2.6539, Accuracy:0.1092 Validation Loss:2.6530, Validation Accuracy:0.1115
Epoch #139: Loss:2.6814, Accuracy:0.0805 Validation Loss:2.7164, Validation Accuracy:0.0459
Epoch #140: Loss:2.6685, Accuracy:0.0895 Validation Loss:2.6562, Validation Accuracy:0.1066
Epoch #141: Loss:2.6552, Accuracy:0.1055 Validation Loss:2.6539, Validation Accuracy:0.1049
Epoch #142: Loss:2.6472, Accuracy:0.1071 Validation Loss:2.6489, Validation Accuracy:0.1115
Epoch #143: Loss:2.6433, Accuracy:0.1080 Validation Loss:2.6496, Validation Accuracy:0.1049
Epoch #144: Loss:2.6496, Accuracy:0.1190 Validation Loss:2.6780, Validation Accuracy:0.0820
Epoch #145: Loss:2.6755, Accuracy:0.0940 Validation Loss:2.6262, Validation Accuracy:0.1098
Epoch #146: Loss:2.6356, Accuracy:0.1088 Validation Loss:2.6727, Validation Accuracy:0.0820
Epoch #147: Loss:2.6737, Accuracy:0.0817 Validation Loss:2.6728, Validation Accuracy:0.0820
Epoch #148: Loss:2.6716, Accuracy:0.0813 Validation Loss:2.6685, Validation Accuracy:0.1033
Epoch #149: Loss:2.6673, Accuracy:0.1030 Validation Loss:2.6638, Validation Accuracy:0.1016
Epoch #150: Loss:2.6626, Accuracy:0.1026 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #151: Loss:2.6575, Accuracy:0.1022 Validation Loss:2.6642, Validation Accuracy:0.1016
Epoch #152: Loss:2.6536, Accuracy:0.1022 Validation Loss:2.6620, Validation Accuracy:0.1016
Epoch #153: Loss:2.6634, Accuracy:0.1022 Validation Loss:2.6636, Validation Accuracy:0.1016
Epoch #154: Loss:2.6641, Accuracy:0.1022 Validation Loss:2.6634, Validation Accuracy:0.1016
Epoch #155: Loss:2.6634, Accuracy:0.1022 Validation Loss:2.6623, Validation Accuracy:0.1016
Epoch #156: Loss:2.6624, Accuracy:0.1022 Validation Loss:2.6613, Validation Accuracy:0.1016
Epoch #157: Loss:2.6614, Accuracy:0.1022 Validation Loss:2.6606, Validation Accuracy:0.1016
Epoch #158: Loss:2.6610, Accuracy:0.1022 Validation Loss:2.6602, Validation Accuracy:0.1016
Epoch #159: Loss:2.6607, Accuracy:0.1022 Validation Loss:2.6601, Validation Accuracy:0.1016
Epoch #160: Loss:2.6606, Accuracy:0.1022 Validation Loss:2.6600, Validation Accuracy:0.1016
Epoch #161: Loss:2.6605, Accuracy:0.1022 Validation Loss:2.6598, Validation Accuracy:0.1016
Epoch #162: Loss:2.6603, Accuracy:0.1022 Validation Loss:2.6597, Validation Accuracy:0.1016
Epoch #163: Loss:2.6602, Accuracy:0.1022 Validation Loss:2.6597, Validation Accuracy:0.1016
Epoch #164: Loss:2.6601, Accuracy:0.1022 Validation Loss:2.6596, Validation Accuracy:0.1016
Epoch #165: Loss:2.6601, Accuracy:0.1022 Validation Loss:2.6596, Validation Accuracy:0.1016
Epoch #166: Loss:2.6601, Accuracy:0.1022 Validation Loss:2.6596, Validation Accuracy:0.1016
Epoch #167: Loss:2.6601, Accuracy:0.1022 Validation Loss:2.6596, Validation Accuracy:0.1016
Epoch #168: Loss:2.6600, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #169: Loss:2.6600, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #170: Loss:2.6600, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #171: Loss:2.6600, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #172: Loss:2.6599, Accuracy:0.1022 Validation Loss:2.6595, Validation Accuracy:0.1016
Epoch #173: Loss:2.6599, Accuracy:0.1022 Validation Loss:2.6594, Validation Accuracy:0.1016
Epoch #174: Loss:2.6599, Accuracy:0.1022 Validation Loss:2.6594, Validation Accuracy:0.1016
Epoch #175: Loss:2.6598, Accuracy:0.1022 Validation Loss:2.6594, Validation Accuracy:0.1016
Epoch #176: Loss:2.6599, Accuracy:0.1022 Validation Loss:2.6594, Validation Accuracy:0.1016
Epoch #177: Loss:2.6598, Accuracy:0.1022 Validation Loss:2.6593, Validation Accuracy:0.1016
Epoch #178: Loss:2.6597, Accuracy:0.1022 Validation Loss:2.6593, Validation Accuracy:0.1016
Epoch #179: Loss:2.6597, Accuracy:0.1022 Validation Loss:2.6593, Validation Accuracy:0.1016
Epoch #180: Loss:2.6596, Accuracy:0.1022 Validation Loss:2.6592, Validation Accuracy:0.1016
Epoch #181: Loss:2.6596, Accuracy:0.1022 Validation Loss:2.6592, Validation Accuracy:0.1016
Epoch #182: Loss:2.6595, Accuracy:0.1022 Validation Loss:2.6591, Validation Accuracy:0.1016
Epoch #183: Loss:2.6594, Accuracy:0.1022 Validation Loss:2.6590, Validation Accuracy:0.1016
Epoch #184: Loss:2.6594, Accuracy:0.1022 Validation Loss:2.6589, Validation Accuracy:0.1016
Epoch #185: Loss:2.6592, Accuracy:0.1022 Validation Loss:2.6588, Validation Accuracy:0.1016
Epoch #186: Loss:2.6591, Accuracy:0.1022 Validation Loss:2.6586, Validation Accuracy:0.1016
Epoch #187: Loss:2.6588, Accuracy:0.1022 Validation Loss:2.6583, Validation Accuracy:0.1016
Epoch #188: Loss:2.6581, Accuracy:0.1026 Validation Loss:2.6574, Validation Accuracy:0.1016
Epoch #189: Loss:2.6557, Accuracy:0.1026 Validation Loss:2.6713, Validation Accuracy:0.1016
Epoch #190: Loss:2.6549, Accuracy:0.1026 Validation Loss:2.6553, Validation Accuracy:0.1016
Epoch #191: Loss:2.6457, Accuracy:0.1026 Validation Loss:2.6543, Validation Accuracy:0.1016
Epoch #192: Loss:2.6352, Accuracy:0.1030 Validation Loss:2.6298, Validation Accuracy:0.1016
Epoch #193: Loss:2.6243, Accuracy:0.1055 Validation Loss:2.6295, Validation Accuracy:0.1082
Epoch #194: Loss:2.6179, Accuracy:0.1145 Validation Loss:2.6676, Validation Accuracy:0.1115
Epoch #195: Loss:2.6650, Accuracy:0.1067 Validation Loss:2.6734, Validation Accuracy:0.1082
Epoch #196: Loss:2.6626, Accuracy:0.1092 Validation Loss:2.6597, Validation Accuracy:0.1082
Epoch #197: Loss:2.6433, Accuracy:0.1137 Validation Loss:2.6372, Validation Accuracy:0.1197
Epoch #198: Loss:2.6236, Accuracy:0.1375 Validation Loss:2.6153, Validation Accuracy:0.1377
Epoch #199: Loss:2.6255, Accuracy:0.1289 Validation Loss:2.6533, Validation Accuracy:0.1098
Epoch #200: Loss:2.6504, Accuracy:0.1112 Validation Loss:2.6595, Validation Accuracy:0.1082
Epoch #201: Loss:2.6532, Accuracy:0.1117 Validation Loss:2.6577, Validation Accuracy:0.1082
Epoch #202: Loss:2.6499, Accuracy:0.1112 Validation Loss:2.6537, Validation Accuracy:0.1082
Epoch #203: Loss:2.6437, Accuracy:0.1137 Validation Loss:2.6486, Validation Accuracy:0.1115
Epoch #204: Loss:2.6350, Accuracy:0.1174 Validation Loss:2.6354, Validation Accuracy:0.1230
Epoch #205: Loss:2.6372, Accuracy:0.1154 Validation Loss:2.6418, Validation Accuracy:0.1164
Epoch #206: Loss:2.6366, Accuracy:0.1154 Validation Loss:2.6535, Validation Accuracy:0.1082
Epoch #207: Loss:2.6474, Accuracy:0.1121 Validation Loss:2.6547, Validation Accuracy:0.1082
Epoch #208: Loss:2.6482, Accuracy:0.1117 Validation Loss:2.6522, Validation Accuracy:0.1082
Epoch #209: Loss:2.6417, Accuracy:0.1129 Validation Loss:2.6462, Validation Accuracy:0.1115
Epoch #210: Loss:2.6317, Accuracy:0.1174 Validation Loss:2.6363, Validation Accuracy:0.1180
Epoch #211: Loss:2.6193, Accuracy:0.1252 Validation Loss:2.6278, Validation Accuracy:0.1230
Epoch #212: Loss:2.6325, Accuracy:0.1162 Validation Loss:2.6573, Validation Accuracy:0.1082
Epoch #213: Loss:2.6537, Accuracy:0.1104 Validation Loss:2.6578, Validation Accuracy:0.1082
Epoch #214: Loss:2.6565, Accuracy:0.1088 Validation Loss:2.6563, Validation Accuracy:0.1082
Epoch #215: Loss:2.6550, Accuracy:0.1088 Validation Loss:2.6546, Validation Accuracy:0.1082
Epoch #216: Loss:2.6529, Accuracy:0.1096 Validation Loss:2.6531, Validation Accuracy:0.1082
Epoch #217: Loss:2.6513, Accuracy:0.1100 Validation Loss:2.6515, Validation Accuracy:0.1082
Epoch #218: Loss:2.6495, Accuracy:0.1104 Validation Loss:2.6493, Validation Accuracy:0.1098
Epoch #219: Loss:2.6468, Accuracy:0.1117 Validation Loss:2.6407, Validation Accuracy:0.1098
Epoch #220: Loss:2.6772, Accuracy:0.1034 Validation Loss:2.6864, Validation Accuracy:0.0951
Epoch #221: Loss:2.6793, Accuracy:0.0977 Validation Loss:2.6719, Validation Accuracy:0.1049
Epoch #222: Loss:2.6663, Accuracy:0.1047 Validation Loss:2.6586, Validation Accuracy:0.1164
Epoch #223: Loss:2.6534, Accuracy:0.1174 Validation Loss:2.6510, Validation Accuracy:0.1164
Epoch #224: Loss:2.6441, Accuracy:0.1219 Validation Loss:2.6769, Validation Accuracy:0.1279
Epoch #225: Loss:2.6489, Accuracy:0.1223 Validation Loss:2.6493, Validation Accuracy:0.1131
Epoch #226: Loss:2.6441, Accuracy:0.1162 Validation Loss:2.6485, Validation Accuracy:0.1131
Epoch #227: Loss:2.6409, Accuracy:0.1182 Validation Loss:2.6381, Validation Accuracy:0.1230
Epoch #228: Loss:2.6498, Accuracy:0.1219 Validation Loss:2.6526, Validation Accuracy:0.1082
Epoch #229: Loss:2.6565, Accuracy:0.1076 Validation Loss:2.6537, Validation Accuracy:0.1082
Epoch #230: Loss:2.6587, Accuracy:0.1047 Validation Loss:2.6536, Validation Accuracy:0.1082
Epoch #231: Loss:2.6586, Accuracy:0.1047 Validation Loss:2.6534, Validation Accuracy:0.1082
Epoch #232: Loss:2.6582, Accuracy:0.1051 Validation Loss:2.6531, Validation Accuracy:0.1082
Epoch #233: Loss:2.6577, Accuracy:0.1051 Validation Loss:2.6529, Validation Accuracy:0.1082
Epoch #234: Loss:2.6574, Accuracy:0.1055 Validation Loss:2.6528, Validation Accuracy:0.1082
Epoch #235: Loss:2.6571, Accuracy:0.1055 Validation Loss:2.6526, Validation Accuracy:0.1082
Epoch #236: Loss:2.6568, Accuracy:0.1059 Validation Loss:2.6525, Validation Accuracy:0.1082
Epoch #237: Loss:2.6564, Accuracy:0.1063 Validation Loss:2.6524, Validation Accuracy:0.1082
Epoch #238: Loss:2.6558, Accuracy:0.1071 Validation Loss:2.6519, Validation Accuracy:0.1082
Epoch #239: Loss:2.6551, Accuracy:0.1076 Validation Loss:2.6508, Validation Accuracy:0.1098
Epoch #240: Loss:2.6544, Accuracy:0.1084 Validation Loss:2.6487, Validation Accuracy:0.1115
Epoch #241: Loss:2.6517, Accuracy:0.1117 Validation Loss:2.6375, Validation Accuracy:0.1246
Epoch #242: Loss:2.6453, Accuracy:0.1227 Validation Loss:2.6474, Validation Accuracy:0.1131
Epoch #243: Loss:2.6534, Accuracy:0.1092 Validation Loss:2.6511, Validation Accuracy:0.1082
Epoch #244: Loss:2.6553, Accuracy:0.1071 Validation Loss:2.6519, Validation Accuracy:0.1082
Epoch #245: Loss:2.6559, Accuracy:0.1071 Validation Loss:2.6519, Validation Accuracy:0.1082
Epoch #246: Loss:2.6559, Accuracy:0.1067 Validation Loss:2.6517, Validation Accuracy:0.1082
Epoch #247: Loss:2.6557, Accuracy:0.1071 Validation Loss:2.6515, Validation Accuracy:0.1082
Epoch #248: Loss:2.6552, Accuracy:0.1071 Validation Loss:2.6512, Validation Accuracy:0.1082
Epoch #249: Loss:2.6549, Accuracy:0.1076 Validation Loss:2.6507, Validation Accuracy:0.1082
Epoch #250: Loss:2.6542, Accuracy:0.1084 Validation Loss:2.6498, Validation Accuracy:0.1098
Epoch #251: Loss:2.6538, Accuracy:0.1088 Validation Loss:2.6494, Validation Accuracy:0.1098
Epoch #252: Loss:2.6534, Accuracy:0.1088 Validation Loss:2.6482, Validation Accuracy:0.1115
Epoch #253: Loss:2.6524, Accuracy:0.1096 Validation Loss:2.6464, Validation Accuracy:0.1131
Epoch #254: Loss:2.6497, Accuracy:0.1125 Validation Loss:2.6457, Validation Accuracy:0.1131
Epoch #255: Loss:2.6464, Accuracy:0.1162 Validation Loss:2.6360, Validation Accuracy:0.1230
Epoch #256: Loss:2.6377, Accuracy:0.1248 Validation Loss:2.6379, Validation Accuracy:0.1279
Epoch #257: Loss:2.6363, Accuracy:0.1310 Validation Loss:2.6309, Validation Accuracy:0.1279
Epoch #258: Loss:2.6352, Accuracy:0.1260 Validation Loss:2.6300, Validation Accuracy:0.1262
Epoch #259: Loss:2.6305, Accuracy:0.1285 Validation Loss:2.6276, Validation Accuracy:0.1328
Epoch #260: Loss:2.6264, Accuracy:0.1338 Validation Loss:2.6221, Validation Accuracy:0.1344
Epoch #261: Loss:2.6212, Accuracy:0.1363 Validation Loss:2.6199, Validation Accuracy:0.1311
Epoch #262: Loss:2.6178, Accuracy:0.1371 Validation Loss:2.6186, Validation Accuracy:0.1328
Epoch #263: Loss:2.6162, Accuracy:0.1351 Validation Loss:2.6162, Validation Accuracy:0.1361
Epoch #264: Loss:2.6159, Accuracy:0.1363 Validation Loss:2.6141, Validation Accuracy:0.1311
Epoch #265: Loss:2.6129, Accuracy:0.1338 Validation Loss:2.6147, Validation Accuracy:0.1344
Epoch #266: Loss:2.6067, Accuracy:0.1363 Validation Loss:2.6077, Validation Accuracy:0.1328
Epoch #267: Loss:2.5984, Accuracy:0.1396 Validation Loss:2.6043, Validation Accuracy:0.1328
Epoch #268: Loss:2.5984, Accuracy:0.1367 Validation Loss:2.6044, Validation Accuracy:0.1311
Epoch #269: Loss:2.5943, Accuracy:0.1383 Validation Loss:2.6112, Validation Accuracy:0.1279
Epoch #270: Loss:2.5925, Accuracy:0.1383 Validation Loss:2.6055, Validation Accuracy:0.1295
Epoch #271: Loss:2.5873, Accuracy:0.1392 Validation Loss:2.5957, Validation Accuracy:0.1295
Epoch #272: Loss:2.5814, Accuracy:0.1412 Validation Loss:2.5944, Validation Accuracy:0.1328
Epoch #273: Loss:2.5767, Accuracy:0.1379 Validation Loss:2.5902, Validation Accuracy:0.1295
Epoch #274: Loss:2.5844, Accuracy:0.1363 Validation Loss:2.5948, Validation Accuracy:0.1279
Epoch #275: Loss:2.6217, Accuracy:0.1219 Validation Loss:2.6385, Validation Accuracy:0.1164
Epoch #276: Loss:2.6514, Accuracy:0.1154 Validation Loss:2.6526, Validation Accuracy:0.1131
Epoch #277: Loss:2.6583, Accuracy:0.1112 Validation Loss:2.6526, Validation Accuracy:0.1098
Epoch #278: Loss:2.6569, Accuracy:0.1104 Validation Loss:2.6500, Validation Accuracy:0.1098
Epoch #279: Loss:2.6546, Accuracy:0.1096 Validation Loss:2.6478, Validation Accuracy:0.1098
Epoch #280: Loss:2.6525, Accuracy:0.1096 Validation Loss:2.6460, Validation Accuracy:0.1098
Epoch #281: Loss:2.6502, Accuracy:0.1100 Validation Loss:2.6443, Validation Accuracy:0.1098
Epoch #282: Loss:2.6484, Accuracy:0.1104 Validation Loss:2.6422, Validation Accuracy:0.1115
Epoch #283: Loss:2.6466, Accuracy:0.1108 Validation Loss:2.6398, Validation Accuracy:0.1131
Epoch #284: Loss:2.6434, Accuracy:0.1125 Validation Loss:2.6382, Validation Accuracy:0.1131
Epoch #285: Loss:2.6395, Accuracy:0.1137 Validation Loss:2.6360, Validation Accuracy:0.1131
Epoch #286: Loss:2.6372, Accuracy:0.1149 Validation Loss:2.6311, Validation Accuracy:0.1164
Epoch #287: Loss:2.6329, Accuracy:0.1166 Validation Loss:2.6157, Validation Accuracy:0.1230
Epoch #288: Loss:2.6123, Accuracy:0.1268 Validation Loss:2.5958, Validation Accuracy:0.1295
Epoch #289: Loss:2.5870, Accuracy:0.1359 Validation Loss:2.5853, Validation Accuracy:0.1328
Epoch #290: Loss:2.5752, Accuracy:0.1396 Validation Loss:2.5836, Validation Accuracy:0.1344
Epoch #291: Loss:2.5684, Accuracy:0.1367 Validation Loss:2.5730, Validation Accuracy:0.1311
Epoch #292: Loss:2.5616, Accuracy:0.1396 Validation Loss:2.5802, Validation Accuracy:0.1361
Epoch #293: Loss:2.5614, Accuracy:0.1371 Validation Loss:2.5653, Validation Accuracy:0.1311
Epoch #294: Loss:2.5539, Accuracy:0.1379 Validation Loss:2.5607, Validation Accuracy:0.1344
Epoch #295: Loss:2.5492, Accuracy:0.1379 Validation Loss:2.5639, Validation Accuracy:0.1344
Epoch #296: Loss:2.5458, Accuracy:0.1392 Validation Loss:2.5442, Validation Accuracy:0.1328
Epoch #297: Loss:2.5419, Accuracy:0.1388 Validation Loss:2.5424, Validation Accuracy:0.1344
Epoch #298: Loss:2.5353, Accuracy:0.1379 Validation Loss:2.5373, Validation Accuracy:0.1344
Epoch #299: Loss:2.5415, Accuracy:0.1379 Validation Loss:2.5393, Validation Accuracy:0.1361
Epoch #300: Loss:2.5323, Accuracy:0.1412 Validation Loss:2.5321, Validation Accuracy:0.1311

Test:
Test Loss:2.53214645, Accuracy:0.1311
Labels: ['sg', 'mb', 'eg', 'eb', 'eo', 'yd', 'ds', 'sk', 'ck', 'my', 'by', 'ib', 'ek', 'ce', 'aa']
Confusion Matrix:
[[ 0  0  3  0  2 30  0  0  0  0  0  1  0  0 15]
 [ 0  0  7  0  1 31  0  0  0  0  0  2  0  0 11]
 [ 0  0  0  0  0 35  0  0  0  0  0  0  0  0 15]
 [ 0  0  0  0  0 49  0  0  0  0  0  1  0  0  1]
 [ 0  0  0  0  0  2  0  0  0  0  0  0  0  0 32]
 [ 0  0  0  0  0 57  0  0  0  0  0  2  0  0  3]
 [ 0  0  0  0  0 28  0  0  0  0  0  1  0  0  2]
 [ 0  0  0  0  0 30  0  0  0  0  0  0  0  0  3]
 [ 0  0  0  0  0 21  0  0  0  0  0  0  0  0  2]
 [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  1 14  0  0  0  0  0  2  0  0 23]
 [ 0  0  4  0  2 40  0  0  0  0  0  0  0  0  8]
 [ 0  0  0  0  0 46  0  0  0  0  0  0  0  0  2]
 [ 0  0  0  0  1 20  0  0  0  0  0  0  0  0  6]
 [ 0  0  2  0  0  9  0  0  0  0  0  0  0  0 23]]
Classification Report:
              precision    recall  f1-score   support

          sg       0.00      0.00      0.00        51
          mb       0.00      0.00      0.00        52
          eg       0.00      0.00      0.00        50
          eb       0.00      0.00      0.00        51
          eo       0.00      0.00      0.00        34
          yd       0.13      0.92      0.23        62
          ds       0.00      0.00      0.00        31
          sk       0.00      0.00      0.00        33
          ck       0.00      0.00      0.00        23
          my       0.00      0.00      0.00        20
          by       0.00      0.00      0.00        40
          ib       0.00      0.00      0.00        54
          ek       0.00      0.00      0.00        48
          ce       0.00      0.00      0.00        27
          aa       0.16      0.68      0.26        34

    accuracy                           0.13       610
   macro avg       0.02      0.11      0.03       610
weighted avg       0.02      0.13      0.04       610

============ Config: 1/1 === End Time: 2019.07.24 00:37:11 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 57 minutes, 47 seconds =====================


======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf42.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.24 04:25:51 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nFreqs', 'channelMode': '0Ov', 'classificationMode': 'Posture', 'trainingEpoch': 300, 'stepSize': 6, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 5 Label(s): ['01', '05', '03', '04', '02'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 5 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for nFreqs------
---LSTM Classifier---
Train Batch: (2436, 7989, 36)
Test Batch: (610, 7989, 36)
Optimizer: <keras.optimizers.Adam object at 0x000002B1105829B0>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000002B10F2F6AE8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 65        
=================================================================
Total params: 22,697
Trainable params: 22,697
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.6125, Accuracy:0.1925 Validation Loss:1.6095, Validation Accuracy:0.2295
Epoch #2: Loss:1.6080, Accuracy:0.2328 Validation Loss:1.6061, Validation Accuracy:0.2328
Epoch #3: Loss:1.6051, Accuracy:0.2332 Validation Loss:1.6065, Validation Accuracy:0.2311
Epoch #4: Loss:1.6050, Accuracy:0.2323 Validation Loss:1.6068, Validation Accuracy:0.2295
Epoch #5: Loss:1.6048, Accuracy:0.2348 Validation Loss:1.6073, Validation Accuracy:0.2213
Epoch #6: Loss:1.6047, Accuracy:0.2332 Validation Loss:1.6073, Validation Accuracy:0.2311
Epoch #7: Loss:1.6044, Accuracy:0.2319 Validation Loss:1.6070, Validation Accuracy:0.2311
Epoch #8: Loss:1.6039, Accuracy:0.2299 Validation Loss:1.6074, Validation Accuracy:0.2246
Epoch #9: Loss:1.6035, Accuracy:0.2332 Validation Loss:1.6077, Validation Accuracy:0.2197
Epoch #10: Loss:1.6035, Accuracy:0.2295 Validation Loss:1.6078, Validation Accuracy:0.2066
Epoch #11: Loss:1.6029, Accuracy:0.2365 Validation Loss:1.6078, Validation Accuracy:0.2246
Epoch #12: Loss:1.6031, Accuracy:0.2352 Validation Loss:1.6076, Validation Accuracy:0.2311
Epoch #13: Loss:1.6036, Accuracy:0.2340 Validation Loss:1.6071, Validation Accuracy:0.2328
Epoch #14: Loss:1.6028, Accuracy:0.2365 Validation Loss:1.6077, Validation Accuracy:0.2180
Epoch #15: Loss:1.6025, Accuracy:0.2381 Validation Loss:1.6079, Validation Accuracy:0.2213
Epoch #16: Loss:1.6021, Accuracy:0.2447 Validation Loss:1.6072, Validation Accuracy:0.2328
Epoch #17: Loss:1.6024, Accuracy:0.2438 Validation Loss:1.6063, Validation Accuracy:0.2393
Epoch #18: Loss:1.6048, Accuracy:0.2360 Validation Loss:1.6085, Validation Accuracy:0.2311
Epoch #19: Loss:1.6042, Accuracy:0.2348 Validation Loss:1.6067, Validation Accuracy:0.2000
Epoch #20: Loss:1.6029, Accuracy:0.2250 Validation Loss:1.6082, Validation Accuracy:0.1902
Epoch #21: Loss:1.6033, Accuracy:0.2348 Validation Loss:1.6072, Validation Accuracy:0.2164
Epoch #22: Loss:1.6024, Accuracy:0.2406 Validation Loss:1.6072, Validation Accuracy:0.2246
Epoch #23: Loss:1.6024, Accuracy:0.2443 Validation Loss:1.6075, Validation Accuracy:0.2426
Epoch #24: Loss:1.6019, Accuracy:0.2459 Validation Loss:1.6081, Validation Accuracy:0.2295
Epoch #25: Loss:1.6016, Accuracy:0.2414 Validation Loss:1.6085, Validation Accuracy:0.2213
Epoch #26: Loss:1.6015, Accuracy:0.2438 Validation Loss:1.6087, Validation Accuracy:0.2230
Epoch #27: Loss:1.6015, Accuracy:0.2434 Validation Loss:1.6090, Validation Accuracy:0.2197
Epoch #28: Loss:1.6014, Accuracy:0.2422 Validation Loss:1.6094, Validation Accuracy:0.2230
Epoch #29: Loss:1.6009, Accuracy:0.2438 Validation Loss:1.6088, Validation Accuracy:0.2279
Epoch #30: Loss:1.6013, Accuracy:0.2447 Validation Loss:1.6089, Validation Accuracy:0.2295
Epoch #31: Loss:1.6009, Accuracy:0.2455 Validation Loss:1.6094, Validation Accuracy:0.2016
Epoch #32: Loss:1.6009, Accuracy:0.2434 Validation Loss:1.6089, Validation Accuracy:0.2197
Epoch #33: Loss:1.6007, Accuracy:0.2459 Validation Loss:1.6088, Validation Accuracy:0.2180
Epoch #34: Loss:1.6004, Accuracy:0.2463 Validation Loss:1.6081, Validation Accuracy:0.2279
Epoch #35: Loss:1.6003, Accuracy:0.2467 Validation Loss:1.6081, Validation Accuracy:0.2279
Epoch #36: Loss:1.6001, Accuracy:0.2479 Validation Loss:1.6074, Validation Accuracy:0.2246
Epoch #37: Loss:1.5999, Accuracy:0.2434 Validation Loss:1.6091, Validation Accuracy:0.2164
Epoch #38: Loss:1.6000, Accuracy:0.2455 Validation Loss:1.6093, Validation Accuracy:0.2164
Epoch #39: Loss:1.5999, Accuracy:0.2438 Validation Loss:1.6089, Validation Accuracy:0.2230
Epoch #40: Loss:1.5999, Accuracy:0.2447 Validation Loss:1.6085, Validation Accuracy:0.2213
Epoch #41: Loss:1.5998, Accuracy:0.2438 Validation Loss:1.6083, Validation Accuracy:0.2279
Epoch #42: Loss:1.6003, Accuracy:0.2479 Validation Loss:1.6082, Validation Accuracy:0.2295
Epoch #43: Loss:1.5999, Accuracy:0.2434 Validation Loss:1.6094, Validation Accuracy:0.2066
Epoch #44: Loss:1.5996, Accuracy:0.2414 Validation Loss:1.6082, Validation Accuracy:0.2328
Epoch #45: Loss:1.5994, Accuracy:0.2430 Validation Loss:1.6067, Validation Accuracy:0.2262
Epoch #46: Loss:1.6003, Accuracy:0.2438 Validation Loss:1.6080, Validation Accuracy:0.2148
Epoch #47: Loss:1.6002, Accuracy:0.2401 Validation Loss:1.6070, Validation Accuracy:0.2361
Epoch #48: Loss:1.6006, Accuracy:0.2434 Validation Loss:1.6075, Validation Accuracy:0.2180
Epoch #49: Loss:1.6001, Accuracy:0.2430 Validation Loss:1.6058, Validation Accuracy:0.2361
Epoch #50: Loss:1.5996, Accuracy:0.2455 Validation Loss:1.6060, Validation Accuracy:0.2262
Epoch #51: Loss:1.5992, Accuracy:0.2434 Validation Loss:1.6062, Validation Accuracy:0.2246
Epoch #52: Loss:1.5994, Accuracy:0.2438 Validation Loss:1.6060, Validation Accuracy:0.2311
Epoch #53: Loss:1.5994, Accuracy:0.2488 Validation Loss:1.6067, Validation Accuracy:0.2115
Epoch #54: Loss:1.5989, Accuracy:0.2406 Validation Loss:1.6060, Validation Accuracy:0.2230
Epoch #55: Loss:1.5990, Accuracy:0.2410 Validation Loss:1.6055, Validation Accuracy:0.2262
Epoch #56: Loss:1.5997, Accuracy:0.2418 Validation Loss:1.6060, Validation Accuracy:0.2180
Epoch #57: Loss:1.6001, Accuracy:0.2434 Validation Loss:1.6054, Validation Accuracy:0.2148
Epoch #58: Loss:1.6001, Accuracy:0.2447 Validation Loss:1.6050, Validation Accuracy:0.2295
Epoch #59: Loss:1.6006, Accuracy:0.2430 Validation Loss:1.6047, Validation Accuracy:0.2246
Epoch #60: Loss:1.6004, Accuracy:0.2447 Validation Loss:1.6047, Validation Accuracy:0.2180
Epoch #61: Loss:1.6002, Accuracy:0.2406 Validation Loss:1.6051, Validation Accuracy:0.2230
Epoch #62: Loss:1.5998, Accuracy:0.2434 Validation Loss:1.6052, Validation Accuracy:0.2328
Epoch #63: Loss:1.5999, Accuracy:0.2443 Validation Loss:1.6056, Validation Accuracy:0.2262
Epoch #64: Loss:1.6004, Accuracy:0.2459 Validation Loss:1.6061, Validation Accuracy:0.2180
Epoch #65: Loss:1.6001, Accuracy:0.2484 Validation Loss:1.6052, Validation Accuracy:0.2344
Epoch #66: Loss:1.6001, Accuracy:0.2410 Validation Loss:1.6046, Validation Accuracy:0.2213
Epoch #67: Loss:1.5993, Accuracy:0.2426 Validation Loss:1.6050, Validation Accuracy:0.2131
Epoch #68: Loss:1.5998, Accuracy:0.2422 Validation Loss:1.6061, Validation Accuracy:0.2115
Epoch #69: Loss:1.6000, Accuracy:0.2418 Validation Loss:1.6064, Validation Accuracy:0.2262
Epoch #70: Loss:1.6014, Accuracy:0.2443 Validation Loss:1.6079, Validation Accuracy:0.2262
Epoch #71: Loss:1.6003, Accuracy:0.2438 Validation Loss:1.6083, Validation Accuracy:0.2082
Epoch #72: Loss:1.6006, Accuracy:0.2377 Validation Loss:1.6076, Validation Accuracy:0.2230
Epoch #73: Loss:1.6002, Accuracy:0.2463 Validation Loss:1.6075, Validation Accuracy:0.2246
Epoch #74: Loss:1.6006, Accuracy:0.2438 Validation Loss:1.6071, Validation Accuracy:0.2295
Epoch #75: Loss:1.6005, Accuracy:0.2471 Validation Loss:1.6077, Validation Accuracy:0.2180
Epoch #76: Loss:1.6003, Accuracy:0.2414 Validation Loss:1.6081, Validation Accuracy:0.2082
Epoch #77: Loss:1.6000, Accuracy:0.2447 Validation Loss:1.6070, Validation Accuracy:0.2230
Epoch #78: Loss:1.5992, Accuracy:0.2467 Validation Loss:1.6074, Validation Accuracy:0.2197
Epoch #79: Loss:1.5994, Accuracy:0.2463 Validation Loss:1.6078, Validation Accuracy:0.2213
Epoch #80: Loss:1.5997, Accuracy:0.2410 Validation Loss:1.6091, Validation Accuracy:0.1951
Epoch #81: Loss:1.6006, Accuracy:0.2385 Validation Loss:1.6071, Validation Accuracy:0.2197
Epoch #82: Loss:1.6016, Accuracy:0.2385 Validation Loss:1.6086, Validation Accuracy:0.2213
Epoch #83: Loss:1.5999, Accuracy:0.2434 Validation Loss:1.6094, Validation Accuracy:0.2246
Epoch #84: Loss:1.5995, Accuracy:0.2434 Validation Loss:1.6085, Validation Accuracy:0.2246
Epoch #85: Loss:1.5991, Accuracy:0.2447 Validation Loss:1.6074, Validation Accuracy:0.2230
Epoch #86: Loss:1.5991, Accuracy:0.2430 Validation Loss:1.6076, Validation Accuracy:0.2115
Epoch #87: Loss:1.5997, Accuracy:0.2389 Validation Loss:1.6128, Validation Accuracy:0.2066
Epoch #88: Loss:1.6023, Accuracy:0.2352 Validation Loss:1.6098, Validation Accuracy:0.2213
Epoch #89: Loss:1.6010, Accuracy:0.2438 Validation Loss:1.6083, Validation Accuracy:0.2262
Epoch #90: Loss:1.6008, Accuracy:0.2434 Validation Loss:1.6083, Validation Accuracy:0.2246
Epoch #91: Loss:1.6000, Accuracy:0.2447 Validation Loss:1.6076, Validation Accuracy:0.2230
Epoch #92: Loss:1.5998, Accuracy:0.2455 Validation Loss:1.6073, Validation Accuracy:0.2230
Epoch #93: Loss:1.5997, Accuracy:0.2451 Validation Loss:1.6069, Validation Accuracy:0.2230
Epoch #94: Loss:1.5995, Accuracy:0.2447 Validation Loss:1.6064, Validation Accuracy:0.2230
Epoch #95: Loss:1.6002, Accuracy:0.2455 Validation Loss:1.6085, Validation Accuracy:0.2230
Epoch #96: Loss:1.5995, Accuracy:0.2455 Validation Loss:1.6074, Validation Accuracy:0.2230
Epoch #97: Loss:1.5993, Accuracy:0.2455 Validation Loss:1.6070, Validation Accuracy:0.2246
Epoch #98: Loss:1.5994, Accuracy:0.2430 Validation Loss:1.6067, Validation Accuracy:0.2230
Epoch #99: Loss:1.5989, Accuracy:0.2451 Validation Loss:1.6073, Validation Accuracy:0.2246
Epoch #100: Loss:1.5988, Accuracy:0.2455 Validation Loss:1.6077, Validation Accuracy:0.2246
Epoch #101: Loss:1.5986, Accuracy:0.2455 Validation Loss:1.6070, Validation Accuracy:0.2246
Epoch #102: Loss:1.5989, Accuracy:0.2463 Validation Loss:1.6070, Validation Accuracy:0.2230
Epoch #103: Loss:1.5982, Accuracy:0.2467 Validation Loss:1.6073, Validation Accuracy:0.2246
Epoch #104: Loss:1.5983, Accuracy:0.2467 Validation Loss:1.6078, Validation Accuracy:0.2230
Epoch #105: Loss:1.5978, Accuracy:0.2455 Validation Loss:1.6069, Validation Accuracy:0.2246
Epoch #106: Loss:1.5980, Accuracy:0.2471 Validation Loss:1.6062, Validation Accuracy:0.2262
Epoch #107: Loss:1.5978, Accuracy:0.2471 Validation Loss:1.6054, Validation Accuracy:0.2328
Epoch #108: Loss:1.5975, Accuracy:0.2459 Validation Loss:1.6061, Validation Accuracy:0.2230
Epoch #109: Loss:1.5976, Accuracy:0.2455 Validation Loss:1.6061, Validation Accuracy:0.2230
Epoch #110: Loss:1.5977, Accuracy:0.2438 Validation Loss:1.6049, Validation Accuracy:0.2328
Epoch #111: Loss:1.5972, Accuracy:0.2463 Validation Loss:1.6046, Validation Accuracy:0.2262
Epoch #112: Loss:1.5967, Accuracy:0.2447 Validation Loss:1.6062, Validation Accuracy:0.2213
Epoch #113: Loss:1.5973, Accuracy:0.2459 Validation Loss:1.6058, Validation Accuracy:0.2230
Epoch #114: Loss:1.5973, Accuracy:0.2455 Validation Loss:1.6056, Validation Accuracy:0.2311
Epoch #115: Loss:1.5968, Accuracy:0.2447 Validation Loss:1.6060, Validation Accuracy:0.2230
Epoch #116: Loss:1.5977, Accuracy:0.2443 Validation Loss:1.6067, Validation Accuracy:0.2230
Epoch #117: Loss:1.5969, Accuracy:0.2438 Validation Loss:1.6063, Validation Accuracy:0.2295
Epoch #118: Loss:1.5970, Accuracy:0.2443 Validation Loss:1.6063, Validation Accuracy:0.2230
Epoch #119: Loss:1.5966, Accuracy:0.2455 Validation Loss:1.6070, Validation Accuracy:0.2230
Epoch #120: Loss:1.5967, Accuracy:0.2451 Validation Loss:1.6066, Validation Accuracy:0.2230
Epoch #121: Loss:1.5965, Accuracy:0.2455 Validation Loss:1.6060, Validation Accuracy:0.2344
Epoch #122: Loss:1.5967, Accuracy:0.2475 Validation Loss:1.6060, Validation Accuracy:0.2230
Epoch #123: Loss:1.5966, Accuracy:0.2463 Validation Loss:1.6060, Validation Accuracy:0.2230
Epoch #124: Loss:1.5963, Accuracy:0.2455 Validation Loss:1.6060, Validation Accuracy:0.2344
Epoch #125: Loss:1.5962, Accuracy:0.2463 Validation Loss:1.6059, Validation Accuracy:0.2311
Epoch #126: Loss:1.5963, Accuracy:0.2422 Validation Loss:1.6064, Validation Accuracy:0.2115
Epoch #127: Loss:1.5970, Accuracy:0.2422 Validation Loss:1.6062, Validation Accuracy:0.2328
Epoch #128: Loss:1.5959, Accuracy:0.2475 Validation Loss:1.6068, Validation Accuracy:0.2230
Epoch #129: Loss:1.5960, Accuracy:0.2488 Validation Loss:1.6070, Validation Accuracy:0.2246
Epoch #130: Loss:1.5957, Accuracy:0.2451 Validation Loss:1.6067, Validation Accuracy:0.2230
Epoch #131: Loss:1.5956, Accuracy:0.2451 Validation Loss:1.6066, Validation Accuracy:0.2230
Epoch #132: Loss:1.5966, Accuracy:0.2463 Validation Loss:1.6066, Validation Accuracy:0.2311
Epoch #133: Loss:1.5952, Accuracy:0.2463 Validation Loss:1.6067, Validation Accuracy:0.2148
Epoch #134: Loss:1.5965, Accuracy:0.2369 Validation Loss:1.6060, Validation Accuracy:0.2164
Epoch #135: Loss:1.5954, Accuracy:0.2401 Validation Loss:1.6063, Validation Accuracy:0.2279
Epoch #136: Loss:1.5957, Accuracy:0.2479 Validation Loss:1.6067, Validation Accuracy:0.2311
Epoch #137: Loss:1.5960, Accuracy:0.2467 Validation Loss:1.6067, Validation Accuracy:0.2295
Epoch #138: Loss:1.5958, Accuracy:0.2463 Validation Loss:1.6069, Validation Accuracy:0.2279
Epoch #139: Loss:1.5960, Accuracy:0.2414 Validation Loss:1.6076, Validation Accuracy:0.2180
Epoch #140: Loss:1.5963, Accuracy:0.2438 Validation Loss:1.6067, Validation Accuracy:0.2295
Epoch #141: Loss:1.5955, Accuracy:0.2463 Validation Loss:1.6074, Validation Accuracy:0.2295
Epoch #142: Loss:1.5961, Accuracy:0.2406 Validation Loss:1.6069, Validation Accuracy:0.2213
Epoch #143: Loss:1.5961, Accuracy:0.2479 Validation Loss:1.6062, Validation Accuracy:0.2295
Epoch #144: Loss:1.5959, Accuracy:0.2467 Validation Loss:1.6052, Validation Accuracy:0.2295
Epoch #145: Loss:1.5961, Accuracy:0.2463 Validation Loss:1.6055, Validation Accuracy:0.2279
Epoch #146: Loss:1.5962, Accuracy:0.2443 Validation Loss:1.6046, Validation Accuracy:0.2295
Epoch #147: Loss:1.5959, Accuracy:0.2467 Validation Loss:1.6047, Validation Accuracy:0.2295
Epoch #148: Loss:1.5961, Accuracy:0.2471 Validation Loss:1.6043, Validation Accuracy:0.2295
Epoch #149: Loss:1.5956, Accuracy:0.2471 Validation Loss:1.6047, Validation Accuracy:0.2295
Epoch #150: Loss:1.5964, Accuracy:0.2475 Validation Loss:1.6044, Validation Accuracy:0.2295
Epoch #151: Loss:1.5957, Accuracy:0.2484 Validation Loss:1.6056, Validation Accuracy:0.2295
Epoch #152: Loss:1.5963, Accuracy:0.2471 Validation Loss:1.6060, Validation Accuracy:0.2262
Epoch #153: Loss:1.5955, Accuracy:0.2488 Validation Loss:1.6055, Validation Accuracy:0.2295
Epoch #154: Loss:1.5956, Accuracy:0.2467 Validation Loss:1.6050, Validation Accuracy:0.2295
Epoch #155: Loss:1.5956, Accuracy:0.2492 Validation Loss:1.6054, Validation Accuracy:0.2295
Epoch #156: Loss:1.5956, Accuracy:0.2471 Validation Loss:1.6052, Validation Accuracy:0.2279
Epoch #157: Loss:1.5955, Accuracy:0.2463 Validation Loss:1.6057, Validation Accuracy:0.2311
Epoch #158: Loss:1.5958, Accuracy:0.2467 Validation Loss:1.6063, Validation Accuracy:0.2295
Epoch #159: Loss:1.5963, Accuracy:0.2406 Validation Loss:1.6066, Validation Accuracy:0.2279
Epoch #160: Loss:1.5961, Accuracy:0.2467 Validation Loss:1.6067, Validation Accuracy:0.2295
Epoch #161: Loss:1.5962, Accuracy:0.2471 Validation Loss:1.6060, Validation Accuracy:0.2295
Epoch #162: Loss:1.5965, Accuracy:0.2467 Validation Loss:1.6053, Validation Accuracy:0.2328
Epoch #163: Loss:1.5967, Accuracy:0.2455 Validation Loss:1.6057, Validation Accuracy:0.2328
Epoch #164: Loss:1.5975, Accuracy:0.2434 Validation Loss:1.6065, Validation Accuracy:0.2148
Epoch #165: Loss:1.5966, Accuracy:0.2488 Validation Loss:1.6058, Validation Accuracy:0.2377
Epoch #166: Loss:1.5968, Accuracy:0.2443 Validation Loss:1.6061, Validation Accuracy:0.2344
Epoch #167: Loss:1.5969, Accuracy:0.2459 Validation Loss:1.6065, Validation Accuracy:0.2279
Epoch #168: Loss:1.5970, Accuracy:0.2443 Validation Loss:1.6060, Validation Accuracy:0.2295
Epoch #169: Loss:1.5966, Accuracy:0.2459 Validation Loss:1.6062, Validation Accuracy:0.2213
Epoch #170: Loss:1.5965, Accuracy:0.2463 Validation Loss:1.6058, Validation Accuracy:0.2295
Epoch #171: Loss:1.5966, Accuracy:0.2430 Validation Loss:1.6057, Validation Accuracy:0.2295
Epoch #172: Loss:1.5963, Accuracy:0.2426 Validation Loss:1.6056, Validation Accuracy:0.2295
Epoch #173: Loss:1.5963, Accuracy:0.2434 Validation Loss:1.6055, Validation Accuracy:0.2295
Epoch #174: Loss:1.5964, Accuracy:0.2455 Validation Loss:1.6053, Validation Accuracy:0.2311
Epoch #175: Loss:1.5962, Accuracy:0.2438 Validation Loss:1.6057, Validation Accuracy:0.2213
Epoch #176: Loss:1.5964, Accuracy:0.2467 Validation Loss:1.6054, Validation Accuracy:0.2213
Epoch #177: Loss:1.5971, Accuracy:0.2418 Validation Loss:1.6049, Validation Accuracy:0.2344
Epoch #178: Loss:1.5967, Accuracy:0.2447 Validation Loss:1.6058, Validation Accuracy:0.2262
Epoch #179: Loss:1.5960, Accuracy:0.2455 Validation Loss:1.6052, Validation Accuracy:0.2344
Epoch #180: Loss:1.5967, Accuracy:0.2430 Validation Loss:1.6053, Validation Accuracy:0.2295
Epoch #181: Loss:1.5963, Accuracy:0.2467 Validation Loss:1.6050, Validation Accuracy:0.2311
Epoch #182: Loss:1.5963, Accuracy:0.2434 Validation Loss:1.6052, Validation Accuracy:0.2361
Epoch #183: Loss:1.5963, Accuracy:0.2447 Validation Loss:1.6045, Validation Accuracy:0.2361
Epoch #184: Loss:1.5962, Accuracy:0.2471 Validation Loss:1.6064, Validation Accuracy:0.2246
Epoch #185: Loss:1.5961, Accuracy:0.2488 Validation Loss:1.6054, Validation Accuracy:0.2328
Epoch #186: Loss:1.5958, Accuracy:0.2484 Validation Loss:1.6055, Validation Accuracy:0.2344
Epoch #187: Loss:1.5959, Accuracy:0.2463 Validation Loss:1.6048, Validation Accuracy:0.2377
Epoch #188: Loss:1.5958, Accuracy:0.2488 Validation Loss:1.6049, Validation Accuracy:0.2344
Epoch #189: Loss:1.5957, Accuracy:0.2471 Validation Loss:1.6049, Validation Accuracy:0.2328
Epoch #190: Loss:1.5956, Accuracy:0.2475 Validation Loss:1.6049, Validation Accuracy:0.2393
Epoch #191: Loss:1.5961, Accuracy:0.2492 Validation Loss:1.6054, Validation Accuracy:0.2393
Epoch #192: Loss:1.5966, Accuracy:0.2430 Validation Loss:1.6054, Validation Accuracy:0.2361
Epoch #193: Loss:1.5957, Accuracy:0.2455 Validation Loss:1.6061, Validation Accuracy:0.2246
Epoch #194: Loss:1.5957, Accuracy:0.2492 Validation Loss:1.6052, Validation Accuracy:0.2377
Epoch #195: Loss:1.5955, Accuracy:0.2434 Validation Loss:1.6051, Validation Accuracy:0.2344
Epoch #196: Loss:1.5951, Accuracy:0.2492 Validation Loss:1.6048, Validation Accuracy:0.2377
Epoch #197: Loss:1.5954, Accuracy:0.2492 Validation Loss:1.6049, Validation Accuracy:0.2393
Epoch #198: Loss:1.5956, Accuracy:0.2479 Validation Loss:1.6046, Validation Accuracy:0.2393
Epoch #199: Loss:1.5952, Accuracy:0.2488 Validation Loss:1.6051, Validation Accuracy:0.2246
Epoch #200: Loss:1.5952, Accuracy:0.2500 Validation Loss:1.6050, Validation Accuracy:0.2393
Epoch #201: Loss:1.5978, Accuracy:0.2426 Validation Loss:1.6056, Validation Accuracy:0.2344
Epoch #202: Loss:1.5947, Accuracy:0.2500 Validation Loss:1.6083, Validation Accuracy:0.2098
Epoch #203: Loss:1.5963, Accuracy:0.2377 Validation Loss:1.6053, Validation Accuracy:0.2344
Epoch #204: Loss:1.5962, Accuracy:0.2467 Validation Loss:1.6056, Validation Accuracy:0.2344
Epoch #205: Loss:1.5952, Accuracy:0.2479 Validation Loss:1.6058, Validation Accuracy:0.2246
Epoch #206: Loss:1.5955, Accuracy:0.2496 Validation Loss:1.6051, Validation Accuracy:0.2393
Epoch #207: Loss:1.5957, Accuracy:0.2471 Validation Loss:1.6059, Validation Accuracy:0.2361
Epoch #208: Loss:1.5958, Accuracy:0.2451 Validation Loss:1.6065, Validation Accuracy:0.2262
Epoch #209: Loss:1.5952, Accuracy:0.2484 Validation Loss:1.6058, Validation Accuracy:0.2295
Epoch #210: Loss:1.5948, Accuracy:0.2451 Validation Loss:1.6060, Validation Accuracy:0.2344
Epoch #211: Loss:1.5954, Accuracy:0.2492 Validation Loss:1.6050, Validation Accuracy:0.2393
Epoch #212: Loss:1.5946, Accuracy:0.2479 Validation Loss:1.6050, Validation Accuracy:0.2393
Epoch #213: Loss:1.5949, Accuracy:0.2500 Validation Loss:1.6051, Validation Accuracy:0.2295
Epoch #214: Loss:1.5951, Accuracy:0.2496 Validation Loss:1.6050, Validation Accuracy:0.2344
Epoch #215: Loss:1.5955, Accuracy:0.2463 Validation Loss:1.6066, Validation Accuracy:0.2393
Epoch #216: Loss:1.5945, Accuracy:0.2475 Validation Loss:1.6062, Validation Accuracy:0.2311
Epoch #217: Loss:1.5944, Accuracy:0.2508 Validation Loss:1.6056, Validation Accuracy:0.2311
Epoch #218: Loss:1.5944, Accuracy:0.2488 Validation Loss:1.6051, Validation Accuracy:0.2393
Epoch #219: Loss:1.5957, Accuracy:0.2484 Validation Loss:1.6058, Validation Accuracy:0.2361
Epoch #220: Loss:1.5948, Accuracy:0.2521 Validation Loss:1.6063, Validation Accuracy:0.2377
Epoch #221: Loss:1.5953, Accuracy:0.2529 Validation Loss:1.6057, Validation Accuracy:0.2393
Epoch #222: Loss:1.5943, Accuracy:0.2475 Validation Loss:1.6054, Validation Accuracy:0.2393
Epoch #223: Loss:1.5947, Accuracy:0.2512 Validation Loss:1.6052, Validation Accuracy:0.2393
Epoch #224: Loss:1.5942, Accuracy:0.2500 Validation Loss:1.6053, Validation Accuracy:0.2393
Epoch #225: Loss:1.5943, Accuracy:0.2492 Validation Loss:1.6053, Validation Accuracy:0.2393
Epoch #226: Loss:1.5940, Accuracy:0.2475 Validation Loss:1.6055, Validation Accuracy:0.2311
Epoch #227: Loss:1.5942, Accuracy:0.2508 Validation Loss:1.6055, Validation Accuracy:0.2393
Epoch #228: Loss:1.5943, Accuracy:0.2496 Validation Loss:1.6055, Validation Accuracy:0.2393
Epoch #229: Loss:1.5941, Accuracy:0.2496 Validation Loss:1.6063, Validation Accuracy:0.2443
Epoch #230: Loss:1.5950, Accuracy:0.2512 Validation Loss:1.6055, Validation Accuracy:0.2328
Epoch #231: Loss:1.5946, Accuracy:0.2512 Validation Loss:1.6053, Validation Accuracy:0.2393
Epoch #232: Loss:1.5940, Accuracy:0.2492 Validation Loss:1.6059, Validation Accuracy:0.2311
Epoch #233: Loss:1.5943, Accuracy:0.2541 Validation Loss:1.6069, Validation Accuracy:0.2443
Epoch #234: Loss:1.5956, Accuracy:0.2492 Validation Loss:1.6067, Validation Accuracy:0.2410
Epoch #235: Loss:1.5943, Accuracy:0.2529 Validation Loss:1.6076, Validation Accuracy:0.2377
Epoch #236: Loss:1.5943, Accuracy:0.2484 Validation Loss:1.6066, Validation Accuracy:0.2393
Epoch #237: Loss:1.5946, Accuracy:0.2475 Validation Loss:1.6062, Validation Accuracy:0.2311
Epoch #238: Loss:1.5937, Accuracy:0.2533 Validation Loss:1.6065, Validation Accuracy:0.2328
Epoch #239: Loss:1.5939, Accuracy:0.2496 Validation Loss:1.6063, Validation Accuracy:0.2459
Epoch #240: Loss:1.5938, Accuracy:0.2533 Validation Loss:1.6057, Validation Accuracy:0.2410
Epoch #241: Loss:1.5935, Accuracy:0.2508 Validation Loss:1.6055, Validation Accuracy:0.2328
Epoch #242: Loss:1.5939, Accuracy:0.2529 Validation Loss:1.6057, Validation Accuracy:0.2328
Epoch #243: Loss:1.5947, Accuracy:0.2508 Validation Loss:1.6069, Validation Accuracy:0.2393
Epoch #244: Loss:1.5947, Accuracy:0.2463 Validation Loss:1.6083, Validation Accuracy:0.2328
Epoch #245: Loss:1.5944, Accuracy:0.2537 Validation Loss:1.6065, Validation Accuracy:0.2410
Epoch #246: Loss:1.5941, Accuracy:0.2508 Validation Loss:1.6055, Validation Accuracy:0.2410
Epoch #247: Loss:1.5935, Accuracy:0.2512 Validation Loss:1.6060, Validation Accuracy:0.2410
Epoch #248: Loss:1.5933, Accuracy:0.2492 Validation Loss:1.6065, Validation Accuracy:0.2328
Epoch #249: Loss:1.5933, Accuracy:0.2525 Validation Loss:1.6073, Validation Accuracy:0.2328
Epoch #250: Loss:1.5934, Accuracy:0.2508 Validation Loss:1.6062, Validation Accuracy:0.2328
Epoch #251: Loss:1.5932, Accuracy:0.2525 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #252: Loss:1.5931, Accuracy:0.2512 Validation Loss:1.6065, Validation Accuracy:0.2410
Epoch #253: Loss:1.5934, Accuracy:0.2475 Validation Loss:1.6065, Validation Accuracy:0.2426
Epoch #254: Loss:1.5934, Accuracy:0.2479 Validation Loss:1.6065, Validation Accuracy:0.2410
Epoch #255: Loss:1.5934, Accuracy:0.2471 Validation Loss:1.6067, Validation Accuracy:0.2328
Epoch #256: Loss:1.5936, Accuracy:0.2578 Validation Loss:1.6077, Validation Accuracy:0.2328
Epoch #257: Loss:1.5936, Accuracy:0.2463 Validation Loss:1.6075, Validation Accuracy:0.2443
Epoch #258: Loss:1.5934, Accuracy:0.2533 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #259: Loss:1.5934, Accuracy:0.2566 Validation Loss:1.6076, Validation Accuracy:0.2426
Epoch #260: Loss:1.5932, Accuracy:0.2541 Validation Loss:1.6082, Validation Accuracy:0.2410
Epoch #261: Loss:1.5944, Accuracy:0.2529 Validation Loss:1.6075, Validation Accuracy:0.2393
Epoch #262: Loss:1.5930, Accuracy:0.2471 Validation Loss:1.6068, Validation Accuracy:0.2377
Epoch #263: Loss:1.5940, Accuracy:0.2475 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #264: Loss:1.5931, Accuracy:0.2512 Validation Loss:1.6066, Validation Accuracy:0.2328
Epoch #265: Loss:1.5929, Accuracy:0.2512 Validation Loss:1.6071, Validation Accuracy:0.2443
Epoch #266: Loss:1.5930, Accuracy:0.2475 Validation Loss:1.6068, Validation Accuracy:0.2410
Epoch #267: Loss:1.5930, Accuracy:0.2492 Validation Loss:1.6071, Validation Accuracy:0.2475
Epoch #268: Loss:1.5927, Accuracy:0.2533 Validation Loss:1.6073, Validation Accuracy:0.2361
Epoch #269: Loss:1.5929, Accuracy:0.2525 Validation Loss:1.6073, Validation Accuracy:0.2361
Epoch #270: Loss:1.5929, Accuracy:0.2525 Validation Loss:1.6067, Validation Accuracy:0.2328
Epoch #271: Loss:1.5936, Accuracy:0.2500 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #272: Loss:1.5926, Accuracy:0.2521 Validation Loss:1.6075, Validation Accuracy:0.2459
Epoch #273: Loss:1.5930, Accuracy:0.2570 Validation Loss:1.6086, Validation Accuracy:0.2361
Epoch #274: Loss:1.5927, Accuracy:0.2533 Validation Loss:1.6080, Validation Accuracy:0.2361
Epoch #275: Loss:1.5929, Accuracy:0.2525 Validation Loss:1.6066, Validation Accuracy:0.2328
Epoch #276: Loss:1.5925, Accuracy:0.2529 Validation Loss:1.6067, Validation Accuracy:0.2443
Epoch #277: Loss:1.5925, Accuracy:0.2537 Validation Loss:1.6073, Validation Accuracy:0.2361
Epoch #278: Loss:1.5927, Accuracy:0.2607 Validation Loss:1.6074, Validation Accuracy:0.2475
Epoch #279: Loss:1.5928, Accuracy:0.2533 Validation Loss:1.6082, Validation Accuracy:0.2361
Epoch #280: Loss:1.5929, Accuracy:0.2533 Validation Loss:1.6081, Validation Accuracy:0.2311
Epoch #281: Loss:1.5923, Accuracy:0.2545 Validation Loss:1.6075, Validation Accuracy:0.2311
Epoch #282: Loss:1.5927, Accuracy:0.2553 Validation Loss:1.6082, Validation Accuracy:0.2459
Epoch #283: Loss:1.5927, Accuracy:0.2545 Validation Loss:1.6079, Validation Accuracy:0.2541
Epoch #284: Loss:1.5925, Accuracy:0.2549 Validation Loss:1.6078, Validation Accuracy:0.2361
Epoch #285: Loss:1.5922, Accuracy:0.2541 Validation Loss:1.6075, Validation Accuracy:0.2361
Epoch #286: Loss:1.5934, Accuracy:0.2463 Validation Loss:1.6067, Validation Accuracy:0.2328
Epoch #287: Loss:1.5922, Accuracy:0.2533 Validation Loss:1.6087, Validation Accuracy:0.2311
Epoch #288: Loss:1.5922, Accuracy:0.2529 Validation Loss:1.6076, Validation Accuracy:0.2361
Epoch #289: Loss:1.5928, Accuracy:0.2529 Validation Loss:1.6088, Validation Accuracy:0.2410
Epoch #290: Loss:1.5928, Accuracy:0.2504 Validation Loss:1.6087, Validation Accuracy:0.2393
Epoch #291: Loss:1.5921, Accuracy:0.2533 Validation Loss:1.6082, Validation Accuracy:0.2443
Epoch #292: Loss:1.5927, Accuracy:0.2557 Validation Loss:1.6074, Validation Accuracy:0.2344
Epoch #293: Loss:1.5915, Accuracy:0.2521 Validation Loss:1.6084, Validation Accuracy:0.2361
Epoch #294: Loss:1.5925, Accuracy:0.2529 Validation Loss:1.6082, Validation Accuracy:0.2361
Epoch #295: Loss:1.5931, Accuracy:0.2557 Validation Loss:1.6076, Validation Accuracy:0.2426
Epoch #296: Loss:1.5924, Accuracy:0.2525 Validation Loss:1.6093, Validation Accuracy:0.2311
Epoch #297: Loss:1.5924, Accuracy:0.2533 Validation Loss:1.6091, Validation Accuracy:0.2475
Epoch #298: Loss:1.5923, Accuracy:0.2537 Validation Loss:1.6093, Validation Accuracy:0.2475
Epoch #299: Loss:1.5919, Accuracy:0.2578 Validation Loss:1.6077, Validation Accuracy:0.2361
Epoch #300: Loss:1.5920, Accuracy:0.2545 Validation Loss:1.6079, Validation Accuracy:0.2311

Test:
Test Loss:1.60788465, Accuracy:0.2311
Labels: ['01', '05', '03', '04', '02']
Confusion Matrix:
[[  5 107   2  12   0]
 [  6 113   0  23   0]
 [  6  95   2  12   0]
 [  4  85   3  21   0]
 [  5  90   1  18   0]]
Classification Report:
              precision    recall  f1-score   support

          01       0.19      0.04      0.07       126
          05       0.23      0.80      0.36       142
          03       0.25      0.02      0.03       115
          04       0.24      0.19      0.21       113
          02       0.00      0.00      0.00       114

    accuracy                           0.23       610
   macro avg       0.18      0.21      0.13       610
weighted avg       0.19      0.23      0.14       610

============ Config: 1/1 === End Time: 2019.07.24 05:19:27 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 53 minutes, 35 seconds =====================


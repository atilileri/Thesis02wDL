======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf18.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.30 10:59:08 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nMags', 'channelMode': 'Split', 'classificationMode': 'Posture3', 'trainingEpoch': 300, 'stepSize': 1, 'sampRate': 8, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
12176 Files with 3 Label(s): ['01', '03', '02'].
Padding:................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 12176 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 3 classes
9740 steps for training, 2436 steps for test
Splitting Train and Test Data...
------Model for nMags------
---LSTM Classifier---
Train Batch: (9740, 7991, 7)
Test Batch: (2436, 7991, 7)
Optimizer: <keras.optimizers.Adam object at 0x000002378034CE80>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x00000237D1D06EA0>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            2696      
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 39        
=================================================================
Total params: 11,535
Trainable params: 11,535
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.0797, Accuracy:0.3822, Validation Loss:1.0750, Validation Accuracy:0.3941
Epoch #2: Loss:1.0746, Accuracy:0.3895, Validation Loss:1.0741, Validation Accuracy:0.4031
Epoch #3: Loss:1.0745, Accuracy:0.3881, Validation Loss:1.0744, Validation Accuracy:0.3941
Epoch #4: Loss:1.0751, Accuracy:0.3931, Validation Loss:1.0742, Validation Accuracy:0.3970
Epoch #5: Loss:1.0737, Accuracy:0.4033, Validation Loss:1.0738, Validation Accuracy:0.3941
Epoch #6: Loss:1.0738, Accuracy:0.4035, Validation Loss:1.0734, Validation Accuracy:0.3978
Epoch #7: Loss:1.0735, Accuracy:0.3972, Validation Loss:1.0732, Validation Accuracy:0.4015
Epoch #8: Loss:1.0733, Accuracy:0.3998, Validation Loss:1.0731, Validation Accuracy:0.4011
Epoch #9: Loss:1.0732, Accuracy:0.3996, Validation Loss:1.0729, Validation Accuracy:0.3986
Epoch #10: Loss:1.0731, Accuracy:0.4041, Validation Loss:1.0726, Validation Accuracy:0.4011
Epoch #11: Loss:1.0731, Accuracy:0.4031, Validation Loss:1.0724, Validation Accuracy:0.4002
Epoch #12: Loss:1.0727, Accuracy:0.4054, Validation Loss:1.0722, Validation Accuracy:0.4048
Epoch #13: Loss:1.0731, Accuracy:0.4072, Validation Loss:1.0723, Validation Accuracy:0.4085
Epoch #14: Loss:1.0717, Accuracy:0.4151, Validation Loss:1.0715, Validation Accuracy:0.4023
Epoch #15: Loss:1.0717, Accuracy:0.4034, Validation Loss:1.0710, Validation Accuracy:0.4044
Epoch #16: Loss:1.0725, Accuracy:0.4050, Validation Loss:1.0717, Validation Accuracy:0.4064
Epoch #17: Loss:1.0706, Accuracy:0.4104, Validation Loss:1.0704, Validation Accuracy:0.4011
Epoch #18: Loss:1.0695, Accuracy:0.4164, Validation Loss:1.0701, Validation Accuracy:0.4122
Epoch #19: Loss:1.0697, Accuracy:0.4146, Validation Loss:1.0691, Validation Accuracy:0.4175
Epoch #20: Loss:1.0693, Accuracy:0.4162, Validation Loss:1.0686, Validation Accuracy:0.4195
Epoch #21: Loss:1.0685, Accuracy:0.4163, Validation Loss:1.0686, Validation Accuracy:0.4097
Epoch #22: Loss:1.0674, Accuracy:0.4229, Validation Loss:1.0682, Validation Accuracy:0.4130
Epoch #23: Loss:1.0660, Accuracy:0.4210, Validation Loss:1.0680, Validation Accuracy:0.4253
Epoch #24: Loss:1.0645, Accuracy:0.4296, Validation Loss:1.0666, Validation Accuracy:0.4195
Epoch #25: Loss:1.0643, Accuracy:0.4241, Validation Loss:1.0663, Validation Accuracy:0.4245
Epoch #26: Loss:1.0626, Accuracy:0.4321, Validation Loss:1.0663, Validation Accuracy:0.4212
Epoch #27: Loss:1.0622, Accuracy:0.4260, Validation Loss:1.0705, Validation Accuracy:0.4027
Epoch #28: Loss:1.0610, Accuracy:0.4273, Validation Loss:1.0656, Validation Accuracy:0.4146
Epoch #29: Loss:1.0629, Accuracy:0.4299, Validation Loss:1.0641, Validation Accuracy:0.4187
Epoch #30: Loss:1.0617, Accuracy:0.4276, Validation Loss:1.0650, Validation Accuracy:0.4236
Epoch #31: Loss:1.0605, Accuracy:0.4260, Validation Loss:1.0631, Validation Accuracy:0.4249
Epoch #32: Loss:1.0582, Accuracy:0.4376, Validation Loss:1.0644, Validation Accuracy:0.4191
Epoch #33: Loss:1.0581, Accuracy:0.4349, Validation Loss:1.0617, Validation Accuracy:0.4298
Epoch #34: Loss:1.0551, Accuracy:0.4376, Validation Loss:1.0623, Validation Accuracy:0.4228
Epoch #35: Loss:1.0588, Accuracy:0.4305, Validation Loss:1.0646, Validation Accuracy:0.4282
Epoch #36: Loss:1.0544, Accuracy:0.4370, Validation Loss:1.0615, Validation Accuracy:0.4236
Epoch #37: Loss:1.0529, Accuracy:0.4411, Validation Loss:1.0616, Validation Accuracy:0.4232
Epoch #38: Loss:1.0552, Accuracy:0.4387, Validation Loss:1.0613, Validation Accuracy:0.4298
Epoch #39: Loss:1.0529, Accuracy:0.4409, Validation Loss:1.0589, Validation Accuracy:0.4319
Epoch #40: Loss:1.0529, Accuracy:0.4407, Validation Loss:1.0595, Validation Accuracy:0.4273
Epoch #41: Loss:1.0528, Accuracy:0.4400, Validation Loss:1.0646, Validation Accuracy:0.4224
Epoch #42: Loss:1.0561, Accuracy:0.4369, Validation Loss:1.0615, Validation Accuracy:0.4261
Epoch #43: Loss:1.0527, Accuracy:0.4464, Validation Loss:1.0577, Validation Accuracy:0.4306
Epoch #44: Loss:1.0495, Accuracy:0.4438, Validation Loss:1.0591, Validation Accuracy:0.4294
Epoch #45: Loss:1.0488, Accuracy:0.4446, Validation Loss:1.0596, Validation Accuracy:0.4294
Epoch #46: Loss:1.0518, Accuracy:0.4454, Validation Loss:1.0591, Validation Accuracy:0.4376
Epoch #47: Loss:1.0500, Accuracy:0.4437, Validation Loss:1.0588, Validation Accuracy:0.4339
Epoch #48: Loss:1.0481, Accuracy:0.4472, Validation Loss:1.0601, Validation Accuracy:0.4298
Epoch #49: Loss:1.0488, Accuracy:0.4502, Validation Loss:1.0602, Validation Accuracy:0.4310
Epoch #50: Loss:1.0496, Accuracy:0.4455, Validation Loss:1.0569, Validation Accuracy:0.4314
Epoch #51: Loss:1.0474, Accuracy:0.4448, Validation Loss:1.0567, Validation Accuracy:0.4335
Epoch #52: Loss:1.0509, Accuracy:0.4422, Validation Loss:1.0616, Validation Accuracy:0.4253
Epoch #53: Loss:1.0478, Accuracy:0.4486, Validation Loss:1.0592, Validation Accuracy:0.4302
Epoch #54: Loss:1.0489, Accuracy:0.4475, Validation Loss:1.0579, Validation Accuracy:0.4261
Epoch #55: Loss:1.0468, Accuracy:0.4440, Validation Loss:1.0569, Validation Accuracy:0.4339
Epoch #56: Loss:1.0460, Accuracy:0.4431, Validation Loss:1.0588, Validation Accuracy:0.4282
Epoch #57: Loss:1.0470, Accuracy:0.4457, Validation Loss:1.0580, Validation Accuracy:0.4327
Epoch #58: Loss:1.0438, Accuracy:0.4464, Validation Loss:1.0569, Validation Accuracy:0.4249
Epoch #59: Loss:1.0443, Accuracy:0.4473, Validation Loss:1.0562, Validation Accuracy:0.4335
Epoch #60: Loss:1.0446, Accuracy:0.4496, Validation Loss:1.0551, Validation Accuracy:0.4343
Epoch #61: Loss:1.0436, Accuracy:0.4467, Validation Loss:1.0561, Validation Accuracy:0.4331
Epoch #62: Loss:1.0429, Accuracy:0.4475, Validation Loss:1.0556, Validation Accuracy:0.4298
Epoch #63: Loss:1.0410, Accuracy:0.4483, Validation Loss:1.0562, Validation Accuracy:0.4376
Epoch #64: Loss:1.0408, Accuracy:0.4508, Validation Loss:1.0565, Validation Accuracy:0.4302
Epoch #65: Loss:1.0453, Accuracy:0.4512, Validation Loss:1.0553, Validation Accuracy:0.4372
Epoch #66: Loss:1.0415, Accuracy:0.4470, Validation Loss:1.0566, Validation Accuracy:0.4327
Epoch #67: Loss:1.0414, Accuracy:0.4497, Validation Loss:1.0555, Validation Accuracy:0.4372
Epoch #68: Loss:1.0386, Accuracy:0.4516, Validation Loss:1.0586, Validation Accuracy:0.4372
Epoch #69: Loss:1.0428, Accuracy:0.4510, Validation Loss:1.0570, Validation Accuracy:0.4364
Epoch #70: Loss:1.0391, Accuracy:0.4549, Validation Loss:1.0535, Validation Accuracy:0.4351
Epoch #71: Loss:1.0377, Accuracy:0.4517, Validation Loss:1.0568, Validation Accuracy:0.4319
Epoch #72: Loss:1.0393, Accuracy:0.4495, Validation Loss:1.0556, Validation Accuracy:0.4339
Epoch #73: Loss:1.0370, Accuracy:0.4502, Validation Loss:1.0543, Validation Accuracy:0.4401
Epoch #74: Loss:1.0345, Accuracy:0.4543, Validation Loss:1.0540, Validation Accuracy:0.4343
Epoch #75: Loss:1.0351, Accuracy:0.4584, Validation Loss:1.0531, Validation Accuracy:0.4306
Epoch #76: Loss:1.0370, Accuracy:0.4496, Validation Loss:1.0554, Validation Accuracy:0.4339
Epoch #77: Loss:1.0383, Accuracy:0.4527, Validation Loss:1.0531, Validation Accuracy:0.4323
Epoch #78: Loss:1.0374, Accuracy:0.4500, Validation Loss:1.0514, Validation Accuracy:0.4351
Epoch #79: Loss:1.0341, Accuracy:0.4531, Validation Loss:1.0527, Validation Accuracy:0.4323
Epoch #80: Loss:1.0377, Accuracy:0.4551, Validation Loss:1.0529, Validation Accuracy:0.4310
Epoch #81: Loss:1.0338, Accuracy:0.4505, Validation Loss:1.0515, Validation Accuracy:0.4368
Epoch #82: Loss:1.0332, Accuracy:0.4573, Validation Loss:1.0558, Validation Accuracy:0.4327
Epoch #83: Loss:1.0355, Accuracy:0.4532, Validation Loss:1.0500, Validation Accuracy:0.4392
Epoch #84: Loss:1.0315, Accuracy:0.4608, Validation Loss:1.0500, Validation Accuracy:0.4368
Epoch #85: Loss:1.0327, Accuracy:0.4578, Validation Loss:1.0497, Validation Accuracy:0.4306
Epoch #86: Loss:1.0284, Accuracy:0.4602, Validation Loss:1.0513, Validation Accuracy:0.4360
Epoch #87: Loss:1.0315, Accuracy:0.4535, Validation Loss:1.0497, Validation Accuracy:0.4351
Epoch #88: Loss:1.0270, Accuracy:0.4603, Validation Loss:1.0483, Validation Accuracy:0.4323
Epoch #89: Loss:1.0261, Accuracy:0.4639, Validation Loss:1.0499, Validation Accuracy:0.4360
Epoch #90: Loss:1.0275, Accuracy:0.4620, Validation Loss:1.0485, Validation Accuracy:0.4331
Epoch #91: Loss:1.0273, Accuracy:0.4586, Validation Loss:1.0502, Validation Accuracy:0.4356
Epoch #92: Loss:1.0299, Accuracy:0.4594, Validation Loss:1.0501, Validation Accuracy:0.4405
Epoch #93: Loss:1.0248, Accuracy:0.4672, Validation Loss:1.0474, Validation Accuracy:0.4372
Epoch #94: Loss:1.0234, Accuracy:0.4660, Validation Loss:1.0488, Validation Accuracy:0.4265
Epoch #95: Loss:1.0249, Accuracy:0.4654, Validation Loss:1.0527, Validation Accuracy:0.4314
Epoch #96: Loss:1.0227, Accuracy:0.4689, Validation Loss:1.0531, Validation Accuracy:0.4335
Epoch #97: Loss:1.0279, Accuracy:0.4605, Validation Loss:1.0494, Validation Accuracy:0.4236
Epoch #98: Loss:1.0247, Accuracy:0.4696, Validation Loss:1.0500, Validation Accuracy:0.4327
Epoch #99: Loss:1.0242, Accuracy:0.4645, Validation Loss:1.0458, Validation Accuracy:0.4306
Epoch #100: Loss:1.0230, Accuracy:0.4678, Validation Loss:1.0472, Validation Accuracy:0.4372
Epoch #101: Loss:1.0201, Accuracy:0.4667, Validation Loss:1.0459, Validation Accuracy:0.4454
Epoch #102: Loss:1.0192, Accuracy:0.4717, Validation Loss:1.0484, Validation Accuracy:0.4384
Epoch #103: Loss:1.0241, Accuracy:0.4679, Validation Loss:1.0457, Validation Accuracy:0.4487
Epoch #104: Loss:1.0182, Accuracy:0.4713, Validation Loss:1.0434, Validation Accuracy:0.4388
Epoch #105: Loss:1.0185, Accuracy:0.4675, Validation Loss:1.0426, Validation Accuracy:0.4384
Epoch #106: Loss:1.0159, Accuracy:0.4776, Validation Loss:1.0438, Validation Accuracy:0.4323
Epoch #107: Loss:1.0163, Accuracy:0.4741, Validation Loss:1.0425, Validation Accuracy:0.4475
Epoch #108: Loss:1.0181, Accuracy:0.4777, Validation Loss:1.0399, Validation Accuracy:0.4479
Epoch #109: Loss:1.0137, Accuracy:0.4782, Validation Loss:1.0425, Validation Accuracy:0.4376
Epoch #110: Loss:1.0149, Accuracy:0.4693, Validation Loss:1.0426, Validation Accuracy:0.4516
Epoch #111: Loss:1.0105, Accuracy:0.4786, Validation Loss:1.0421, Validation Accuracy:0.4462
Epoch #112: Loss:1.0169, Accuracy:0.4772, Validation Loss:1.0438, Validation Accuracy:0.4409
Epoch #113: Loss:1.0209, Accuracy:0.4636, Validation Loss:1.0364, Validation Accuracy:0.4438
Epoch #114: Loss:1.0136, Accuracy:0.4742, Validation Loss:1.0373, Validation Accuracy:0.4499
Epoch #115: Loss:1.0109, Accuracy:0.4771, Validation Loss:1.0380, Validation Accuracy:0.4466
Epoch #116: Loss:1.0100, Accuracy:0.4799, Validation Loss:1.0387, Validation Accuracy:0.4409
Epoch #117: Loss:1.0117, Accuracy:0.4794, Validation Loss:1.0412, Validation Accuracy:0.4462
Epoch #118: Loss:1.0103, Accuracy:0.4869, Validation Loss:1.0378, Validation Accuracy:0.4495
Epoch #119: Loss:1.0058, Accuracy:0.4845, Validation Loss:1.0375, Validation Accuracy:0.4495
Epoch #120: Loss:1.0043, Accuracy:0.4839, Validation Loss:1.0417, Validation Accuracy:0.4487
Epoch #121: Loss:1.0050, Accuracy:0.4866, Validation Loss:1.0386, Validation Accuracy:0.4450
Epoch #122: Loss:1.0028, Accuracy:0.4803, Validation Loss:1.0433, Validation Accuracy:0.4392
Epoch #123: Loss:1.0078, Accuracy:0.4824, Validation Loss:1.0379, Validation Accuracy:0.4503
Epoch #124: Loss:1.0065, Accuracy:0.4815, Validation Loss:1.0333, Validation Accuracy:0.4487
Epoch #125: Loss:1.0002, Accuracy:0.4932, Validation Loss:1.0384, Validation Accuracy:0.4462
Epoch #126: Loss:1.0106, Accuracy:0.4758, Validation Loss:1.0344, Validation Accuracy:0.4503
Epoch #127: Loss:1.0008, Accuracy:0.4866, Validation Loss:1.0367, Validation Accuracy:0.4524
Epoch #128: Loss:0.9980, Accuracy:0.4931, Validation Loss:1.0349, Validation Accuracy:0.4528
Epoch #129: Loss:0.9978, Accuracy:0.4879, Validation Loss:1.0379, Validation Accuracy:0.4511
Epoch #130: Loss:0.9972, Accuracy:0.4893, Validation Loss:1.0401, Validation Accuracy:0.4581
Epoch #131: Loss:0.9998, Accuracy:0.4879, Validation Loss:1.0358, Validation Accuracy:0.4507
Epoch #132: Loss:1.0002, Accuracy:0.4933, Validation Loss:1.0377, Validation Accuracy:0.4569
Epoch #133: Loss:0.9973, Accuracy:0.4933, Validation Loss:1.0414, Validation Accuracy:0.4503
Epoch #134: Loss:0.9936, Accuracy:0.4943, Validation Loss:1.0387, Validation Accuracy:0.4475
Epoch #135: Loss:0.9963, Accuracy:0.4980, Validation Loss:1.0471, Validation Accuracy:0.4413
Epoch #136: Loss:1.0039, Accuracy:0.4847, Validation Loss:1.0440, Validation Accuracy:0.4413
Epoch #137: Loss:0.9943, Accuracy:0.4922, Validation Loss:1.0359, Validation Accuracy:0.4569
Epoch #138: Loss:0.9941, Accuracy:0.4924, Validation Loss:1.0376, Validation Accuracy:0.4540
Epoch #139: Loss:0.9893, Accuracy:0.4996, Validation Loss:1.0341, Validation Accuracy:0.4475
Epoch #140: Loss:0.9861, Accuracy:0.5046, Validation Loss:1.0386, Validation Accuracy:0.4585
Epoch #141: Loss:0.9932, Accuracy:0.4938, Validation Loss:1.0350, Validation Accuracy:0.4561
Epoch #142: Loss:0.9851, Accuracy:0.5018, Validation Loss:1.0358, Validation Accuracy:0.4499
Epoch #143: Loss:0.9938, Accuracy:0.5022, Validation Loss:1.0377, Validation Accuracy:0.4536
Epoch #144: Loss:0.9868, Accuracy:0.5038, Validation Loss:1.0306, Validation Accuracy:0.4573
Epoch #145: Loss:0.9858, Accuracy:0.5070, Validation Loss:1.0279, Validation Accuracy:0.4676
Epoch #146: Loss:0.9911, Accuracy:0.4995, Validation Loss:1.0355, Validation Accuracy:0.4573
Epoch #147: Loss:0.9863, Accuracy:0.5062, Validation Loss:1.0385, Validation Accuracy:0.4553
Epoch #148: Loss:0.9792, Accuracy:0.5138, Validation Loss:1.0305, Validation Accuracy:0.4499
Epoch #149: Loss:0.9847, Accuracy:0.5055, Validation Loss:1.0329, Validation Accuracy:0.4626
Epoch #150: Loss:0.9783, Accuracy:0.5107, Validation Loss:1.0323, Validation Accuracy:0.4581
Epoch #151: Loss:0.9814, Accuracy:0.5047, Validation Loss:1.0344, Validation Accuracy:0.4544
Epoch #152: Loss:0.9768, Accuracy:0.5142, Validation Loss:1.0337, Validation Accuracy:0.4631
Epoch #153: Loss:0.9765, Accuracy:0.5093, Validation Loss:1.0328, Validation Accuracy:0.4676
Epoch #154: Loss:0.9749, Accuracy:0.5154, Validation Loss:1.0358, Validation Accuracy:0.4573
Epoch #155: Loss:0.9753, Accuracy:0.5112, Validation Loss:1.0336, Validation Accuracy:0.4643
Epoch #156: Loss:0.9706, Accuracy:0.5121, Validation Loss:1.0365, Validation Accuracy:0.4626
Epoch #157: Loss:0.9738, Accuracy:0.5155, Validation Loss:1.0377, Validation Accuracy:0.4598
Epoch #158: Loss:0.9701, Accuracy:0.5189, Validation Loss:1.0389, Validation Accuracy:0.4692
Epoch #159: Loss:0.9779, Accuracy:0.5103, Validation Loss:1.0311, Validation Accuracy:0.4635
Epoch #160: Loss:0.9669, Accuracy:0.5298, Validation Loss:1.0311, Validation Accuracy:0.4647
Epoch #161: Loss:0.9682, Accuracy:0.5234, Validation Loss:1.0318, Validation Accuracy:0.4663
Epoch #162: Loss:0.9692, Accuracy:0.5216, Validation Loss:1.0342, Validation Accuracy:0.4647
Epoch #163: Loss:0.9655, Accuracy:0.5243, Validation Loss:1.0321, Validation Accuracy:0.4692
Epoch #164: Loss:0.9676, Accuracy:0.5219, Validation Loss:1.0315, Validation Accuracy:0.4524
Epoch #165: Loss:0.9612, Accuracy:0.5251, Validation Loss:1.0338, Validation Accuracy:0.4631
Epoch #166: Loss:0.9618, Accuracy:0.5283, Validation Loss:1.0355, Validation Accuracy:0.4647
Epoch #167: Loss:0.9589, Accuracy:0.5300, Validation Loss:1.0324, Validation Accuracy:0.4672
Epoch #168: Loss:0.9661, Accuracy:0.5269, Validation Loss:1.0438, Validation Accuracy:0.4507
Epoch #169: Loss:0.9649, Accuracy:0.5241, Validation Loss:1.0381, Validation Accuracy:0.4639
Epoch #170: Loss:0.9609, Accuracy:0.5291, Validation Loss:1.0408, Validation Accuracy:0.4614
Epoch #171: Loss:0.9594, Accuracy:0.5342, Validation Loss:1.0306, Validation Accuracy:0.4729
Epoch #172: Loss:0.9529, Accuracy:0.5367, Validation Loss:1.0382, Validation Accuracy:0.4553
Epoch #173: Loss:0.9548, Accuracy:0.5309, Validation Loss:1.0418, Validation Accuracy:0.4692
Epoch #174: Loss:0.9578, Accuracy:0.5366, Validation Loss:1.0390, Validation Accuracy:0.4688
Epoch #175: Loss:0.9560, Accuracy:0.5306, Validation Loss:1.0321, Validation Accuracy:0.4581
Epoch #176: Loss:0.9542, Accuracy:0.5292, Validation Loss:1.0409, Validation Accuracy:0.4553
Epoch #177: Loss:0.9709, Accuracy:0.5128, Validation Loss:1.0294, Validation Accuracy:0.4676
Epoch #178: Loss:0.9509, Accuracy:0.5376, Validation Loss:1.0238, Validation Accuracy:0.4737
Epoch #179: Loss:0.9502, Accuracy:0.5332, Validation Loss:1.0260, Validation Accuracy:0.4733
Epoch #180: Loss:0.9453, Accuracy:0.5414, Validation Loss:1.0353, Validation Accuracy:0.4536
Epoch #181: Loss:0.9503, Accuracy:0.5390, Validation Loss:1.0272, Validation Accuracy:0.4704
Epoch #182: Loss:0.9463, Accuracy:0.5424, Validation Loss:1.0399, Validation Accuracy:0.4577
Epoch #183: Loss:0.9499, Accuracy:0.5381, Validation Loss:1.0353, Validation Accuracy:0.4758
Epoch #184: Loss:0.9454, Accuracy:0.5408, Validation Loss:1.0351, Validation Accuracy:0.4704
Epoch #185: Loss:0.9509, Accuracy:0.5366, Validation Loss:1.0395, Validation Accuracy:0.4589
Epoch #186: Loss:0.9456, Accuracy:0.5378, Validation Loss:1.0350, Validation Accuracy:0.4713
Epoch #187: Loss:0.9433, Accuracy:0.5408, Validation Loss:1.0305, Validation Accuracy:0.4659
Epoch #188: Loss:0.9412, Accuracy:0.5450, Validation Loss:1.0340, Validation Accuracy:0.4692
Epoch #189: Loss:0.9429, Accuracy:0.5438, Validation Loss:1.0297, Validation Accuracy:0.4680
Epoch #190: Loss:0.9392, Accuracy:0.5429, Validation Loss:1.0529, Validation Accuracy:0.4573
Epoch #191: Loss:0.9523, Accuracy:0.5334, Validation Loss:1.0391, Validation Accuracy:0.4626
Epoch #192: Loss:0.9421, Accuracy:0.5471, Validation Loss:1.0302, Validation Accuracy:0.4667
Epoch #193: Loss:0.9385, Accuracy:0.5438, Validation Loss:1.0320, Validation Accuracy:0.4692
Epoch #194: Loss:0.9416, Accuracy:0.5445, Validation Loss:1.0275, Validation Accuracy:0.4741
Epoch #195: Loss:0.9365, Accuracy:0.5474, Validation Loss:1.0396, Validation Accuracy:0.4483
Epoch #196: Loss:0.9423, Accuracy:0.5470, Validation Loss:1.0295, Validation Accuracy:0.4709
Epoch #197: Loss:0.9363, Accuracy:0.5448, Validation Loss:1.0345, Validation Accuracy:0.4700
Epoch #198: Loss:0.9331, Accuracy:0.5455, Validation Loss:1.0342, Validation Accuracy:0.4762
Epoch #199: Loss:0.9332, Accuracy:0.5497, Validation Loss:1.0351, Validation Accuracy:0.4725
Epoch #200: Loss:0.9338, Accuracy:0.5495, Validation Loss:1.0414, Validation Accuracy:0.4667
Epoch #201: Loss:0.9284, Accuracy:0.5508, Validation Loss:1.0334, Validation Accuracy:0.4733
Epoch #202: Loss:0.9255, Accuracy:0.5574, Validation Loss:1.0389, Validation Accuracy:0.4787
Epoch #203: Loss:0.9330, Accuracy:0.5520, Validation Loss:1.0455, Validation Accuracy:0.4709
Epoch #204: Loss:0.9299, Accuracy:0.5505, Validation Loss:1.0474, Validation Accuracy:0.4618
Epoch #205: Loss:0.9297, Accuracy:0.5508, Validation Loss:1.0486, Validation Accuracy:0.4577
Epoch #206: Loss:0.9282, Accuracy:0.5498, Validation Loss:1.0431, Validation Accuracy:0.4713
Epoch #207: Loss:0.9232, Accuracy:0.5544, Validation Loss:1.0541, Validation Accuracy:0.4667
Epoch #208: Loss:0.9281, Accuracy:0.5506, Validation Loss:1.0401, Validation Accuracy:0.4704
Epoch #209: Loss:0.9236, Accuracy:0.5559, Validation Loss:1.0511, Validation Accuracy:0.4540
Epoch #210: Loss:0.9284, Accuracy:0.5516, Validation Loss:1.0420, Validation Accuracy:0.4635
Epoch #211: Loss:0.9224, Accuracy:0.5539, Validation Loss:1.0430, Validation Accuracy:0.4770
Epoch #212: Loss:0.9210, Accuracy:0.5568, Validation Loss:1.0486, Validation Accuracy:0.4631
Epoch #213: Loss:0.9277, Accuracy:0.5500, Validation Loss:1.0435, Validation Accuracy:0.4594
Epoch #214: Loss:0.9152, Accuracy:0.5608, Validation Loss:1.0489, Validation Accuracy:0.4626
Epoch #215: Loss:0.9153, Accuracy:0.5670, Validation Loss:1.0479, Validation Accuracy:0.4606
Epoch #216: Loss:0.9193, Accuracy:0.5574, Validation Loss:1.0501, Validation Accuracy:0.4544
Epoch #217: Loss:0.9207, Accuracy:0.5549, Validation Loss:1.0475, Validation Accuracy:0.4766
Epoch #218: Loss:0.9120, Accuracy:0.5672, Validation Loss:1.0571, Validation Accuracy:0.4585
Epoch #219: Loss:0.9086, Accuracy:0.5694, Validation Loss:1.0493, Validation Accuracy:0.4643
Epoch #220: Loss:0.9063, Accuracy:0.5687, Validation Loss:1.0477, Validation Accuracy:0.4663
Epoch #221: Loss:0.9106, Accuracy:0.5584, Validation Loss:1.0534, Validation Accuracy:0.4663
Epoch #222: Loss:0.9040, Accuracy:0.5722, Validation Loss:1.0512, Validation Accuracy:0.4561
Epoch #223: Loss:0.9111, Accuracy:0.5671, Validation Loss:1.0539, Validation Accuracy:0.4663
Epoch #224: Loss:0.9033, Accuracy:0.5708, Validation Loss:1.0523, Validation Accuracy:0.4651
Epoch #225: Loss:0.9011, Accuracy:0.5720, Validation Loss:1.0547, Validation Accuracy:0.4713
Epoch #226: Loss:0.9260, Accuracy:0.5537, Validation Loss:1.0480, Validation Accuracy:0.4758
Epoch #227: Loss:0.9044, Accuracy:0.5644, Validation Loss:1.0599, Validation Accuracy:0.4540
Epoch #228: Loss:0.8996, Accuracy:0.5739, Validation Loss:1.0604, Validation Accuracy:0.4585
Epoch #229: Loss:0.9025, Accuracy:0.5689, Validation Loss:1.0485, Validation Accuracy:0.4594
Epoch #230: Loss:0.8949, Accuracy:0.5749, Validation Loss:1.0490, Validation Accuracy:0.4626
Epoch #231: Loss:0.8953, Accuracy:0.5746, Validation Loss:1.0613, Validation Accuracy:0.4618
Epoch #232: Loss:0.9033, Accuracy:0.5703, Validation Loss:1.0559, Validation Accuracy:0.4704
Epoch #233: Loss:0.9097, Accuracy:0.5637, Validation Loss:1.0498, Validation Accuracy:0.4672
Epoch #234: Loss:0.8965, Accuracy:0.5732, Validation Loss:1.0582, Validation Accuracy:0.4569
Epoch #235: Loss:0.8960, Accuracy:0.5731, Validation Loss:1.0681, Validation Accuracy:0.4614
Epoch #236: Loss:0.8958, Accuracy:0.5763, Validation Loss:1.0720, Validation Accuracy:0.4540
Epoch #237: Loss:0.8990, Accuracy:0.5725, Validation Loss:1.0525, Validation Accuracy:0.4622
Epoch #238: Loss:0.8955, Accuracy:0.5767, Validation Loss:1.0557, Validation Accuracy:0.4729
Epoch #239: Loss:0.8972, Accuracy:0.5746, Validation Loss:1.0776, Validation Accuracy:0.4688
Epoch #240: Loss:0.9019, Accuracy:0.5728, Validation Loss:1.0550, Validation Accuracy:0.4610
Epoch #241: Loss:0.8912, Accuracy:0.5769, Validation Loss:1.0572, Validation Accuracy:0.4635
Epoch #242: Loss:0.8939, Accuracy:0.5737, Validation Loss:1.0546, Validation Accuracy:0.4721
Epoch #243: Loss:0.8935, Accuracy:0.5781, Validation Loss:1.0536, Validation Accuracy:0.4729
Epoch #244: Loss:0.8926, Accuracy:0.5791, Validation Loss:1.0618, Validation Accuracy:0.4651
Epoch #245: Loss:0.8849, Accuracy:0.5834, Validation Loss:1.0628, Validation Accuracy:0.4717
Epoch #246: Loss:0.8846, Accuracy:0.5799, Validation Loss:1.0779, Validation Accuracy:0.4811
Epoch #247: Loss:0.8968, Accuracy:0.5687, Validation Loss:1.0683, Validation Accuracy:0.4672
Epoch #248: Loss:0.8881, Accuracy:0.5796, Validation Loss:1.0599, Validation Accuracy:0.4651
Epoch #249: Loss:0.8819, Accuracy:0.5841, Validation Loss:1.0679, Validation Accuracy:0.4655
Epoch #250: Loss:0.8792, Accuracy:0.5831, Validation Loss:1.0657, Validation Accuracy:0.4610
Epoch #251: Loss:0.8815, Accuracy:0.5855, Validation Loss:1.0719, Validation Accuracy:0.4602
Epoch #252: Loss:0.8805, Accuracy:0.5835, Validation Loss:1.0720, Validation Accuracy:0.4573
Epoch #253: Loss:0.8800, Accuracy:0.5818, Validation Loss:1.0749, Validation Accuracy:0.4639
Epoch #254: Loss:0.8883, Accuracy:0.5780, Validation Loss:1.0653, Validation Accuracy:0.4626
Epoch #255: Loss:0.8790, Accuracy:0.5872, Validation Loss:1.0742, Validation Accuracy:0.4729
Epoch #256: Loss:0.8948, Accuracy:0.5745, Validation Loss:1.0692, Validation Accuracy:0.4680
Epoch #257: Loss:0.8773, Accuracy:0.5858, Validation Loss:1.0620, Validation Accuracy:0.4692
Epoch #258: Loss:0.8792, Accuracy:0.5808, Validation Loss:1.0737, Validation Accuracy:0.4667
Epoch #259: Loss:0.8813, Accuracy:0.5825, Validation Loss:1.0719, Validation Accuracy:0.4700
Epoch #260: Loss:0.8878, Accuracy:0.5820, Validation Loss:1.0744, Validation Accuracy:0.4639
Epoch #261: Loss:0.8785, Accuracy:0.5853, Validation Loss:1.0856, Validation Accuracy:0.4655
Epoch #262: Loss:0.8829, Accuracy:0.5828, Validation Loss:1.0728, Validation Accuracy:0.4651
Epoch #263: Loss:0.8739, Accuracy:0.5896, Validation Loss:1.0655, Validation Accuracy:0.4680
Epoch #264: Loss:0.8733, Accuracy:0.5890, Validation Loss:1.0797, Validation Accuracy:0.4700
Epoch #265: Loss:0.8728, Accuracy:0.5898, Validation Loss:1.0861, Validation Accuracy:0.4676
Epoch #266: Loss:0.8724, Accuracy:0.5905, Validation Loss:1.0764, Validation Accuracy:0.4676
Epoch #267: Loss:0.8708, Accuracy:0.5900, Validation Loss:1.0816, Validation Accuracy:0.4667
Epoch #268: Loss:0.8619, Accuracy:0.5935, Validation Loss:1.0752, Validation Accuracy:0.4688
Epoch #269: Loss:0.8646, Accuracy:0.5979, Validation Loss:1.0963, Validation Accuracy:0.4688
Epoch #270: Loss:0.8893, Accuracy:0.5745, Validation Loss:1.0733, Validation Accuracy:0.4631
Epoch #271: Loss:0.8679, Accuracy:0.5912, Validation Loss:1.0906, Validation Accuracy:0.4540
Epoch #272: Loss:0.8929, Accuracy:0.5732, Validation Loss:1.0717, Validation Accuracy:0.4561
Epoch #273: Loss:0.8637, Accuracy:0.5957, Validation Loss:1.0815, Validation Accuracy:0.4704
Epoch #274: Loss:0.8639, Accuracy:0.5944, Validation Loss:1.0734, Validation Accuracy:0.4639
Epoch #275: Loss:0.8621, Accuracy:0.5953, Validation Loss:1.0808, Validation Accuracy:0.4643
Epoch #276: Loss:0.8603, Accuracy:0.6002, Validation Loss:1.0887, Validation Accuracy:0.4672
Epoch #277: Loss:0.8558, Accuracy:0.5998, Validation Loss:1.0858, Validation Accuracy:0.4721
Epoch #278: Loss:0.8639, Accuracy:0.5923, Validation Loss:1.0769, Validation Accuracy:0.4635
Epoch #279: Loss:0.8725, Accuracy:0.5894, Validation Loss:1.0744, Validation Accuracy:0.4639
Epoch #280: Loss:0.8624, Accuracy:0.5977, Validation Loss:1.0749, Validation Accuracy:0.4709
Epoch #281: Loss:0.8739, Accuracy:0.5915, Validation Loss:1.0926, Validation Accuracy:0.4717
Epoch #282: Loss:0.8603, Accuracy:0.5945, Validation Loss:1.0878, Validation Accuracy:0.4721
Epoch #283: Loss:0.8599, Accuracy:0.5995, Validation Loss:1.0928, Validation Accuracy:0.4635
Epoch #284: Loss:0.8570, Accuracy:0.6008, Validation Loss:1.0808, Validation Accuracy:0.4663
Epoch #285: Loss:0.8574, Accuracy:0.6012, Validation Loss:1.1001, Validation Accuracy:0.4745
Epoch #286: Loss:0.8615, Accuracy:0.5951, Validation Loss:1.0827, Validation Accuracy:0.4676
Epoch #287: Loss:0.8669, Accuracy:0.5972, Validation Loss:1.0876, Validation Accuracy:0.4651
Epoch #288: Loss:0.8590, Accuracy:0.6008, Validation Loss:1.0806, Validation Accuracy:0.4614
Epoch #289: Loss:0.8576, Accuracy:0.6024, Validation Loss:1.0950, Validation Accuracy:0.4635
Epoch #290: Loss:0.8507, Accuracy:0.6042, Validation Loss:1.1093, Validation Accuracy:0.4635
Epoch #291: Loss:0.8662, Accuracy:0.5939, Validation Loss:1.1033, Validation Accuracy:0.4643
Epoch #292: Loss:0.8510, Accuracy:0.5989, Validation Loss:1.0886, Validation Accuracy:0.4598
Epoch #293: Loss:0.8488, Accuracy:0.6059, Validation Loss:1.0849, Validation Accuracy:0.4626
Epoch #294: Loss:0.8568, Accuracy:0.6006, Validation Loss:1.0964, Validation Accuracy:0.4631
Epoch #295: Loss:0.8684, Accuracy:0.5899, Validation Loss:1.0831, Validation Accuracy:0.4585
Epoch #296: Loss:0.8705, Accuracy:0.5857, Validation Loss:1.0770, Validation Accuracy:0.4762
Epoch #297: Loss:0.8440, Accuracy:0.6104, Validation Loss:1.0987, Validation Accuracy:0.4676
Epoch #298: Loss:0.8394, Accuracy:0.6139, Validation Loss:1.0997, Validation Accuracy:0.4655
Epoch #299: Loss:0.8413, Accuracy:0.6051, Validation Loss:1.0913, Validation Accuracy:0.4594
Epoch #300: Loss:0.8437, Accuracy:0.6046, Validation Loss:1.0922, Validation Accuracy:0.4618

Test:
Test Loss:1.09215021, Accuracy:0.4618
Labels: ['01', '03', '02']
Confusion Matrix:
       01   03   02
t:01  447  135  378
t:03  174  180  214
t:02  268  142  498
Classification Report:
              precision    recall  f1-score   support

          01       0.50      0.47      0.48       960
          03       0.39      0.32      0.35       568
          02       0.46      0.55      0.50       908

    accuracy                           0.46      2436
   macro avg       0.45      0.44      0.44      2436
weighted avg       0.46      0.46      0.46      2436

============ Config: 1/1 === End Time: 2019.07.30 12:01:22 =========================================
============ Config: 1/1 === Duration: 0 days, 1 hours, 2 minutes, 14 seconds =====================

Ending script after plotting results...

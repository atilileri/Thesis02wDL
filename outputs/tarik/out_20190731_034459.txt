======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf7.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.31 03:44:59 =======================================
Parameters: inputFolder : C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
sampRate : 8
featureMode : FrMgPh
channelMode : 2
classificationMode : Speaker
trainingEpoch : 300
stepSize : 1
batchSize : 512
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3044 Files with 15 Label(s): ['mb', 'ib', 'ek', 'eb', 'sg', 'yd', 'my', 'ck', 'eo', 'aa', 'ds', 'sk', 'eg', 'by', 'ce'].
Padding:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3044 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2435 steps for training, 609 steps for test
Splitting Train and Test Data...
------Model for FrMgPh------
---LSTM Classifier---
Train Batch: (2435, 7991, 42)
Test Batch: (609, 7991, 42)
Optimizer: <keras.optimizers.Adam object at 0x000001EE18760240>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001EE16008048>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            16136     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 25,131
Trainable params: 25,131
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.7128, Accuracy:0.0476, Validation Loss:2.7058, Validation Accuracy:0.0361
Epoch #2: Loss:2.7031, Accuracy:0.0645, Validation Loss:2.6967, Validation Accuracy:0.0821
Epoch #3: Loss:2.6946, Accuracy:0.0813, Validation Loss:2.6892, Validation Accuracy:0.0821
Epoch #4: Loss:2.6857, Accuracy:0.0813, Validation Loss:2.6823, Validation Accuracy:0.0821
Epoch #5: Loss:2.6785, Accuracy:0.0813, Validation Loss:2.6758, Validation Accuracy:0.0821
Epoch #6: Loss:2.6728, Accuracy:0.0879, Validation Loss:2.6705, Validation Accuracy:0.1232
Epoch #7: Loss:2.6677, Accuracy:0.1244, Validation Loss:2.6653, Validation Accuracy:0.1330
Epoch #8: Loss:2.6627, Accuracy:0.1396, Validation Loss:2.6612, Validation Accuracy:0.1609
Epoch #9: Loss:2.6594, Accuracy:0.1577, Validation Loss:2.6581, Validation Accuracy:0.1560
Epoch #10: Loss:2.6554, Accuracy:0.1520, Validation Loss:2.6546, Validation Accuracy:0.1461
Epoch #11: Loss:2.6508, Accuracy:0.1405, Validation Loss:2.6501, Validation Accuracy:0.1461
Epoch #12: Loss:2.6451, Accuracy:0.1429, Validation Loss:2.6436, Validation Accuracy:0.1445
Epoch #13: Loss:2.6374, Accuracy:0.1462, Validation Loss:2.6345, Validation Accuracy:0.1478
Epoch #14: Loss:2.6279, Accuracy:0.1470, Validation Loss:2.6244, Validation Accuracy:0.1527
Epoch #15: Loss:2.6153, Accuracy:0.1593, Validation Loss:2.6127, Validation Accuracy:0.1576
Epoch #16: Loss:2.6029, Accuracy:0.1573, Validation Loss:2.6107, Validation Accuracy:0.1478
Epoch #17: Loss:2.5904, Accuracy:0.1520, Validation Loss:2.5904, Validation Accuracy:0.1593
Epoch #18: Loss:2.5797, Accuracy:0.1585, Validation Loss:2.5812, Validation Accuracy:0.1626
Epoch #19: Loss:2.5651, Accuracy:0.1581, Validation Loss:2.5745, Validation Accuracy:0.1593
Epoch #20: Loss:2.5546, Accuracy:0.1589, Validation Loss:2.5612, Validation Accuracy:0.1609
Epoch #21: Loss:2.5438, Accuracy:0.1573, Validation Loss:2.5434, Validation Accuracy:0.1642
Epoch #22: Loss:2.5264, Accuracy:0.1626, Validation Loss:2.5485, Validation Accuracy:0.1576
Epoch #23: Loss:2.5178, Accuracy:0.1581, Validation Loss:2.5347, Validation Accuracy:0.1724
Epoch #24: Loss:2.5082, Accuracy:0.1688, Validation Loss:2.5219, Validation Accuracy:0.1658
Epoch #25: Loss:2.5142, Accuracy:0.1483, Validation Loss:2.5354, Validation Accuracy:0.1429
Epoch #26: Loss:2.5179, Accuracy:0.1425, Validation Loss:2.5224, Validation Accuracy:0.1511
Epoch #27: Loss:2.5031, Accuracy:0.1647, Validation Loss:2.5248, Validation Accuracy:0.1412
Epoch #28: Loss:2.5293, Accuracy:0.1478, Validation Loss:2.5107, Validation Accuracy:0.1593
Epoch #29: Loss:2.5080, Accuracy:0.1651, Validation Loss:2.5190, Validation Accuracy:0.1658
Epoch #30: Loss:2.4967, Accuracy:0.1610, Validation Loss:2.5118, Validation Accuracy:0.1478
Epoch #31: Loss:2.4890, Accuracy:0.1569, Validation Loss:2.4962, Validation Accuracy:0.1576
Epoch #32: Loss:2.4790, Accuracy:0.1647, Validation Loss:2.4915, Validation Accuracy:0.1642
Epoch #33: Loss:2.4717, Accuracy:0.1643, Validation Loss:2.4874, Validation Accuracy:0.1593
Epoch #34: Loss:2.4710, Accuracy:0.1643, Validation Loss:2.4831, Validation Accuracy:0.1642
Epoch #35: Loss:2.4643, Accuracy:0.1684, Validation Loss:2.4850, Validation Accuracy:0.1642
Epoch #36: Loss:2.4602, Accuracy:0.1647, Validation Loss:2.4853, Validation Accuracy:0.1724
Epoch #37: Loss:2.4597, Accuracy:0.1721, Validation Loss:2.4869, Validation Accuracy:0.1724
Epoch #38: Loss:2.4602, Accuracy:0.1713, Validation Loss:2.4838, Validation Accuracy:0.1790
Epoch #39: Loss:2.4586, Accuracy:0.1733, Validation Loss:2.4821, Validation Accuracy:0.1806
Epoch #40: Loss:2.4574, Accuracy:0.1737, Validation Loss:2.4807, Validation Accuracy:0.1806
Epoch #41: Loss:2.4579, Accuracy:0.1737, Validation Loss:2.4792, Validation Accuracy:0.1823
Epoch #42: Loss:2.4573, Accuracy:0.1721, Validation Loss:2.4769, Validation Accuracy:0.1839
Epoch #43: Loss:2.4557, Accuracy:0.1737, Validation Loss:2.4806, Validation Accuracy:0.1773
Epoch #44: Loss:2.4623, Accuracy:0.1741, Validation Loss:2.4833, Validation Accuracy:0.1708
Epoch #45: Loss:2.4565, Accuracy:0.1725, Validation Loss:2.4807, Validation Accuracy:0.1626
Epoch #46: Loss:2.4557, Accuracy:0.1729, Validation Loss:2.4749, Validation Accuracy:0.1675
Epoch #47: Loss:2.4552, Accuracy:0.1655, Validation Loss:2.4765, Validation Accuracy:0.1708
Epoch #48: Loss:2.4525, Accuracy:0.1741, Validation Loss:2.4754, Validation Accuracy:0.1609
Epoch #49: Loss:2.4555, Accuracy:0.1688, Validation Loss:2.4743, Validation Accuracy:0.1823
Epoch #50: Loss:2.4621, Accuracy:0.1696, Validation Loss:2.4757, Validation Accuracy:0.1790
Epoch #51: Loss:2.4633, Accuracy:0.1614, Validation Loss:2.4835, Validation Accuracy:0.1544
Epoch #52: Loss:2.4630, Accuracy:0.1676, Validation Loss:2.4702, Validation Accuracy:0.1757
Epoch #53: Loss:2.4616, Accuracy:0.1643, Validation Loss:2.4729, Validation Accuracy:0.1856
Epoch #54: Loss:2.4564, Accuracy:0.1708, Validation Loss:2.4762, Validation Accuracy:0.1494
Epoch #55: Loss:2.4564, Accuracy:0.1688, Validation Loss:2.4729, Validation Accuracy:0.1724
Epoch #56: Loss:2.4541, Accuracy:0.1696, Validation Loss:2.4752, Validation Accuracy:0.1741
Epoch #57: Loss:2.4553, Accuracy:0.1680, Validation Loss:2.4778, Validation Accuracy:0.1708
Epoch #58: Loss:2.4558, Accuracy:0.1733, Validation Loss:2.4789, Validation Accuracy:0.1741
Epoch #59: Loss:2.4542, Accuracy:0.1704, Validation Loss:2.4784, Validation Accuracy:0.1741
Epoch #60: Loss:2.4545, Accuracy:0.1671, Validation Loss:2.4777, Validation Accuracy:0.1757
Epoch #61: Loss:2.4511, Accuracy:0.1704, Validation Loss:2.4770, Validation Accuracy:0.1741
Epoch #62: Loss:2.4504, Accuracy:0.1713, Validation Loss:2.4745, Validation Accuracy:0.1757
Epoch #63: Loss:2.4500, Accuracy:0.1680, Validation Loss:2.4760, Validation Accuracy:0.1773
Epoch #64: Loss:2.4479, Accuracy:0.1688, Validation Loss:2.4777, Validation Accuracy:0.1741
Epoch #65: Loss:2.4509, Accuracy:0.1684, Validation Loss:2.4789, Validation Accuracy:0.1741
Epoch #66: Loss:2.4513, Accuracy:0.1676, Validation Loss:2.4777, Validation Accuracy:0.1773
Epoch #67: Loss:2.4507, Accuracy:0.1684, Validation Loss:2.4754, Validation Accuracy:0.1790
Epoch #68: Loss:2.4509, Accuracy:0.1708, Validation Loss:2.4750, Validation Accuracy:0.1724
Epoch #69: Loss:2.4484, Accuracy:0.1729, Validation Loss:2.4740, Validation Accuracy:0.1675
Epoch #70: Loss:2.4471, Accuracy:0.1692, Validation Loss:2.4734, Validation Accuracy:0.1741
Epoch #71: Loss:2.4474, Accuracy:0.1745, Validation Loss:2.4769, Validation Accuracy:0.1773
Epoch #72: Loss:2.4470, Accuracy:0.1733, Validation Loss:2.4745, Validation Accuracy:0.1757
Epoch #73: Loss:2.4479, Accuracy:0.1708, Validation Loss:2.4754, Validation Accuracy:0.1724
Epoch #74: Loss:2.4470, Accuracy:0.1725, Validation Loss:2.4749, Validation Accuracy:0.1724
Epoch #75: Loss:2.4470, Accuracy:0.1729, Validation Loss:2.4746, Validation Accuracy:0.1773
Epoch #76: Loss:2.4484, Accuracy:0.1737, Validation Loss:2.4785, Validation Accuracy:0.1790
Epoch #77: Loss:2.4467, Accuracy:0.1749, Validation Loss:2.4733, Validation Accuracy:0.1741
Epoch #78: Loss:2.4471, Accuracy:0.1713, Validation Loss:2.4751, Validation Accuracy:0.1757
Epoch #79: Loss:2.4462, Accuracy:0.1721, Validation Loss:2.4747, Validation Accuracy:0.1724
Epoch #80: Loss:2.4458, Accuracy:0.1696, Validation Loss:2.4741, Validation Accuracy:0.1741
Epoch #81: Loss:2.4434, Accuracy:0.1725, Validation Loss:2.4745, Validation Accuracy:0.1757
Epoch #82: Loss:2.4429, Accuracy:0.1729, Validation Loss:2.4754, Validation Accuracy:0.1757
Epoch #83: Loss:2.4425, Accuracy:0.1733, Validation Loss:2.4737, Validation Accuracy:0.1757
Epoch #84: Loss:2.4424, Accuracy:0.1721, Validation Loss:2.4751, Validation Accuracy:0.1724
Epoch #85: Loss:2.4422, Accuracy:0.1741, Validation Loss:2.4746, Validation Accuracy:0.1757
Epoch #86: Loss:2.4427, Accuracy:0.1778, Validation Loss:2.4729, Validation Accuracy:0.1757
Epoch #87: Loss:2.4422, Accuracy:0.1770, Validation Loss:2.4732, Validation Accuracy:0.1708
Epoch #88: Loss:2.4426, Accuracy:0.1745, Validation Loss:2.4758, Validation Accuracy:0.1691
Epoch #89: Loss:2.4420, Accuracy:0.1778, Validation Loss:2.4755, Validation Accuracy:0.1724
Epoch #90: Loss:2.4421, Accuracy:0.1762, Validation Loss:2.4763, Validation Accuracy:0.1741
Epoch #91: Loss:2.4423, Accuracy:0.1704, Validation Loss:2.4774, Validation Accuracy:0.1724
Epoch #92: Loss:2.4421, Accuracy:0.1766, Validation Loss:2.4771, Validation Accuracy:0.1708
Epoch #93: Loss:2.4422, Accuracy:0.1762, Validation Loss:2.4770, Validation Accuracy:0.1708
Epoch #94: Loss:2.4422, Accuracy:0.1770, Validation Loss:2.4794, Validation Accuracy:0.1708
Epoch #95: Loss:2.4413, Accuracy:0.1774, Validation Loss:2.4767, Validation Accuracy:0.1708
Epoch #96: Loss:2.4409, Accuracy:0.1758, Validation Loss:2.4769, Validation Accuracy:0.1708
Epoch #97: Loss:2.4405, Accuracy:0.1766, Validation Loss:2.4778, Validation Accuracy:0.1708
Epoch #98: Loss:2.4409, Accuracy:0.1774, Validation Loss:2.4778, Validation Accuracy:0.1691
Epoch #99: Loss:2.4405, Accuracy:0.1774, Validation Loss:2.4786, Validation Accuracy:0.1724
Epoch #100: Loss:2.4409, Accuracy:0.1770, Validation Loss:2.4776, Validation Accuracy:0.1675
Epoch #101: Loss:2.4403, Accuracy:0.1795, Validation Loss:2.4769, Validation Accuracy:0.1757
Epoch #102: Loss:2.4410, Accuracy:0.1791, Validation Loss:2.4800, Validation Accuracy:0.1790
Epoch #103: Loss:2.4440, Accuracy:0.1791, Validation Loss:2.4793, Validation Accuracy:0.1757
Epoch #104: Loss:2.4441, Accuracy:0.1791, Validation Loss:2.4838, Validation Accuracy:0.1773
Epoch #105: Loss:2.4417, Accuracy:0.1762, Validation Loss:2.4768, Validation Accuracy:0.1708
Epoch #106: Loss:2.4413, Accuracy:0.1758, Validation Loss:2.4792, Validation Accuracy:0.1757
Epoch #107: Loss:2.4408, Accuracy:0.1778, Validation Loss:2.4786, Validation Accuracy:0.1757
Epoch #108: Loss:2.4406, Accuracy:0.1778, Validation Loss:2.4765, Validation Accuracy:0.1708
Epoch #109: Loss:2.4409, Accuracy:0.1766, Validation Loss:2.4764, Validation Accuracy:0.1757
Epoch #110: Loss:2.4404, Accuracy:0.1782, Validation Loss:2.4773, Validation Accuracy:0.1757
Epoch #111: Loss:2.4402, Accuracy:0.1786, Validation Loss:2.4766, Validation Accuracy:0.1757
Epoch #112: Loss:2.4399, Accuracy:0.1782, Validation Loss:2.4763, Validation Accuracy:0.1757
Epoch #113: Loss:2.4403, Accuracy:0.1786, Validation Loss:2.4757, Validation Accuracy:0.1741
Epoch #114: Loss:2.4407, Accuracy:0.1774, Validation Loss:2.4755, Validation Accuracy:0.1741
Epoch #115: Loss:2.4407, Accuracy:0.1766, Validation Loss:2.4773, Validation Accuracy:0.1741
Epoch #116: Loss:2.4418, Accuracy:0.1770, Validation Loss:2.4771, Validation Accuracy:0.1724
Epoch #117: Loss:2.4410, Accuracy:0.1770, Validation Loss:2.4750, Validation Accuracy:0.1708
Epoch #118: Loss:2.4411, Accuracy:0.1766, Validation Loss:2.4792, Validation Accuracy:0.1724
Epoch #119: Loss:2.4408, Accuracy:0.1774, Validation Loss:2.4760, Validation Accuracy:0.1708
Epoch #120: Loss:2.4405, Accuracy:0.1762, Validation Loss:2.4782, Validation Accuracy:0.1724
Epoch #121: Loss:2.4399, Accuracy:0.1770, Validation Loss:2.4760, Validation Accuracy:0.1708
Epoch #122: Loss:2.4397, Accuracy:0.1766, Validation Loss:2.4754, Validation Accuracy:0.1708
Epoch #123: Loss:2.4393, Accuracy:0.1778, Validation Loss:2.4772, Validation Accuracy:0.1741
Epoch #124: Loss:2.4398, Accuracy:0.1774, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #125: Loss:2.4398, Accuracy:0.1766, Validation Loss:2.4761, Validation Accuracy:0.1708
Epoch #126: Loss:2.4397, Accuracy:0.1786, Validation Loss:2.4813, Validation Accuracy:0.1757
Epoch #127: Loss:2.4391, Accuracy:0.1782, Validation Loss:2.4763, Validation Accuracy:0.1708
Epoch #128: Loss:2.4397, Accuracy:0.1762, Validation Loss:2.4759, Validation Accuracy:0.1708
Epoch #129: Loss:2.4388, Accuracy:0.1795, Validation Loss:2.4806, Validation Accuracy:0.1757
Epoch #130: Loss:2.4396, Accuracy:0.1782, Validation Loss:2.4767, Validation Accuracy:0.1708
Epoch #131: Loss:2.4401, Accuracy:0.1762, Validation Loss:2.4776, Validation Accuracy:0.1757
Epoch #132: Loss:2.4392, Accuracy:0.1782, Validation Loss:2.4798, Validation Accuracy:0.1757
Epoch #133: Loss:2.4388, Accuracy:0.1778, Validation Loss:2.4758, Validation Accuracy:0.1708
Epoch #134: Loss:2.4388, Accuracy:0.1762, Validation Loss:2.4765, Validation Accuracy:0.1757
Epoch #135: Loss:2.4389, Accuracy:0.1774, Validation Loss:2.4774, Validation Accuracy:0.1757
Epoch #136: Loss:2.4384, Accuracy:0.1782, Validation Loss:2.4760, Validation Accuracy:0.1757
Epoch #137: Loss:2.4383, Accuracy:0.1774, Validation Loss:2.4760, Validation Accuracy:0.1708
Epoch #138: Loss:2.4382, Accuracy:0.1762, Validation Loss:2.4769, Validation Accuracy:0.1757
Epoch #139: Loss:2.4398, Accuracy:0.1799, Validation Loss:2.4784, Validation Accuracy:0.1708
Epoch #140: Loss:2.4381, Accuracy:0.1766, Validation Loss:2.4757, Validation Accuracy:0.1708
Epoch #141: Loss:2.4373, Accuracy:0.1770, Validation Loss:2.4808, Validation Accuracy:0.1757
Epoch #142: Loss:2.4381, Accuracy:0.1778, Validation Loss:2.4764, Validation Accuracy:0.1724
Epoch #143: Loss:2.4376, Accuracy:0.1766, Validation Loss:2.4766, Validation Accuracy:0.1724
Epoch #144: Loss:2.4376, Accuracy:0.1762, Validation Loss:2.4757, Validation Accuracy:0.1724
Epoch #145: Loss:2.4375, Accuracy:0.1762, Validation Loss:2.4771, Validation Accuracy:0.1757
Epoch #146: Loss:2.4378, Accuracy:0.1778, Validation Loss:2.4772, Validation Accuracy:0.1757
Epoch #147: Loss:2.4376, Accuracy:0.1778, Validation Loss:2.4765, Validation Accuracy:0.1724
Epoch #148: Loss:2.4374, Accuracy:0.1762, Validation Loss:2.4751, Validation Accuracy:0.1724
Epoch #149: Loss:2.4374, Accuracy:0.1774, Validation Loss:2.4778, Validation Accuracy:0.1741
Epoch #150: Loss:2.4375, Accuracy:0.1766, Validation Loss:2.4750, Validation Accuracy:0.1724
Epoch #151: Loss:2.4371, Accuracy:0.1770, Validation Loss:2.4753, Validation Accuracy:0.1724
Epoch #152: Loss:2.4368, Accuracy:0.1766, Validation Loss:2.4757, Validation Accuracy:0.1741
Epoch #153: Loss:2.4367, Accuracy:0.1770, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #154: Loss:2.4368, Accuracy:0.1766, Validation Loss:2.4759, Validation Accuracy:0.1691
Epoch #155: Loss:2.4380, Accuracy:0.1762, Validation Loss:2.4756, Validation Accuracy:0.1724
Epoch #156: Loss:2.4368, Accuracy:0.1770, Validation Loss:2.4792, Validation Accuracy:0.1741
Epoch #157: Loss:2.4373, Accuracy:0.1754, Validation Loss:2.4748, Validation Accuracy:0.1724
Epoch #158: Loss:2.4369, Accuracy:0.1766, Validation Loss:2.4775, Validation Accuracy:0.1724
Epoch #159: Loss:2.4372, Accuracy:0.1762, Validation Loss:2.4749, Validation Accuracy:0.1724
Epoch #160: Loss:2.4365, Accuracy:0.1778, Validation Loss:2.4783, Validation Accuracy:0.1741
Epoch #161: Loss:2.4363, Accuracy:0.1782, Validation Loss:2.4744, Validation Accuracy:0.1724
Epoch #162: Loss:2.4364, Accuracy:0.1770, Validation Loss:2.4758, Validation Accuracy:0.1724
Epoch #163: Loss:2.4365, Accuracy:0.1774, Validation Loss:2.4760, Validation Accuracy:0.1724
Epoch #164: Loss:2.4371, Accuracy:0.1770, Validation Loss:2.4739, Validation Accuracy:0.1724
Epoch #165: Loss:2.4359, Accuracy:0.1786, Validation Loss:2.4806, Validation Accuracy:0.1675
Epoch #166: Loss:2.4364, Accuracy:0.1766, Validation Loss:2.4748, Validation Accuracy:0.1724
Epoch #167: Loss:2.4375, Accuracy:0.1770, Validation Loss:2.4755, Validation Accuracy:0.1724
Epoch #168: Loss:2.4359, Accuracy:0.1749, Validation Loss:2.4797, Validation Accuracy:0.1724
Epoch #169: Loss:2.4377, Accuracy:0.1770, Validation Loss:2.4737, Validation Accuracy:0.1724
Epoch #170: Loss:2.4353, Accuracy:0.1766, Validation Loss:2.4783, Validation Accuracy:0.1724
Epoch #171: Loss:2.4367, Accuracy:0.1762, Validation Loss:2.4754, Validation Accuracy:0.1724
Epoch #172: Loss:2.4362, Accuracy:0.1770, Validation Loss:2.4740, Validation Accuracy:0.1724
Epoch #173: Loss:2.4373, Accuracy:0.1758, Validation Loss:2.4776, Validation Accuracy:0.1675
Epoch #174: Loss:2.4361, Accuracy:0.1778, Validation Loss:2.4735, Validation Accuracy:0.1724
Epoch #175: Loss:2.4354, Accuracy:0.1762, Validation Loss:2.4764, Validation Accuracy:0.1724
Epoch #176: Loss:2.4360, Accuracy:0.1770, Validation Loss:2.4752, Validation Accuracy:0.1724
Epoch #177: Loss:2.4354, Accuracy:0.1766, Validation Loss:2.4750, Validation Accuracy:0.1724
Epoch #178: Loss:2.4363, Accuracy:0.1754, Validation Loss:2.4762, Validation Accuracy:0.1675
Epoch #179: Loss:2.4360, Accuracy:0.1770, Validation Loss:2.4771, Validation Accuracy:0.1708
Epoch #180: Loss:2.4355, Accuracy:0.1770, Validation Loss:2.4767, Validation Accuracy:0.1708
Epoch #181: Loss:2.4358, Accuracy:0.1766, Validation Loss:2.4773, Validation Accuracy:0.1708
Epoch #182: Loss:2.4357, Accuracy:0.1770, Validation Loss:2.4787, Validation Accuracy:0.1724
Epoch #183: Loss:2.4361, Accuracy:0.1770, Validation Loss:2.4765, Validation Accuracy:0.1708
Epoch #184: Loss:2.4356, Accuracy:0.1762, Validation Loss:2.4788, Validation Accuracy:0.1724
Epoch #185: Loss:2.4366, Accuracy:0.1741, Validation Loss:2.4773, Validation Accuracy:0.1708
Epoch #186: Loss:2.4360, Accuracy:0.1766, Validation Loss:2.4759, Validation Accuracy:0.1708
Epoch #187: Loss:2.4358, Accuracy:0.1766, Validation Loss:2.4782, Validation Accuracy:0.1724
Epoch #188: Loss:2.4367, Accuracy:0.1741, Validation Loss:2.4775, Validation Accuracy:0.1708
Epoch #189: Loss:2.4360, Accuracy:0.1766, Validation Loss:2.4766, Validation Accuracy:0.1708
Epoch #190: Loss:2.4355, Accuracy:0.1766, Validation Loss:2.4795, Validation Accuracy:0.1724
Epoch #191: Loss:2.4361, Accuracy:0.1774, Validation Loss:2.4770, Validation Accuracy:0.1708
Epoch #192: Loss:2.4356, Accuracy:0.1762, Validation Loss:2.4775, Validation Accuracy:0.1708
Epoch #193: Loss:2.4365, Accuracy:0.1770, Validation Loss:2.4810, Validation Accuracy:0.1724
Epoch #194: Loss:2.4359, Accuracy:0.1766, Validation Loss:2.4755, Validation Accuracy:0.1708
Epoch #195: Loss:2.4356, Accuracy:0.1766, Validation Loss:2.4783, Validation Accuracy:0.1708
Epoch #196: Loss:2.4369, Accuracy:0.1729, Validation Loss:2.4801, Validation Accuracy:0.1724
Epoch #197: Loss:2.4368, Accuracy:0.1766, Validation Loss:2.4744, Validation Accuracy:0.1724
Epoch #198: Loss:2.4357, Accuracy:0.1754, Validation Loss:2.4785, Validation Accuracy:0.1708
Epoch #199: Loss:2.4340, Accuracy:0.1733, Validation Loss:2.4728, Validation Accuracy:0.1691
Epoch #200: Loss:2.4340, Accuracy:0.1754, Validation Loss:2.4736, Validation Accuracy:0.1724
Epoch #201: Loss:2.4357, Accuracy:0.1749, Validation Loss:2.4723, Validation Accuracy:0.1691
Epoch #202: Loss:2.4354, Accuracy:0.1745, Validation Loss:2.4707, Validation Accuracy:0.1708
Epoch #203: Loss:2.4360, Accuracy:0.1745, Validation Loss:2.4739, Validation Accuracy:0.1741
Epoch #204: Loss:2.4349, Accuracy:0.1770, Validation Loss:2.4720, Validation Accuracy:0.1741
Epoch #205: Loss:2.4345, Accuracy:0.1770, Validation Loss:2.4711, Validation Accuracy:0.1773
Epoch #206: Loss:2.4339, Accuracy:0.1782, Validation Loss:2.4716, Validation Accuracy:0.1741
Epoch #207: Loss:2.4333, Accuracy:0.1766, Validation Loss:2.4711, Validation Accuracy:0.1741
Epoch #208: Loss:2.4332, Accuracy:0.1778, Validation Loss:2.4716, Validation Accuracy:0.1741
Epoch #209: Loss:2.4332, Accuracy:0.1778, Validation Loss:2.4719, Validation Accuracy:0.1724
Epoch #210: Loss:2.4333, Accuracy:0.1758, Validation Loss:2.4743, Validation Accuracy:0.1741
Epoch #211: Loss:2.4341, Accuracy:0.1766, Validation Loss:2.4750, Validation Accuracy:0.1741
Epoch #212: Loss:2.4341, Accuracy:0.1762, Validation Loss:2.4741, Validation Accuracy:0.1724
Epoch #213: Loss:2.4334, Accuracy:0.1774, Validation Loss:2.4737, Validation Accuracy:0.1724
Epoch #214: Loss:2.4331, Accuracy:0.1754, Validation Loss:2.4747, Validation Accuracy:0.1741
Epoch #215: Loss:2.4340, Accuracy:0.1754, Validation Loss:2.4758, Validation Accuracy:0.1741
Epoch #216: Loss:2.4333, Accuracy:0.1766, Validation Loss:2.4756, Validation Accuracy:0.1741
Epoch #217: Loss:2.4332, Accuracy:0.1766, Validation Loss:2.4782, Validation Accuracy:0.1741
Epoch #218: Loss:2.4329, Accuracy:0.1758, Validation Loss:2.4763, Validation Accuracy:0.1757
Epoch #219: Loss:2.4326, Accuracy:0.1766, Validation Loss:2.4762, Validation Accuracy:0.1757
Epoch #220: Loss:2.4327, Accuracy:0.1762, Validation Loss:2.4744, Validation Accuracy:0.1757
Epoch #221: Loss:2.4326, Accuracy:0.1766, Validation Loss:2.4747, Validation Accuracy:0.1741
Epoch #222: Loss:2.4328, Accuracy:0.1729, Validation Loss:2.4755, Validation Accuracy:0.1741
Epoch #223: Loss:2.4324, Accuracy:0.1762, Validation Loss:2.4764, Validation Accuracy:0.1724
Epoch #224: Loss:2.4322, Accuracy:0.1762, Validation Loss:2.4767, Validation Accuracy:0.1741
Epoch #225: Loss:2.4322, Accuracy:0.1766, Validation Loss:2.4744, Validation Accuracy:0.1741
Epoch #226: Loss:2.4321, Accuracy:0.1762, Validation Loss:2.4769, Validation Accuracy:0.1724
Epoch #227: Loss:2.4323, Accuracy:0.1782, Validation Loss:2.4781, Validation Accuracy:0.1724
Epoch #228: Loss:2.4338, Accuracy:0.1762, Validation Loss:2.4740, Validation Accuracy:0.1741
Epoch #229: Loss:2.4319, Accuracy:0.1786, Validation Loss:2.4804, Validation Accuracy:0.1773
Epoch #230: Loss:2.4330, Accuracy:0.1754, Validation Loss:2.4740, Validation Accuracy:0.1741
Epoch #231: Loss:2.4326, Accuracy:0.1766, Validation Loss:2.4767, Validation Accuracy:0.1741
Epoch #232: Loss:2.4325, Accuracy:0.1762, Validation Loss:2.4782, Validation Accuracy:0.1708
Epoch #233: Loss:2.4319, Accuracy:0.1745, Validation Loss:2.4760, Validation Accuracy:0.1724
Epoch #234: Loss:2.4327, Accuracy:0.1749, Validation Loss:2.4778, Validation Accuracy:0.1724
Epoch #235: Loss:2.4312, Accuracy:0.1762, Validation Loss:2.4740, Validation Accuracy:0.1741
Epoch #236: Loss:2.4321, Accuracy:0.1766, Validation Loss:2.4767, Validation Accuracy:0.1741
Epoch #237: Loss:2.4319, Accuracy:0.1770, Validation Loss:2.4758, Validation Accuracy:0.1741
Epoch #238: Loss:2.4314, Accuracy:0.1766, Validation Loss:2.4765, Validation Accuracy:0.1741
Epoch #239: Loss:2.4312, Accuracy:0.1762, Validation Loss:2.4784, Validation Accuracy:0.1724
Epoch #240: Loss:2.4316, Accuracy:0.1762, Validation Loss:2.4771, Validation Accuracy:0.1741
Epoch #241: Loss:2.4315, Accuracy:0.1770, Validation Loss:2.4765, Validation Accuracy:0.1741
Epoch #242: Loss:2.4316, Accuracy:0.1741, Validation Loss:2.4775, Validation Accuracy:0.1741
Epoch #243: Loss:2.4313, Accuracy:0.1766, Validation Loss:2.4762, Validation Accuracy:0.1741
Epoch #244: Loss:2.4313, Accuracy:0.1754, Validation Loss:2.4779, Validation Accuracy:0.1691
Epoch #245: Loss:2.4315, Accuracy:0.1762, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #246: Loss:2.4310, Accuracy:0.1766, Validation Loss:2.4777, Validation Accuracy:0.1773
Epoch #247: Loss:2.4320, Accuracy:0.1778, Validation Loss:2.4758, Validation Accuracy:0.1741
Epoch #248: Loss:2.4314, Accuracy:0.1721, Validation Loss:2.4809, Validation Accuracy:0.1757
Epoch #249: Loss:2.4308, Accuracy:0.1754, Validation Loss:2.4756, Validation Accuracy:0.1724
Epoch #250: Loss:2.4315, Accuracy:0.1770, Validation Loss:2.4749, Validation Accuracy:0.1757
Epoch #251: Loss:2.4316, Accuracy:0.1770, Validation Loss:2.4809, Validation Accuracy:0.1806
Epoch #252: Loss:2.4308, Accuracy:0.1766, Validation Loss:2.4758, Validation Accuracy:0.1741
Epoch #253: Loss:2.4321, Accuracy:0.1770, Validation Loss:2.4778, Validation Accuracy:0.1724
Epoch #254: Loss:2.4301, Accuracy:0.1754, Validation Loss:2.4829, Validation Accuracy:0.1790
Epoch #255: Loss:2.4320, Accuracy:0.1766, Validation Loss:2.4756, Validation Accuracy:0.1741
Epoch #256: Loss:2.4309, Accuracy:0.1766, Validation Loss:2.4792, Validation Accuracy:0.1790
Epoch #257: Loss:2.4326, Accuracy:0.1770, Validation Loss:2.4799, Validation Accuracy:0.1773
Epoch #258: Loss:2.4332, Accuracy:0.1737, Validation Loss:2.4756, Validation Accuracy:0.1741
Epoch #259: Loss:2.4303, Accuracy:0.1762, Validation Loss:2.4846, Validation Accuracy:0.1806
Epoch #260: Loss:2.4316, Accuracy:0.1770, Validation Loss:2.4766, Validation Accuracy:0.1741
Epoch #261: Loss:2.4306, Accuracy:0.1766, Validation Loss:2.4778, Validation Accuracy:0.1741
Epoch #262: Loss:2.4312, Accuracy:0.1762, Validation Loss:2.4801, Validation Accuracy:0.1757
Epoch #263: Loss:2.4296, Accuracy:0.1766, Validation Loss:2.4757, Validation Accuracy:0.1741
Epoch #264: Loss:2.4308, Accuracy:0.1766, Validation Loss:2.4789, Validation Accuracy:0.1806
Epoch #265: Loss:2.4303, Accuracy:0.1749, Validation Loss:2.4773, Validation Accuracy:0.1757
Epoch #266: Loss:2.4302, Accuracy:0.1778, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #267: Loss:2.4306, Accuracy:0.1766, Validation Loss:2.4786, Validation Accuracy:0.1806
Epoch #268: Loss:2.4301, Accuracy:0.1721, Validation Loss:2.4771, Validation Accuracy:0.1741
Epoch #269: Loss:2.4302, Accuracy:0.1799, Validation Loss:2.4794, Validation Accuracy:0.1773
Epoch #270: Loss:2.4340, Accuracy:0.1782, Validation Loss:2.4762, Validation Accuracy:0.1757
Epoch #271: Loss:2.4335, Accuracy:0.1745, Validation Loss:2.4888, Validation Accuracy:0.1593
Epoch #272: Loss:2.4317, Accuracy:0.1758, Validation Loss:2.4762, Validation Accuracy:0.1741
Epoch #273: Loss:2.4325, Accuracy:0.1766, Validation Loss:2.4788, Validation Accuracy:0.1790
Epoch #274: Loss:2.4304, Accuracy:0.1774, Validation Loss:2.4795, Validation Accuracy:0.1790
Epoch #275: Loss:2.4298, Accuracy:0.1778, Validation Loss:2.4758, Validation Accuracy:0.1741
Epoch #276: Loss:2.4297, Accuracy:0.1762, Validation Loss:2.4798, Validation Accuracy:0.1806
Epoch #277: Loss:2.4295, Accuracy:0.1766, Validation Loss:2.4783, Validation Accuracy:0.1790
Epoch #278: Loss:2.4305, Accuracy:0.1745, Validation Loss:2.4779, Validation Accuracy:0.1757
Epoch #279: Loss:2.4302, Accuracy:0.1758, Validation Loss:2.4822, Validation Accuracy:0.1806
Epoch #280: Loss:2.4298, Accuracy:0.1795, Validation Loss:2.4768, Validation Accuracy:0.1741
Epoch #281: Loss:2.4299, Accuracy:0.1795, Validation Loss:2.4796, Validation Accuracy:0.1790
Epoch #282: Loss:2.4291, Accuracy:0.1782, Validation Loss:2.4786, Validation Accuracy:0.1790
Epoch #283: Loss:2.4291, Accuracy:0.1782, Validation Loss:2.4803, Validation Accuracy:0.1790
Epoch #284: Loss:2.4289, Accuracy:0.1786, Validation Loss:2.4780, Validation Accuracy:0.1790
Epoch #285: Loss:2.4290, Accuracy:0.1782, Validation Loss:2.4777, Validation Accuracy:0.1790
Epoch #286: Loss:2.4291, Accuracy:0.1786, Validation Loss:2.4787, Validation Accuracy:0.1790
Epoch #287: Loss:2.4288, Accuracy:0.1749, Validation Loss:2.4782, Validation Accuracy:0.1757
Epoch #288: Loss:2.4287, Accuracy:0.1774, Validation Loss:2.4786, Validation Accuracy:0.1757
Epoch #289: Loss:2.4288, Accuracy:0.1791, Validation Loss:2.4802, Validation Accuracy:0.1790
Epoch #290: Loss:2.4290, Accuracy:0.1778, Validation Loss:2.4780, Validation Accuracy:0.1773
Epoch #291: Loss:2.4290, Accuracy:0.1791, Validation Loss:2.4798, Validation Accuracy:0.1790
Epoch #292: Loss:2.4292, Accuracy:0.1762, Validation Loss:2.4802, Validation Accuracy:0.1790
Epoch #293: Loss:2.4289, Accuracy:0.1774, Validation Loss:2.4770, Validation Accuracy:0.1741
Epoch #294: Loss:2.4292, Accuracy:0.1786, Validation Loss:2.4796, Validation Accuracy:0.1790
Epoch #295: Loss:2.4291, Accuracy:0.1791, Validation Loss:2.4783, Validation Accuracy:0.1790
Epoch #296: Loss:2.4288, Accuracy:0.1758, Validation Loss:2.4779, Validation Accuracy:0.1790
Epoch #297: Loss:2.4284, Accuracy:0.1774, Validation Loss:2.4826, Validation Accuracy:0.1823
Epoch #298: Loss:2.4291, Accuracy:0.1762, Validation Loss:2.4786, Validation Accuracy:0.1773
Epoch #299: Loss:2.4288, Accuracy:0.1786, Validation Loss:2.4808, Validation Accuracy:0.1757
Epoch #300: Loss:2.4288, Accuracy:0.1782, Validation Loss:2.4800, Validation Accuracy:0.1773

Test:

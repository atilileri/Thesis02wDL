======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf10.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.31 06:41:07 =======================================
Parameters: inputFolder : C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
sampRate : 8
featureMode : FrMgPh
channelMode : 3
classificationMode : Speaker
trainingEpoch : 300
stepSize : 1
batchSize : 512
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3044 Files with 15 Label(s): ['ce', 'mb', 'yd', 'by', 'ib', 'eg', 'ck', 'ek', 'eb', 'eo', 'sg', 'sk', 'ds', 'my', 'aa'].
Padding:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3044 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2435 steps for training, 609 steps for test
Splitting Train and Test Data...
------Model for FrMgPh------
---LSTM Classifier---
Train Batch: (2435, 7991, 42)
Test Batch: (609, 7991, 42)
Optimizer: <keras.optimizers.Adam object at 0x0000023D801E7F98>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000023DA7526048>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            16136     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 25,131
Trainable params: 25,131
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.7056, Accuracy:0.0587, Validation Loss:2.6966, Validation Accuracy:0.0821
Epoch #2: Loss:2.6906, Accuracy:0.1060, Validation Loss:2.6821, Validation Accuracy:0.1018
Epoch #3: Loss:2.6790, Accuracy:0.1023, Validation Loss:2.6742, Validation Accuracy:0.1018
Epoch #4: Loss:2.6722, Accuracy:0.1023, Validation Loss:2.6700, Validation Accuracy:0.1018
Epoch #5: Loss:2.6682, Accuracy:0.1023, Validation Loss:2.6636, Validation Accuracy:0.1018
Epoch #6: Loss:2.6613, Accuracy:0.1018, Validation Loss:2.6586, Validation Accuracy:0.1018
Epoch #7: Loss:2.6565, Accuracy:0.1014, Validation Loss:2.6531, Validation Accuracy:0.1034
Epoch #8: Loss:2.6513, Accuracy:0.1027, Validation Loss:2.6471, Validation Accuracy:0.1166
Epoch #9: Loss:2.6448, Accuracy:0.1199, Validation Loss:2.6403, Validation Accuracy:0.1363
Epoch #10: Loss:2.6375, Accuracy:0.1290, Validation Loss:2.6320, Validation Accuracy:0.1363
Epoch #11: Loss:2.6290, Accuracy:0.1331, Validation Loss:2.6255, Validation Accuracy:0.1379
Epoch #12: Loss:2.6211, Accuracy:0.1372, Validation Loss:2.6128, Validation Accuracy:0.1593
Epoch #13: Loss:2.6068, Accuracy:0.1639, Validation Loss:2.5987, Validation Accuracy:0.1478
Epoch #14: Loss:2.5917, Accuracy:0.1598, Validation Loss:2.5835, Validation Accuracy:0.1494
Epoch #15: Loss:2.5773, Accuracy:0.1606, Validation Loss:2.5724, Validation Accuracy:0.1494
Epoch #16: Loss:2.5635, Accuracy:0.1573, Validation Loss:2.5605, Validation Accuracy:0.1461
Epoch #17: Loss:2.5478, Accuracy:0.1552, Validation Loss:2.5539, Validation Accuracy:0.1461
Epoch #18: Loss:2.5367, Accuracy:0.1552, Validation Loss:2.5422, Validation Accuracy:0.1511
Epoch #19: Loss:2.5272, Accuracy:0.1585, Validation Loss:2.5345, Validation Accuracy:0.1527
Epoch #20: Loss:2.5170, Accuracy:0.1630, Validation Loss:2.5274, Validation Accuracy:0.1544
Epoch #21: Loss:2.5316, Accuracy:0.1630, Validation Loss:2.5387, Validation Accuracy:0.1576
Epoch #22: Loss:2.5177, Accuracy:0.1602, Validation Loss:2.5247, Validation Accuracy:0.1642
Epoch #23: Loss:2.5082, Accuracy:0.1618, Validation Loss:2.5167, Validation Accuracy:0.1527
Epoch #24: Loss:2.4995, Accuracy:0.1606, Validation Loss:2.5143, Validation Accuracy:0.1642
Epoch #25: Loss:2.4940, Accuracy:0.1680, Validation Loss:2.5126, Validation Accuracy:0.1544
Epoch #26: Loss:2.4889, Accuracy:0.1655, Validation Loss:2.5053, Validation Accuracy:0.1708
Epoch #27: Loss:2.4866, Accuracy:0.1688, Validation Loss:2.5071, Validation Accuracy:0.1658
Epoch #28: Loss:2.4858, Accuracy:0.1593, Validation Loss:2.5054, Validation Accuracy:0.1675
Epoch #29: Loss:2.4826, Accuracy:0.1532, Validation Loss:2.5026, Validation Accuracy:0.1658
Epoch #30: Loss:2.4787, Accuracy:0.1643, Validation Loss:2.4993, Validation Accuracy:0.1691
Epoch #31: Loss:2.4772, Accuracy:0.1647, Validation Loss:2.4959, Validation Accuracy:0.1708
Epoch #32: Loss:2.4734, Accuracy:0.1639, Validation Loss:2.4938, Validation Accuracy:0.1658
Epoch #33: Loss:2.4740, Accuracy:0.1581, Validation Loss:2.4947, Validation Accuracy:0.1708
Epoch #34: Loss:2.4748, Accuracy:0.1639, Validation Loss:2.4993, Validation Accuracy:0.1708
Epoch #35: Loss:2.4733, Accuracy:0.1626, Validation Loss:2.4985, Validation Accuracy:0.1708
Epoch #36: Loss:2.4721, Accuracy:0.1626, Validation Loss:2.4958, Validation Accuracy:0.1708
Epoch #37: Loss:2.4702, Accuracy:0.1622, Validation Loss:2.4920, Validation Accuracy:0.1658
Epoch #38: Loss:2.4675, Accuracy:0.1630, Validation Loss:2.4895, Validation Accuracy:0.1691
Epoch #39: Loss:2.4655, Accuracy:0.1647, Validation Loss:2.4859, Validation Accuracy:0.1708
Epoch #40: Loss:2.4630, Accuracy:0.1643, Validation Loss:2.4874, Validation Accuracy:0.1691
Epoch #41: Loss:2.4631, Accuracy:0.1671, Validation Loss:2.4837, Validation Accuracy:0.1658
Epoch #42: Loss:2.4618, Accuracy:0.1639, Validation Loss:2.4816, Validation Accuracy:0.1658
Epoch #43: Loss:2.4584, Accuracy:0.1655, Validation Loss:2.4795, Validation Accuracy:0.1675
Epoch #44: Loss:2.4585, Accuracy:0.1655, Validation Loss:2.4785, Validation Accuracy:0.1708
Epoch #45: Loss:2.4554, Accuracy:0.1655, Validation Loss:2.4773, Validation Accuracy:0.1708
Epoch #46: Loss:2.4549, Accuracy:0.1651, Validation Loss:2.4768, Validation Accuracy:0.1708
Epoch #47: Loss:2.4545, Accuracy:0.1663, Validation Loss:2.4767, Validation Accuracy:0.1642
Epoch #48: Loss:2.4526, Accuracy:0.1700, Validation Loss:2.4741, Validation Accuracy:0.1708
Epoch #49: Loss:2.4528, Accuracy:0.1688, Validation Loss:2.4763, Validation Accuracy:0.1708
Epoch #50: Loss:2.4520, Accuracy:0.1713, Validation Loss:2.4756, Validation Accuracy:0.1741
Epoch #51: Loss:2.4496, Accuracy:0.1704, Validation Loss:2.4760, Validation Accuracy:0.1708
Epoch #52: Loss:2.4515, Accuracy:0.1671, Validation Loss:2.4750, Validation Accuracy:0.1757
Epoch #53: Loss:2.4535, Accuracy:0.1700, Validation Loss:2.4780, Validation Accuracy:0.1757
Epoch #54: Loss:2.4529, Accuracy:0.1671, Validation Loss:2.4741, Validation Accuracy:0.1757
Epoch #55: Loss:2.4538, Accuracy:0.1737, Validation Loss:2.4731, Validation Accuracy:0.1790
Epoch #56: Loss:2.4539, Accuracy:0.1663, Validation Loss:2.4686, Validation Accuracy:0.1773
Epoch #57: Loss:2.4536, Accuracy:0.1725, Validation Loss:2.4687, Validation Accuracy:0.1757
Epoch #58: Loss:2.4536, Accuracy:0.1696, Validation Loss:2.4695, Validation Accuracy:0.1741
Epoch #59: Loss:2.4501, Accuracy:0.1713, Validation Loss:2.4679, Validation Accuracy:0.1823
Epoch #60: Loss:2.4481, Accuracy:0.1737, Validation Loss:2.4726, Validation Accuracy:0.1593
Epoch #61: Loss:2.4490, Accuracy:0.1626, Validation Loss:2.4639, Validation Accuracy:0.1806
Epoch #62: Loss:2.4456, Accuracy:0.1676, Validation Loss:2.4671, Validation Accuracy:0.1724
Epoch #63: Loss:2.4446, Accuracy:0.1680, Validation Loss:2.4643, Validation Accuracy:0.1856
Epoch #64: Loss:2.4452, Accuracy:0.1725, Validation Loss:2.4652, Validation Accuracy:0.1872
Epoch #65: Loss:2.4433, Accuracy:0.1754, Validation Loss:2.4638, Validation Accuracy:0.1888
Epoch #66: Loss:2.4427, Accuracy:0.1741, Validation Loss:2.4639, Validation Accuracy:0.1888
Epoch #67: Loss:2.4424, Accuracy:0.1749, Validation Loss:2.4649, Validation Accuracy:0.1872
Epoch #68: Loss:2.4422, Accuracy:0.1762, Validation Loss:2.4629, Validation Accuracy:0.1888
Epoch #69: Loss:2.4416, Accuracy:0.1799, Validation Loss:2.4633, Validation Accuracy:0.1823
Epoch #70: Loss:2.4410, Accuracy:0.1803, Validation Loss:2.4653, Validation Accuracy:0.1823
Epoch #71: Loss:2.4411, Accuracy:0.1745, Validation Loss:2.4614, Validation Accuracy:0.1888
Epoch #72: Loss:2.4415, Accuracy:0.1799, Validation Loss:2.4578, Validation Accuracy:0.1839
Epoch #73: Loss:2.4437, Accuracy:0.1774, Validation Loss:2.4722, Validation Accuracy:0.1806
Epoch #74: Loss:2.4474, Accuracy:0.1733, Validation Loss:2.4576, Validation Accuracy:0.1806
Epoch #75: Loss:2.4454, Accuracy:0.1770, Validation Loss:2.4633, Validation Accuracy:0.1806
Epoch #76: Loss:2.4401, Accuracy:0.1791, Validation Loss:2.4617, Validation Accuracy:0.1856
Epoch #77: Loss:2.4406, Accuracy:0.1782, Validation Loss:2.4658, Validation Accuracy:0.1757
Epoch #78: Loss:2.4416, Accuracy:0.1741, Validation Loss:2.4627, Validation Accuracy:0.1773
Epoch #79: Loss:2.4411, Accuracy:0.1815, Validation Loss:2.4635, Validation Accuracy:0.1856
Epoch #80: Loss:2.4398, Accuracy:0.1786, Validation Loss:2.4678, Validation Accuracy:0.1790
Epoch #81: Loss:2.4395, Accuracy:0.1840, Validation Loss:2.4641, Validation Accuracy:0.1856
Epoch #82: Loss:2.4369, Accuracy:0.1828, Validation Loss:2.4685, Validation Accuracy:0.1790
Epoch #83: Loss:2.4360, Accuracy:0.1786, Validation Loss:2.4637, Validation Accuracy:0.1856
Epoch #84: Loss:2.4358, Accuracy:0.1811, Validation Loss:2.4651, Validation Accuracy:0.1806
Epoch #85: Loss:2.4347, Accuracy:0.1791, Validation Loss:2.4638, Validation Accuracy:0.1905
Epoch #86: Loss:2.4349, Accuracy:0.1791, Validation Loss:2.4635, Validation Accuracy:0.1888
Epoch #87: Loss:2.4348, Accuracy:0.1803, Validation Loss:2.4642, Validation Accuracy:0.1790
Epoch #88: Loss:2.4340, Accuracy:0.1815, Validation Loss:2.4693, Validation Accuracy:0.1839
Epoch #89: Loss:2.4361, Accuracy:0.1803, Validation Loss:2.4689, Validation Accuracy:0.1806
Epoch #90: Loss:2.4380, Accuracy:0.1737, Validation Loss:2.4692, Validation Accuracy:0.1905
Epoch #91: Loss:2.4378, Accuracy:0.1766, Validation Loss:2.4683, Validation Accuracy:0.1856
Epoch #92: Loss:2.4365, Accuracy:0.1803, Validation Loss:2.4721, Validation Accuracy:0.1856
Epoch #93: Loss:2.4354, Accuracy:0.1766, Validation Loss:2.4658, Validation Accuracy:0.1773
Epoch #94: Loss:2.4343, Accuracy:0.1819, Validation Loss:2.4669, Validation Accuracy:0.1872
Epoch #95: Loss:2.4338, Accuracy:0.1803, Validation Loss:2.4650, Validation Accuracy:0.1872
Epoch #96: Loss:2.4330, Accuracy:0.1807, Validation Loss:2.4669, Validation Accuracy:0.1856
Epoch #97: Loss:2.4324, Accuracy:0.1819, Validation Loss:2.4642, Validation Accuracy:0.1790
Epoch #98: Loss:2.4322, Accuracy:0.1803, Validation Loss:2.4648, Validation Accuracy:0.1773
Epoch #99: Loss:2.4325, Accuracy:0.1815, Validation Loss:2.4664, Validation Accuracy:0.1757
Epoch #100: Loss:2.4313, Accuracy:0.1807, Validation Loss:2.4653, Validation Accuracy:0.1888
Epoch #101: Loss:2.4318, Accuracy:0.1828, Validation Loss:2.4657, Validation Accuracy:0.1872
Epoch #102: Loss:2.4309, Accuracy:0.1791, Validation Loss:2.4704, Validation Accuracy:0.1757
Epoch #103: Loss:2.4326, Accuracy:0.1844, Validation Loss:2.4682, Validation Accuracy:0.1790
Epoch #104: Loss:2.4317, Accuracy:0.1823, Validation Loss:2.4719, Validation Accuracy:0.1741
Epoch #105: Loss:2.4313, Accuracy:0.1803, Validation Loss:2.4708, Validation Accuracy:0.1757
Epoch #106: Loss:2.4318, Accuracy:0.1807, Validation Loss:2.4716, Validation Accuracy:0.1757
Epoch #107: Loss:2.4313, Accuracy:0.1807, Validation Loss:2.4720, Validation Accuracy:0.1757
Epoch #108: Loss:2.4311, Accuracy:0.1832, Validation Loss:2.4730, Validation Accuracy:0.1856
Epoch #109: Loss:2.4323, Accuracy:0.1754, Validation Loss:2.4712, Validation Accuracy:0.1806
Epoch #110: Loss:2.4312, Accuracy:0.1770, Validation Loss:2.4703, Validation Accuracy:0.1773
Epoch #111: Loss:2.4306, Accuracy:0.1828, Validation Loss:2.4686, Validation Accuracy:0.1741
Epoch #112: Loss:2.4318, Accuracy:0.1836, Validation Loss:2.4679, Validation Accuracy:0.1773
Epoch #113: Loss:2.4314, Accuracy:0.1815, Validation Loss:2.4707, Validation Accuracy:0.1741
Epoch #114: Loss:2.4320, Accuracy:0.1749, Validation Loss:2.4712, Validation Accuracy:0.1724
Epoch #115: Loss:2.4348, Accuracy:0.1848, Validation Loss:2.4716, Validation Accuracy:0.1741
Epoch #116: Loss:2.4343, Accuracy:0.1733, Validation Loss:2.4733, Validation Accuracy:0.1691
Epoch #117: Loss:2.4306, Accuracy:0.1873, Validation Loss:2.4702, Validation Accuracy:0.1724
Epoch #118: Loss:2.4338, Accuracy:0.1737, Validation Loss:2.4764, Validation Accuracy:0.1757
Epoch #119: Loss:2.4319, Accuracy:0.1815, Validation Loss:2.4709, Validation Accuracy:0.1691
Epoch #120: Loss:2.4321, Accuracy:0.1791, Validation Loss:2.4754, Validation Accuracy:0.1856
Epoch #121: Loss:2.4300, Accuracy:0.1848, Validation Loss:2.4712, Validation Accuracy:0.1757
Epoch #122: Loss:2.4290, Accuracy:0.1819, Validation Loss:2.4775, Validation Accuracy:0.1839
Epoch #123: Loss:2.4301, Accuracy:0.1819, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #124: Loss:2.4305, Accuracy:0.1832, Validation Loss:2.4750, Validation Accuracy:0.1773
Epoch #125: Loss:2.4330, Accuracy:0.1782, Validation Loss:2.4743, Validation Accuracy:0.1856
Epoch #126: Loss:2.4351, Accuracy:0.1799, Validation Loss:2.4714, Validation Accuracy:0.1872
Epoch #127: Loss:2.4326, Accuracy:0.1811, Validation Loss:2.4740, Validation Accuracy:0.1806
Epoch #128: Loss:2.4321, Accuracy:0.1807, Validation Loss:2.4710, Validation Accuracy:0.1724
Epoch #129: Loss:2.4312, Accuracy:0.1828, Validation Loss:2.4755, Validation Accuracy:0.1856
Epoch #130: Loss:2.4308, Accuracy:0.1811, Validation Loss:2.4731, Validation Accuracy:0.1708
Epoch #131: Loss:2.4305, Accuracy:0.1803, Validation Loss:2.4726, Validation Accuracy:0.1839
Epoch #132: Loss:2.4307, Accuracy:0.1811, Validation Loss:2.4741, Validation Accuracy:0.1839
Epoch #133: Loss:2.4316, Accuracy:0.1803, Validation Loss:2.4738, Validation Accuracy:0.1823
Epoch #134: Loss:2.4315, Accuracy:0.1807, Validation Loss:2.4747, Validation Accuracy:0.1823
Epoch #135: Loss:2.4293, Accuracy:0.1860, Validation Loss:2.4730, Validation Accuracy:0.1757
Epoch #136: Loss:2.4307, Accuracy:0.1795, Validation Loss:2.4748, Validation Accuracy:0.1839
Epoch #137: Loss:2.4293, Accuracy:0.1799, Validation Loss:2.4732, Validation Accuracy:0.1839
Epoch #138: Loss:2.4291, Accuracy:0.1815, Validation Loss:2.4742, Validation Accuracy:0.1839
Epoch #139: Loss:2.4293, Accuracy:0.1803, Validation Loss:2.4735, Validation Accuracy:0.1856
Epoch #140: Loss:2.4296, Accuracy:0.1774, Validation Loss:2.4736, Validation Accuracy:0.1839
Epoch #141: Loss:2.4293, Accuracy:0.1803, Validation Loss:2.4750, Validation Accuracy:0.1839
Epoch #142: Loss:2.4296, Accuracy:0.1791, Validation Loss:2.4737, Validation Accuracy:0.1839
Epoch #143: Loss:2.4295, Accuracy:0.1815, Validation Loss:2.4764, Validation Accuracy:0.1872
Epoch #144: Loss:2.4299, Accuracy:0.1786, Validation Loss:2.4737, Validation Accuracy:0.1806
Epoch #145: Loss:2.4290, Accuracy:0.1815, Validation Loss:2.4750, Validation Accuracy:0.1888
Epoch #146: Loss:2.4285, Accuracy:0.1791, Validation Loss:2.4737, Validation Accuracy:0.1856
Epoch #147: Loss:2.4297, Accuracy:0.1856, Validation Loss:2.4757, Validation Accuracy:0.1823
Epoch #148: Loss:2.4313, Accuracy:0.1840, Validation Loss:2.4739, Validation Accuracy:0.1724
Epoch #149: Loss:2.4291, Accuracy:0.1795, Validation Loss:2.4741, Validation Accuracy:0.1823
Epoch #150: Loss:2.4287, Accuracy:0.1807, Validation Loss:2.4749, Validation Accuracy:0.1790
Epoch #151: Loss:2.4283, Accuracy:0.1848, Validation Loss:2.4747, Validation Accuracy:0.1839
Epoch #152: Loss:2.4282, Accuracy:0.1803, Validation Loss:2.4759, Validation Accuracy:0.1790
Epoch #153: Loss:2.4291, Accuracy:0.1774, Validation Loss:2.4753, Validation Accuracy:0.1872
Epoch #154: Loss:2.4294, Accuracy:0.1803, Validation Loss:2.4750, Validation Accuracy:0.1839
Epoch #155: Loss:2.4274, Accuracy:0.1860, Validation Loss:2.4743, Validation Accuracy:0.1741
Epoch #156: Loss:2.4278, Accuracy:0.1811, Validation Loss:2.4757, Validation Accuracy:0.1856
Epoch #157: Loss:2.4282, Accuracy:0.1828, Validation Loss:2.4757, Validation Accuracy:0.1888
Epoch #158: Loss:2.4287, Accuracy:0.1836, Validation Loss:2.4743, Validation Accuracy:0.1823
Epoch #159: Loss:2.4301, Accuracy:0.1782, Validation Loss:2.4769, Validation Accuracy:0.1872
Epoch #160: Loss:2.4287, Accuracy:0.1823, Validation Loss:2.4744, Validation Accuracy:0.1741
Epoch #161: Loss:2.4293, Accuracy:0.1823, Validation Loss:2.4759, Validation Accuracy:0.1790
Epoch #162: Loss:2.4274, Accuracy:0.1852, Validation Loss:2.4747, Validation Accuracy:0.1757
Epoch #163: Loss:2.4294, Accuracy:0.1803, Validation Loss:2.4789, Validation Accuracy:0.1872
Epoch #164: Loss:2.4281, Accuracy:0.1807, Validation Loss:2.4756, Validation Accuracy:0.1806
Epoch #165: Loss:2.4276, Accuracy:0.1864, Validation Loss:2.4762, Validation Accuracy:0.1839
Epoch #166: Loss:2.4270, Accuracy:0.1848, Validation Loss:2.4752, Validation Accuracy:0.1790
Epoch #167: Loss:2.4271, Accuracy:0.1795, Validation Loss:2.4762, Validation Accuracy:0.1872
Epoch #168: Loss:2.4266, Accuracy:0.1836, Validation Loss:2.4754, Validation Accuracy:0.1839
Epoch #169: Loss:2.4267, Accuracy:0.1836, Validation Loss:2.4772, Validation Accuracy:0.1872
Epoch #170: Loss:2.4274, Accuracy:0.1852, Validation Loss:2.4767, Validation Accuracy:0.1724
Epoch #171: Loss:2.4274, Accuracy:0.1799, Validation Loss:2.4762, Validation Accuracy:0.1790
Epoch #172: Loss:2.4263, Accuracy:0.1873, Validation Loss:2.4763, Validation Accuracy:0.1839
Epoch #173: Loss:2.4260, Accuracy:0.1869, Validation Loss:2.4769, Validation Accuracy:0.1839
Epoch #174: Loss:2.4263, Accuracy:0.1840, Validation Loss:2.4763, Validation Accuracy:0.1839
Epoch #175: Loss:2.4260, Accuracy:0.1852, Validation Loss:2.4772, Validation Accuracy:0.1839
Epoch #176: Loss:2.4264, Accuracy:0.1848, Validation Loss:2.4767, Validation Accuracy:0.1872
Epoch #177: Loss:2.4264, Accuracy:0.1856, Validation Loss:2.4763, Validation Accuracy:0.1839
Epoch #178: Loss:2.4268, Accuracy:0.1832, Validation Loss:2.4783, Validation Accuracy:0.1872
Epoch #179: Loss:2.4254, Accuracy:0.1815, Validation Loss:2.4762, Validation Accuracy:0.1806
Epoch #180: Loss:2.4260, Accuracy:0.1856, Validation Loss:2.4791, Validation Accuracy:0.1872
Epoch #181: Loss:2.4266, Accuracy:0.1848, Validation Loss:2.4776, Validation Accuracy:0.1839
Epoch #182: Loss:2.4255, Accuracy:0.1881, Validation Loss:2.4768, Validation Accuracy:0.1839
Epoch #183: Loss:2.4258, Accuracy:0.1860, Validation Loss:2.4777, Validation Accuracy:0.1872
Epoch #184: Loss:2.4266, Accuracy:0.1832, Validation Loss:2.4773, Validation Accuracy:0.1872
Epoch #185: Loss:2.4259, Accuracy:0.1823, Validation Loss:2.4779, Validation Accuracy:0.1790
Epoch #186: Loss:2.4252, Accuracy:0.1856, Validation Loss:2.4768, Validation Accuracy:0.1757
Epoch #187: Loss:2.4260, Accuracy:0.1840, Validation Loss:2.4782, Validation Accuracy:0.1872
Epoch #188: Loss:2.4267, Accuracy:0.1815, Validation Loss:2.4771, Validation Accuracy:0.1839
Epoch #189: Loss:2.4248, Accuracy:0.1815, Validation Loss:2.4765, Validation Accuracy:0.1708
Epoch #190: Loss:2.4260, Accuracy:0.1828, Validation Loss:2.4787, Validation Accuracy:0.1872
Epoch #191: Loss:2.4268, Accuracy:0.1856, Validation Loss:2.4765, Validation Accuracy:0.1806
Epoch #192: Loss:2.4246, Accuracy:0.1836, Validation Loss:2.4797, Validation Accuracy:0.1888
Epoch #193: Loss:2.4258, Accuracy:0.1848, Validation Loss:2.4778, Validation Accuracy:0.1839
Epoch #194: Loss:2.4256, Accuracy:0.1864, Validation Loss:2.4780, Validation Accuracy:0.1757
Epoch #195: Loss:2.4253, Accuracy:0.1823, Validation Loss:2.4783, Validation Accuracy:0.1741
Epoch #196: Loss:2.4251, Accuracy:0.1836, Validation Loss:2.4801, Validation Accuracy:0.1839
Epoch #197: Loss:2.4245, Accuracy:0.1881, Validation Loss:2.4776, Validation Accuracy:0.1708
Epoch #198: Loss:2.4249, Accuracy:0.1848, Validation Loss:2.4793, Validation Accuracy:0.1839
Epoch #199: Loss:2.4243, Accuracy:0.1852, Validation Loss:2.4783, Validation Accuracy:0.1773
Epoch #200: Loss:2.4258, Accuracy:0.1803, Validation Loss:2.4785, Validation Accuracy:0.1823
Epoch #201: Loss:2.4251, Accuracy:0.1860, Validation Loss:2.4781, Validation Accuracy:0.1839
Epoch #202: Loss:2.4242, Accuracy:0.1844, Validation Loss:2.4785, Validation Accuracy:0.1839
Epoch #203: Loss:2.4242, Accuracy:0.1860, Validation Loss:2.4783, Validation Accuracy:0.1790
Epoch #204: Loss:2.4243, Accuracy:0.1852, Validation Loss:2.4781, Validation Accuracy:0.1839
Epoch #205: Loss:2.4234, Accuracy:0.1864, Validation Loss:2.4799, Validation Accuracy:0.1872
Epoch #206: Loss:2.4243, Accuracy:0.1844, Validation Loss:2.4787, Validation Accuracy:0.1741
Epoch #207: Loss:2.4239, Accuracy:0.1836, Validation Loss:2.4797, Validation Accuracy:0.1872
Epoch #208: Loss:2.4233, Accuracy:0.1869, Validation Loss:2.4780, Validation Accuracy:0.1839
Epoch #209: Loss:2.4232, Accuracy:0.1869, Validation Loss:2.4792, Validation Accuracy:0.1872
Epoch #210: Loss:2.4236, Accuracy:0.1856, Validation Loss:2.4786, Validation Accuracy:0.1872
Epoch #211: Loss:2.4237, Accuracy:0.1881, Validation Loss:2.4783, Validation Accuracy:0.1872
Epoch #212: Loss:2.4234, Accuracy:0.1848, Validation Loss:2.4792, Validation Accuracy:0.1839
Epoch #213: Loss:2.4243, Accuracy:0.1852, Validation Loss:2.4790, Validation Accuracy:0.1872
Epoch #214: Loss:2.4242, Accuracy:0.1803, Validation Loss:2.4785, Validation Accuracy:0.1872
Epoch #215: Loss:2.4237, Accuracy:0.1856, Validation Loss:2.4797, Validation Accuracy:0.1872
Epoch #216: Loss:2.4240, Accuracy:0.1844, Validation Loss:2.4786, Validation Accuracy:0.1872
Epoch #217: Loss:2.4238, Accuracy:0.1852, Validation Loss:2.4798, Validation Accuracy:0.1872
Epoch #218: Loss:2.4235, Accuracy:0.1856, Validation Loss:2.4787, Validation Accuracy:0.1806
Epoch #219: Loss:2.4237, Accuracy:0.1860, Validation Loss:2.4802, Validation Accuracy:0.1839
Epoch #220: Loss:2.4225, Accuracy:0.1869, Validation Loss:2.4804, Validation Accuracy:0.1741
Epoch #221: Loss:2.4228, Accuracy:0.1885, Validation Loss:2.4810, Validation Accuracy:0.1839
Epoch #222: Loss:2.4241, Accuracy:0.1856, Validation Loss:2.4793, Validation Accuracy:0.1839
Epoch #223: Loss:2.4225, Accuracy:0.1864, Validation Loss:2.4803, Validation Accuracy:0.1839
Epoch #224: Loss:2.4223, Accuracy:0.1860, Validation Loss:2.4797, Validation Accuracy:0.1839
Epoch #225: Loss:2.4222, Accuracy:0.1873, Validation Loss:2.4793, Validation Accuracy:0.1790
Epoch #226: Loss:2.4228, Accuracy:0.1864, Validation Loss:2.4812, Validation Accuracy:0.1839
Epoch #227: Loss:2.4222, Accuracy:0.1856, Validation Loss:2.4796, Validation Accuracy:0.1839
Epoch #228: Loss:2.4222, Accuracy:0.1877, Validation Loss:2.4805, Validation Accuracy:0.1790
Epoch #229: Loss:2.4220, Accuracy:0.1873, Validation Loss:2.4811, Validation Accuracy:0.1839
Epoch #230: Loss:2.4224, Accuracy:0.1856, Validation Loss:2.4805, Validation Accuracy:0.1839
Epoch #231: Loss:2.4225, Accuracy:0.1852, Validation Loss:2.4816, Validation Accuracy:0.1872
Epoch #232: Loss:2.4232, Accuracy:0.1873, Validation Loss:2.4807, Validation Accuracy:0.1839
Epoch #233: Loss:2.4232, Accuracy:0.1864, Validation Loss:2.4841, Validation Accuracy:0.1872
Epoch #234: Loss:2.4221, Accuracy:0.1881, Validation Loss:2.4793, Validation Accuracy:0.1757
Epoch #235: Loss:2.4228, Accuracy:0.1799, Validation Loss:2.4813, Validation Accuracy:0.1872
Epoch #236: Loss:2.4222, Accuracy:0.1869, Validation Loss:2.4815, Validation Accuracy:0.1872
Epoch #237: Loss:2.4220, Accuracy:0.1856, Validation Loss:2.4805, Validation Accuracy:0.1790
Epoch #238: Loss:2.4216, Accuracy:0.1844, Validation Loss:2.4825, Validation Accuracy:0.1856
Epoch #239: Loss:2.4215, Accuracy:0.1885, Validation Loss:2.4819, Validation Accuracy:0.1872
Epoch #240: Loss:2.4218, Accuracy:0.1848, Validation Loss:2.4808, Validation Accuracy:0.1872
Epoch #241: Loss:2.4212, Accuracy:0.1840, Validation Loss:2.4812, Validation Accuracy:0.1741
Epoch #242: Loss:2.4216, Accuracy:0.1815, Validation Loss:2.4825, Validation Accuracy:0.1888
Epoch #243: Loss:2.4216, Accuracy:0.1815, Validation Loss:2.4808, Validation Accuracy:0.1741
Epoch #244: Loss:2.4221, Accuracy:0.1877, Validation Loss:2.4819, Validation Accuracy:0.1872
Epoch #245: Loss:2.4219, Accuracy:0.1856, Validation Loss:2.4811, Validation Accuracy:0.1741
Epoch #246: Loss:2.4230, Accuracy:0.1782, Validation Loss:2.4828, Validation Accuracy:0.1872
Epoch #247: Loss:2.4209, Accuracy:0.1860, Validation Loss:2.4814, Validation Accuracy:0.1790
Epoch #248: Loss:2.4209, Accuracy:0.1897, Validation Loss:2.4817, Validation Accuracy:0.1839
Epoch #249: Loss:2.4212, Accuracy:0.1836, Validation Loss:2.4827, Validation Accuracy:0.1872
Epoch #250: Loss:2.4204, Accuracy:0.1860, Validation Loss:2.4821, Validation Accuracy:0.1872
Epoch #251: Loss:2.4210, Accuracy:0.1860, Validation Loss:2.4826, Validation Accuracy:0.1839
Epoch #252: Loss:2.4226, Accuracy:0.1770, Validation Loss:2.4832, Validation Accuracy:0.1839
Epoch #253: Loss:2.4220, Accuracy:0.1852, Validation Loss:2.4814, Validation Accuracy:0.1790
Epoch #254: Loss:2.4227, Accuracy:0.1881, Validation Loss:2.4812, Validation Accuracy:0.1806
Epoch #255: Loss:2.4227, Accuracy:0.1815, Validation Loss:2.4826, Validation Accuracy:0.1839
Epoch #256: Loss:2.4216, Accuracy:0.1881, Validation Loss:2.4825, Validation Accuracy:0.1790
Epoch #257: Loss:2.4228, Accuracy:0.1840, Validation Loss:2.4829, Validation Accuracy:0.1806
Epoch #258: Loss:2.4204, Accuracy:0.1856, Validation Loss:2.4834, Validation Accuracy:0.1757
Epoch #259: Loss:2.4202, Accuracy:0.1881, Validation Loss:2.4841, Validation Accuracy:0.1856
Epoch #260: Loss:2.4228, Accuracy:0.1840, Validation Loss:2.4830, Validation Accuracy:0.1741
Epoch #261: Loss:2.4216, Accuracy:0.1864, Validation Loss:2.4839, Validation Accuracy:0.1839
Epoch #262: Loss:2.4205, Accuracy:0.1860, Validation Loss:2.4819, Validation Accuracy:0.1773
Epoch #263: Loss:2.4212, Accuracy:0.1885, Validation Loss:2.4830, Validation Accuracy:0.1872
Epoch #264: Loss:2.4205, Accuracy:0.1852, Validation Loss:2.4832, Validation Accuracy:0.1872
Epoch #265: Loss:2.4205, Accuracy:0.1852, Validation Loss:2.4827, Validation Accuracy:0.1872
Epoch #266: Loss:2.4195, Accuracy:0.1864, Validation Loss:2.4824, Validation Accuracy:0.1872
Epoch #267: Loss:2.4196, Accuracy:0.1869, Validation Loss:2.4829, Validation Accuracy:0.1872
Epoch #268: Loss:2.4205, Accuracy:0.1844, Validation Loss:2.4838, Validation Accuracy:0.1872
Epoch #269: Loss:2.4209, Accuracy:0.1869, Validation Loss:2.4821, Validation Accuracy:0.1839
Epoch #270: Loss:2.4218, Accuracy:0.1840, Validation Loss:2.4837, Validation Accuracy:0.1872
Epoch #271: Loss:2.4219, Accuracy:0.1848, Validation Loss:2.4846, Validation Accuracy:0.1823
Epoch #272: Loss:2.4227, Accuracy:0.1836, Validation Loss:2.4826, Validation Accuracy:0.1806
Epoch #273: Loss:2.4195, Accuracy:0.1844, Validation Loss:2.4887, Validation Accuracy:0.1806
Epoch #274: Loss:2.4212, Accuracy:0.1877, Validation Loss:2.4827, Validation Accuracy:0.1872
Epoch #275: Loss:2.4196, Accuracy:0.1864, Validation Loss:2.4824, Validation Accuracy:0.1790
Epoch #276: Loss:2.4205, Accuracy:0.1873, Validation Loss:2.4851, Validation Accuracy:0.1839
Epoch #277: Loss:2.4202, Accuracy:0.1852, Validation Loss:2.4833, Validation Accuracy:0.1790
Epoch #278: Loss:2.4191, Accuracy:0.1873, Validation Loss:2.4841, Validation Accuracy:0.1839
Epoch #279: Loss:2.4203, Accuracy:0.1860, Validation Loss:2.4848, Validation Accuracy:0.1872
Epoch #280: Loss:2.4205, Accuracy:0.1836, Validation Loss:2.4846, Validation Accuracy:0.1856
Epoch #281: Loss:2.4204, Accuracy:0.1832, Validation Loss:2.4834, Validation Accuracy:0.1806
Epoch #282: Loss:2.4193, Accuracy:0.1856, Validation Loss:2.4843, Validation Accuracy:0.1790
Epoch #283: Loss:2.4212, Accuracy:0.1881, Validation Loss:2.4842, Validation Accuracy:0.1872
Epoch #284: Loss:2.4208, Accuracy:0.1844, Validation Loss:2.4826, Validation Accuracy:0.1790
Epoch #285: Loss:2.4195, Accuracy:0.1860, Validation Loss:2.4839, Validation Accuracy:0.1757
Epoch #286: Loss:2.4198, Accuracy:0.1856, Validation Loss:2.4859, Validation Accuracy:0.1888
Epoch #287: Loss:2.4195, Accuracy:0.1856, Validation Loss:2.4829, Validation Accuracy:0.1839
Epoch #288: Loss:2.4194, Accuracy:0.1836, Validation Loss:2.4834, Validation Accuracy:0.1823
Epoch #289: Loss:2.4193, Accuracy:0.1864, Validation Loss:2.4850, Validation Accuracy:0.1872
Epoch #290: Loss:2.4183, Accuracy:0.1836, Validation Loss:2.4828, Validation Accuracy:0.1691
Epoch #291: Loss:2.4191, Accuracy:0.1823, Validation Loss:2.4839, Validation Accuracy:0.1790
Epoch #292: Loss:2.4200, Accuracy:0.1893, Validation Loss:2.4857, Validation Accuracy:0.1741
Epoch #293: Loss:2.4203, Accuracy:0.1815, Validation Loss:2.4836, Validation Accuracy:0.1839
Epoch #294: Loss:2.4218, Accuracy:0.1828, Validation Loss:2.4860, Validation Accuracy:0.1790
Epoch #295: Loss:2.4230, Accuracy:0.1828, Validation Loss:2.4845, Validation Accuracy:0.1839
Epoch #296: Loss:2.4193, Accuracy:0.1848, Validation Loss:2.4835, Validation Accuracy:0.1790
Epoch #297: Loss:2.4183, Accuracy:0.1877, Validation Loss:2.4859, Validation Accuracy:0.1839
Epoch #298: Loss:2.4189, Accuracy:0.1877, Validation Loss:2.4853, Validation Accuracy:0.1806
Epoch #299: Loss:2.4189, Accuracy:0.1856, Validation Loss:2.4834, Validation Accuracy:0.1839
Epoch #300: Loss:2.4188, Accuracy:0.1864, Validation Loss:2.4865, Validation Accuracy:0.1872

Test:

======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf16.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.30 08:54:19 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nMags', 'channelMode': 'Split', 'classificationMode': 'Speaker', 'trainingEpoch': 300, 'stepSize': 1, 'sampRate': 8, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
12176 Files with 15 Label(s): ['eo', 'by', 'ek', 'my', 'mb', 'aa', 'sg', 'sk', 'ce', 'yd', 'ib', 'ck', 'eg', 'ds', 'eb'].
Padding:................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 12176 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
9740 steps for training, 2436 steps for test
Splitting Train and Test Data...
------Model for nMags------
---LSTM Classifier---
Train Batch: (9740, 7991, 7)
Test Batch: (2436, 7991, 7)
Optimizer: <keras.optimizers.Adam object at 0x000001F781385240>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001F7E5696EA0>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            2696      
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 11,691
Trainable params: 11,691
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.6902, Accuracy:0.0815, Validation Loss:2.6789, Validation Accuracy:0.1236
Epoch #2: Loss:2.6747, Accuracy:0.1138, Validation Loss:2.6679, Validation Accuracy:0.1018
Epoch #3: Loss:2.6615, Accuracy:0.0742, Validation Loss:2.6530, Validation Accuracy:0.0603
Epoch #4: Loss:2.6409, Accuracy:0.0989, Validation Loss:2.6232, Validation Accuracy:0.1030
Epoch #5: Loss:2.6034, Accuracy:0.1090, Validation Loss:2.5839, Validation Accuracy:0.1186
Epoch #6: Loss:2.5591, Accuracy:0.1367, Validation Loss:2.5411, Validation Accuracy:0.1544
Epoch #7: Loss:2.5237, Accuracy:0.1599, Validation Loss:2.5133, Validation Accuracy:0.1568
Epoch #8: Loss:2.5050, Accuracy:0.1679, Validation Loss:2.4953, Validation Accuracy:0.1765
Epoch #9: Loss:2.4888, Accuracy:0.1752, Validation Loss:2.4853, Validation Accuracy:0.1732
Epoch #10: Loss:2.4814, Accuracy:0.1727, Validation Loss:2.4772, Validation Accuracy:0.1790
Epoch #11: Loss:2.4705, Accuracy:0.1755, Validation Loss:2.4696, Validation Accuracy:0.1753
Epoch #12: Loss:2.4648, Accuracy:0.1768, Validation Loss:2.4697, Validation Accuracy:0.1687
Epoch #13: Loss:2.4579, Accuracy:0.1774, Validation Loss:2.4576, Validation Accuracy:0.1786
Epoch #14: Loss:2.4589, Accuracy:0.1743, Validation Loss:2.4575, Validation Accuracy:0.1798
Epoch #15: Loss:2.4521, Accuracy:0.1801, Validation Loss:2.4526, Validation Accuracy:0.1819
Epoch #16: Loss:2.4487, Accuracy:0.1770, Validation Loss:2.4517, Validation Accuracy:0.1839
Epoch #17: Loss:2.4540, Accuracy:0.1764, Validation Loss:2.4540, Validation Accuracy:0.1810
Epoch #18: Loss:2.4457, Accuracy:0.1797, Validation Loss:2.4484, Validation Accuracy:0.1810
Epoch #19: Loss:2.4435, Accuracy:0.1774, Validation Loss:2.4448, Validation Accuracy:0.1835
Epoch #20: Loss:2.4413, Accuracy:0.1807, Validation Loss:2.4463, Validation Accuracy:0.1847
Epoch #21: Loss:2.4400, Accuracy:0.1791, Validation Loss:2.4427, Validation Accuracy:0.1843
Epoch #22: Loss:2.4363, Accuracy:0.1840, Validation Loss:2.4450, Validation Accuracy:0.1749
Epoch #23: Loss:2.4372, Accuracy:0.1793, Validation Loss:2.4420, Validation Accuracy:0.1856
Epoch #24: Loss:2.4339, Accuracy:0.1825, Validation Loss:2.4408, Validation Accuracy:0.1814
Epoch #25: Loss:2.4347, Accuracy:0.1815, Validation Loss:2.4386, Validation Accuracy:0.1864
Epoch #26: Loss:2.4318, Accuracy:0.1811, Validation Loss:2.4424, Validation Accuracy:0.1843
Epoch #27: Loss:2.4354, Accuracy:0.1803, Validation Loss:2.4382, Validation Accuracy:0.1802
Epoch #28: Loss:2.4307, Accuracy:0.1780, Validation Loss:2.4605, Validation Accuracy:0.1675
Epoch #29: Loss:2.4338, Accuracy:0.1781, Validation Loss:2.4408, Validation Accuracy:0.1728
Epoch #30: Loss:2.4268, Accuracy:0.1830, Validation Loss:2.4382, Validation Accuracy:0.1810
Epoch #31: Loss:2.4258, Accuracy:0.1819, Validation Loss:2.4350, Validation Accuracy:0.1884
Epoch #32: Loss:2.4259, Accuracy:0.1837, Validation Loss:2.4490, Validation Accuracy:0.1798
Epoch #33: Loss:2.4386, Accuracy:0.1798, Validation Loss:2.4394, Validation Accuracy:0.1888
Epoch #34: Loss:2.4271, Accuracy:0.1800, Validation Loss:2.4358, Validation Accuracy:0.1856
Epoch #35: Loss:2.4270, Accuracy:0.1802, Validation Loss:2.4367, Validation Accuracy:0.1741
Epoch #36: Loss:2.4247, Accuracy:0.1813, Validation Loss:2.4377, Validation Accuracy:0.1769
Epoch #37: Loss:2.4225, Accuracy:0.1845, Validation Loss:2.4331, Validation Accuracy:0.1851
Epoch #38: Loss:2.4192, Accuracy:0.1852, Validation Loss:2.4319, Validation Accuracy:0.1872
Epoch #39: Loss:2.4208, Accuracy:0.1840, Validation Loss:2.4425, Validation Accuracy:0.1761
Epoch #40: Loss:2.4230, Accuracy:0.1803, Validation Loss:2.4356, Validation Accuracy:0.1778
Epoch #41: Loss:2.4210, Accuracy:0.1825, Validation Loss:2.4482, Validation Accuracy:0.1761
Epoch #42: Loss:2.4221, Accuracy:0.1861, Validation Loss:2.4375, Validation Accuracy:0.1757
Epoch #43: Loss:2.4152, Accuracy:0.1862, Validation Loss:2.4343, Validation Accuracy:0.1814
Epoch #44: Loss:2.4165, Accuracy:0.1837, Validation Loss:2.4329, Validation Accuracy:0.1790
Epoch #45: Loss:2.4159, Accuracy:0.1860, Validation Loss:2.4397, Validation Accuracy:0.1757
Epoch #46: Loss:2.4144, Accuracy:0.1852, Validation Loss:2.4310, Validation Accuracy:0.1876
Epoch #47: Loss:2.4135, Accuracy:0.1890, Validation Loss:2.4317, Validation Accuracy:0.1884
Epoch #48: Loss:2.4110, Accuracy:0.1874, Validation Loss:2.4307, Validation Accuracy:0.1814
Epoch #49: Loss:2.4102, Accuracy:0.1885, Validation Loss:2.4295, Validation Accuracy:0.1810
Epoch #50: Loss:2.4071, Accuracy:0.1860, Validation Loss:2.4279, Validation Accuracy:0.1794
Epoch #51: Loss:2.4062, Accuracy:0.1880, Validation Loss:2.4275, Validation Accuracy:0.1827
Epoch #52: Loss:2.4059, Accuracy:0.1884, Validation Loss:2.4274, Validation Accuracy:0.1876
Epoch #53: Loss:2.4074, Accuracy:0.1893, Validation Loss:2.4277, Validation Accuracy:0.1794
Epoch #54: Loss:2.4032, Accuracy:0.1933, Validation Loss:2.4284, Validation Accuracy:0.1798
Epoch #55: Loss:2.4070, Accuracy:0.1898, Validation Loss:2.4300, Validation Accuracy:0.1839
Epoch #56: Loss:2.4025, Accuracy:0.1933, Validation Loss:2.4334, Validation Accuracy:0.1802
Epoch #57: Loss:2.4016, Accuracy:0.1927, Validation Loss:2.4253, Validation Accuracy:0.1860
Epoch #58: Loss:2.4018, Accuracy:0.1944, Validation Loss:2.4431, Validation Accuracy:0.1843
Epoch #59: Loss:2.4107, Accuracy:0.1858, Validation Loss:2.4288, Validation Accuracy:0.1905
Epoch #60: Loss:2.4001, Accuracy:0.1926, Validation Loss:2.4265, Validation Accuracy:0.1823
Epoch #61: Loss:2.4000, Accuracy:0.1941, Validation Loss:2.4250, Validation Accuracy:0.1884
Epoch #62: Loss:2.3998, Accuracy:0.1979, Validation Loss:2.4214, Validation Accuracy:0.1929
Epoch #63: Loss:2.3946, Accuracy:0.2002, Validation Loss:2.4227, Validation Accuracy:0.1888
Epoch #64: Loss:2.3948, Accuracy:0.1982, Validation Loss:2.4345, Validation Accuracy:0.1819
Epoch #65: Loss:2.4014, Accuracy:0.1950, Validation Loss:2.4189, Validation Accuracy:0.1839
Epoch #66: Loss:2.3873, Accuracy:0.1982, Validation Loss:2.4212, Validation Accuracy:0.1860
Epoch #67: Loss:2.3903, Accuracy:0.1980, Validation Loss:2.4247, Validation Accuracy:0.1827
Epoch #68: Loss:2.3992, Accuracy:0.1944, Validation Loss:2.4144, Validation Accuracy:0.1868
Epoch #69: Loss:2.3855, Accuracy:0.2000, Validation Loss:2.4175, Validation Accuracy:0.1933
Epoch #70: Loss:2.3841, Accuracy:0.2008, Validation Loss:2.4119, Validation Accuracy:0.1938
Epoch #71: Loss:2.3802, Accuracy:0.2049, Validation Loss:2.4126, Validation Accuracy:0.1950
Epoch #72: Loss:2.3798, Accuracy:0.2038, Validation Loss:2.4150, Validation Accuracy:0.1876
Epoch #73: Loss:2.3772, Accuracy:0.2046, Validation Loss:2.4075, Validation Accuracy:0.1970
Epoch #74: Loss:2.3769, Accuracy:0.2053, Validation Loss:2.4112, Validation Accuracy:0.1983
Epoch #75: Loss:2.3766, Accuracy:0.2049, Validation Loss:2.4095, Validation Accuracy:0.1958
Epoch #76: Loss:2.3761, Accuracy:0.2039, Validation Loss:2.4045, Validation Accuracy:0.1954
Epoch #77: Loss:2.3748, Accuracy:0.2038, Validation Loss:2.4087, Validation Accuracy:0.1933
Epoch #78: Loss:2.3750, Accuracy:0.2066, Validation Loss:2.4139, Validation Accuracy:0.1946
Epoch #79: Loss:2.3815, Accuracy:0.2047, Validation Loss:2.4076, Validation Accuracy:0.2003
Epoch #80: Loss:2.3689, Accuracy:0.2126, Validation Loss:2.4054, Validation Accuracy:0.2040
Epoch #81: Loss:2.3674, Accuracy:0.2120, Validation Loss:2.4040, Validation Accuracy:0.2061
Epoch #82: Loss:2.3668, Accuracy:0.2117, Validation Loss:2.4151, Validation Accuracy:0.2016
Epoch #83: Loss:2.3736, Accuracy:0.2083, Validation Loss:2.4039, Validation Accuracy:0.2073
Epoch #84: Loss:2.3619, Accuracy:0.2146, Validation Loss:2.4020, Validation Accuracy:0.1958
Epoch #85: Loss:2.3627, Accuracy:0.2117, Validation Loss:2.4038, Validation Accuracy:0.1999
Epoch #86: Loss:2.3631, Accuracy:0.2104, Validation Loss:2.4072, Validation Accuracy:0.2007
Epoch #87: Loss:2.3605, Accuracy:0.2111, Validation Loss:2.4015, Validation Accuracy:0.2024
Epoch #88: Loss:2.3583, Accuracy:0.2134, Validation Loss:2.4079, Validation Accuracy:0.1970
Epoch #89: Loss:2.3602, Accuracy:0.2144, Validation Loss:2.4073, Validation Accuracy:0.1946
Epoch #90: Loss:2.3590, Accuracy:0.2161, Validation Loss:2.4012, Validation Accuracy:0.2016
Epoch #91: Loss:2.3549, Accuracy:0.2175, Validation Loss:2.4013, Validation Accuracy:0.2032
Epoch #92: Loss:2.3603, Accuracy:0.2113, Validation Loss:2.4100, Validation Accuracy:0.1999
Epoch #93: Loss:2.3547, Accuracy:0.2188, Validation Loss:2.4008, Validation Accuracy:0.2040
Epoch #94: Loss:2.3495, Accuracy:0.2202, Validation Loss:2.3984, Validation Accuracy:0.2028
Epoch #95: Loss:2.3498, Accuracy:0.2187, Validation Loss:2.4033, Validation Accuracy:0.2048
Epoch #96: Loss:2.3496, Accuracy:0.2206, Validation Loss:2.3996, Validation Accuracy:0.2053
Epoch #97: Loss:2.3521, Accuracy:0.2231, Validation Loss:2.3987, Validation Accuracy:0.2048
Epoch #98: Loss:2.3447, Accuracy:0.2236, Validation Loss:2.3979, Validation Accuracy:0.2081
Epoch #99: Loss:2.3467, Accuracy:0.2198, Validation Loss:2.4002, Validation Accuracy:0.2085
Epoch #100: Loss:2.3433, Accuracy:0.2231, Validation Loss:2.3948, Validation Accuracy:0.2069
Epoch #101: Loss:2.3471, Accuracy:0.2196, Validation Loss:2.4072, Validation Accuracy:0.2053
Epoch #102: Loss:2.3486, Accuracy:0.2219, Validation Loss:2.4014, Validation Accuracy:0.2089
Epoch #103: Loss:2.3461, Accuracy:0.2214, Validation Loss:2.4026, Validation Accuracy:0.2016
Epoch #104: Loss:2.3535, Accuracy:0.2196, Validation Loss:2.3998, Validation Accuracy:0.2024
Epoch #105: Loss:2.3411, Accuracy:0.2283, Validation Loss:2.4006, Validation Accuracy:0.2098
Epoch #106: Loss:2.3433, Accuracy:0.2262, Validation Loss:2.4033, Validation Accuracy:0.2106
Epoch #107: Loss:2.3387, Accuracy:0.2257, Validation Loss:2.3994, Validation Accuracy:0.2085
Epoch #108: Loss:2.3349, Accuracy:0.2282, Validation Loss:2.3948, Validation Accuracy:0.2024
Epoch #109: Loss:2.3317, Accuracy:0.2277, Validation Loss:2.3967, Validation Accuracy:0.2098
Epoch #110: Loss:2.3327, Accuracy:0.2269, Validation Loss:2.3961, Validation Accuracy:0.2077
Epoch #111: Loss:2.3333, Accuracy:0.2286, Validation Loss:2.4016, Validation Accuracy:0.1999
Epoch #112: Loss:2.3298, Accuracy:0.2280, Validation Loss:2.3927, Validation Accuracy:0.2069
Epoch #113: Loss:2.3291, Accuracy:0.2296, Validation Loss:2.3992, Validation Accuracy:0.2028
Epoch #114: Loss:2.3333, Accuracy:0.2268, Validation Loss:2.3949, Validation Accuracy:0.2011
Epoch #115: Loss:2.3359, Accuracy:0.2268, Validation Loss:2.3978, Validation Accuracy:0.2011
Epoch #116: Loss:2.3250, Accuracy:0.2293, Validation Loss:2.3941, Validation Accuracy:0.2053
Epoch #117: Loss:2.3222, Accuracy:0.2309, Validation Loss:2.3921, Validation Accuracy:0.2003
Epoch #118: Loss:2.3212, Accuracy:0.2340, Validation Loss:2.3977, Validation Accuracy:0.2036
Epoch #119: Loss:2.3219, Accuracy:0.2316, Validation Loss:2.3952, Validation Accuracy:0.2077
Epoch #120: Loss:2.3186, Accuracy:0.2335, Validation Loss:2.3886, Validation Accuracy:0.2085
Epoch #121: Loss:2.3192, Accuracy:0.2345, Validation Loss:2.4011, Validation Accuracy:0.2065
Epoch #122: Loss:2.3224, Accuracy:0.2339, Validation Loss:2.3926, Validation Accuracy:0.2024
Epoch #123: Loss:2.3178, Accuracy:0.2315, Validation Loss:2.4008, Validation Accuracy:0.2048
Epoch #124: Loss:2.3197, Accuracy:0.2345, Validation Loss:2.3990, Validation Accuracy:0.2098
Epoch #125: Loss:2.3186, Accuracy:0.2303, Validation Loss:2.3990, Validation Accuracy:0.2057
Epoch #126: Loss:2.3171, Accuracy:0.2354, Validation Loss:2.3949, Validation Accuracy:0.2065
Epoch #127: Loss:2.3195, Accuracy:0.2287, Validation Loss:2.3962, Validation Accuracy:0.2085
Epoch #128: Loss:2.3132, Accuracy:0.2350, Validation Loss:2.3945, Validation Accuracy:0.2028
Epoch #129: Loss:2.3153, Accuracy:0.2374, Validation Loss:2.3936, Validation Accuracy:0.2069
Epoch #130: Loss:2.3260, Accuracy:0.2297, Validation Loss:2.3936, Validation Accuracy:0.2073
Epoch #131: Loss:2.3100, Accuracy:0.2353, Validation Loss:2.3966, Validation Accuracy:0.2098
Epoch #132: Loss:2.3090, Accuracy:0.2359, Validation Loss:2.3898, Validation Accuracy:0.2073
Epoch #133: Loss:2.3056, Accuracy:0.2371, Validation Loss:2.3940, Validation Accuracy:0.2073
Epoch #134: Loss:2.3046, Accuracy:0.2369, Validation Loss:2.3977, Validation Accuracy:0.2028
Epoch #135: Loss:2.3119, Accuracy:0.2337, Validation Loss:2.3930, Validation Accuracy:0.2057
Epoch #136: Loss:2.3049, Accuracy:0.2332, Validation Loss:2.3940, Validation Accuracy:0.1995
Epoch #137: Loss:2.3058, Accuracy:0.2366, Validation Loss:2.3910, Validation Accuracy:0.2044
Epoch #138: Loss:2.3032, Accuracy:0.2410, Validation Loss:2.3891, Validation Accuracy:0.2044
Epoch #139: Loss:2.3075, Accuracy:0.2376, Validation Loss:2.3914, Validation Accuracy:0.2028
Epoch #140: Loss:2.2958, Accuracy:0.2384, Validation Loss:2.3911, Validation Accuracy:0.2036
Epoch #141: Loss:2.3077, Accuracy:0.2374, Validation Loss:2.3930, Validation Accuracy:0.2073
Epoch #142: Loss:2.3051, Accuracy:0.2391, Validation Loss:2.3908, Validation Accuracy:0.2016
Epoch #143: Loss:2.2986, Accuracy:0.2408, Validation Loss:2.3861, Validation Accuracy:0.2110
Epoch #144: Loss:2.2916, Accuracy:0.2415, Validation Loss:2.3977, Validation Accuracy:0.2089
Epoch #145: Loss:2.3127, Accuracy:0.2371, Validation Loss:2.3910, Validation Accuracy:0.2003
Epoch #146: Loss:2.2945, Accuracy:0.2402, Validation Loss:2.3908, Validation Accuracy:0.2094
Epoch #147: Loss:2.2885, Accuracy:0.2408, Validation Loss:2.3870, Validation Accuracy:0.2057
Epoch #148: Loss:2.2884, Accuracy:0.2427, Validation Loss:2.3916, Validation Accuracy:0.2061
Epoch #149: Loss:2.2842, Accuracy:0.2435, Validation Loss:2.3898, Validation Accuracy:0.2053
Epoch #150: Loss:2.2856, Accuracy:0.2420, Validation Loss:2.3954, Validation Accuracy:0.2085
Epoch #151: Loss:2.2876, Accuracy:0.2469, Validation Loss:2.3932, Validation Accuracy:0.2089
Epoch #152: Loss:2.2850, Accuracy:0.2443, Validation Loss:2.3911, Validation Accuracy:0.2065
Epoch #153: Loss:2.2838, Accuracy:0.2418, Validation Loss:2.4047, Validation Accuracy:0.1966
Epoch #154: Loss:2.2895, Accuracy:0.2375, Validation Loss:2.3927, Validation Accuracy:0.2016
Epoch #155: Loss:2.2975, Accuracy:0.2380, Validation Loss:2.3820, Validation Accuracy:0.2036
Epoch #156: Loss:2.2800, Accuracy:0.2443, Validation Loss:2.3812, Validation Accuracy:0.2053
Epoch #157: Loss:2.2781, Accuracy:0.2467, Validation Loss:2.3830, Validation Accuracy:0.2053
Epoch #158: Loss:2.2764, Accuracy:0.2479, Validation Loss:2.3858, Validation Accuracy:0.2081
Epoch #159: Loss:2.2745, Accuracy:0.2494, Validation Loss:2.3902, Validation Accuracy:0.1991
Epoch #160: Loss:2.2793, Accuracy:0.2491, Validation Loss:2.3890, Validation Accuracy:0.2036
Epoch #161: Loss:2.2717, Accuracy:0.2464, Validation Loss:2.3829, Validation Accuracy:0.2085
Epoch #162: Loss:2.2802, Accuracy:0.2414, Validation Loss:2.3882, Validation Accuracy:0.1999
Epoch #163: Loss:2.2724, Accuracy:0.2477, Validation Loss:2.3842, Validation Accuracy:0.2016
Epoch #164: Loss:2.2694, Accuracy:0.2529, Validation Loss:2.3819, Validation Accuracy:0.2089
Epoch #165: Loss:2.2742, Accuracy:0.2501, Validation Loss:2.3813, Validation Accuracy:0.2089
Epoch #166: Loss:2.2680, Accuracy:0.2516, Validation Loss:2.3841, Validation Accuracy:0.2057
Epoch #167: Loss:2.2658, Accuracy:0.2494, Validation Loss:2.3874, Validation Accuracy:0.2040
Epoch #168: Loss:2.2669, Accuracy:0.2482, Validation Loss:2.3857, Validation Accuracy:0.2102
Epoch #169: Loss:2.2645, Accuracy:0.2487, Validation Loss:2.3836, Validation Accuracy:0.2069
Epoch #170: Loss:2.2709, Accuracy:0.2436, Validation Loss:2.3825, Validation Accuracy:0.2089
Epoch #171: Loss:2.2621, Accuracy:0.2514, Validation Loss:2.3794, Validation Accuracy:0.2057
Epoch #172: Loss:2.2529, Accuracy:0.2562, Validation Loss:2.3853, Validation Accuracy:0.2126
Epoch #173: Loss:2.2562, Accuracy:0.2553, Validation Loss:2.3840, Validation Accuracy:0.2110
Epoch #174: Loss:2.2578, Accuracy:0.2541, Validation Loss:2.3882, Validation Accuracy:0.1995
Epoch #175: Loss:2.2552, Accuracy:0.2534, Validation Loss:2.3870, Validation Accuracy:0.2032
Epoch #176: Loss:2.2694, Accuracy:0.2465, Validation Loss:2.3919, Validation Accuracy:0.2073
Epoch #177: Loss:2.2505, Accuracy:0.2561, Validation Loss:2.3815, Validation Accuracy:0.2057
Epoch #178: Loss:2.2516, Accuracy:0.2559, Validation Loss:2.3811, Validation Accuracy:0.2053
Epoch #179: Loss:2.2516, Accuracy:0.2518, Validation Loss:2.3803, Validation Accuracy:0.2098
Epoch #180: Loss:2.2477, Accuracy:0.2541, Validation Loss:2.3815, Validation Accuracy:0.2114
Epoch #181: Loss:2.2439, Accuracy:0.2565, Validation Loss:2.3834, Validation Accuracy:0.2020
Epoch #182: Loss:2.2411, Accuracy:0.2587, Validation Loss:2.4009, Validation Accuracy:0.2048
Epoch #183: Loss:2.2548, Accuracy:0.2508, Validation Loss:2.3932, Validation Accuracy:0.2024
Epoch #184: Loss:2.2428, Accuracy:0.2574, Validation Loss:2.3844, Validation Accuracy:0.2061
Epoch #185: Loss:2.2440, Accuracy:0.2514, Validation Loss:2.3925, Validation Accuracy:0.2053
Epoch #186: Loss:2.2486, Accuracy:0.2545, Validation Loss:2.3855, Validation Accuracy:0.2044
Epoch #187: Loss:2.2442, Accuracy:0.2551, Validation Loss:2.3839, Validation Accuracy:0.2135
Epoch #188: Loss:2.2420, Accuracy:0.2536, Validation Loss:2.3876, Validation Accuracy:0.2011
Epoch #189: Loss:2.2367, Accuracy:0.2543, Validation Loss:2.3848, Validation Accuracy:0.2143
Epoch #190: Loss:2.2439, Accuracy:0.2560, Validation Loss:2.3817, Validation Accuracy:0.2024
Epoch #191: Loss:2.2316, Accuracy:0.2609, Validation Loss:2.3840, Validation Accuracy:0.2151
Epoch #192: Loss:2.2303, Accuracy:0.2572, Validation Loss:2.3806, Validation Accuracy:0.2135
Epoch #193: Loss:2.2260, Accuracy:0.2595, Validation Loss:2.3819, Validation Accuracy:0.2118
Epoch #194: Loss:2.2311, Accuracy:0.2595, Validation Loss:2.3953, Validation Accuracy:0.2053
Epoch #195: Loss:2.2345, Accuracy:0.2579, Validation Loss:2.3836, Validation Accuracy:0.2069
Epoch #196: Loss:2.2288, Accuracy:0.2605, Validation Loss:2.3807, Validation Accuracy:0.2163
Epoch #197: Loss:2.2333, Accuracy:0.2591, Validation Loss:2.3898, Validation Accuracy:0.2048
Epoch #198: Loss:2.2251, Accuracy:0.2612, Validation Loss:2.3894, Validation Accuracy:0.2077
Epoch #199: Loss:2.2261, Accuracy:0.2598, Validation Loss:2.3818, Validation Accuracy:0.2118
Epoch #200: Loss:2.2152, Accuracy:0.2696, Validation Loss:2.3780, Validation Accuracy:0.2122
Epoch #201: Loss:2.2193, Accuracy:0.2622, Validation Loss:2.3771, Validation Accuracy:0.2065
Epoch #202: Loss:2.2120, Accuracy:0.2670, Validation Loss:2.3870, Validation Accuracy:0.2110
Epoch #203: Loss:2.2230, Accuracy:0.2557, Validation Loss:2.3902, Validation Accuracy:0.2122
Epoch #204: Loss:2.2160, Accuracy:0.2645, Validation Loss:2.3753, Validation Accuracy:0.2089
Epoch #205: Loss:2.2091, Accuracy:0.2652, Validation Loss:2.3776, Validation Accuracy:0.2114
Epoch #206: Loss:2.2097, Accuracy:0.2715, Validation Loss:2.3761, Validation Accuracy:0.2135
Epoch #207: Loss:2.2077, Accuracy:0.2677, Validation Loss:2.3846, Validation Accuracy:0.2135
Epoch #208: Loss:2.2096, Accuracy:0.2654, Validation Loss:2.3767, Validation Accuracy:0.2110
Epoch #209: Loss:2.2037, Accuracy:0.2682, Validation Loss:2.3805, Validation Accuracy:0.2122
Epoch #210: Loss:2.2079, Accuracy:0.2650, Validation Loss:2.3777, Validation Accuracy:0.2110
Epoch #211: Loss:2.2053, Accuracy:0.2678, Validation Loss:2.3814, Validation Accuracy:0.2155
Epoch #212: Loss:2.2016, Accuracy:0.2706, Validation Loss:2.3852, Validation Accuracy:0.2102
Epoch #213: Loss:2.1938, Accuracy:0.2742, Validation Loss:2.3762, Validation Accuracy:0.2114
Epoch #214: Loss:2.1971, Accuracy:0.2686, Validation Loss:2.3742, Validation Accuracy:0.2114
Epoch #215: Loss:2.1942, Accuracy:0.2749, Validation Loss:2.3880, Validation Accuracy:0.2131
Epoch #216: Loss:2.2148, Accuracy:0.2619, Validation Loss:2.3816, Validation Accuracy:0.2126
Epoch #217: Loss:2.1973, Accuracy:0.2709, Validation Loss:2.3743, Validation Accuracy:0.2184
Epoch #218: Loss:2.1883, Accuracy:0.2773, Validation Loss:2.3814, Validation Accuracy:0.2200
Epoch #219: Loss:2.1882, Accuracy:0.2751, Validation Loss:2.3791, Validation Accuracy:0.2163
Epoch #220: Loss:2.1901, Accuracy:0.2749, Validation Loss:2.4003, Validation Accuracy:0.2262
Epoch #221: Loss:2.2106, Accuracy:0.2645, Validation Loss:2.3811, Validation Accuracy:0.2180
Epoch #222: Loss:2.1987, Accuracy:0.2738, Validation Loss:2.3761, Validation Accuracy:0.2139
Epoch #223: Loss:2.1883, Accuracy:0.2711, Validation Loss:2.3759, Validation Accuracy:0.2184
Epoch #224: Loss:2.1977, Accuracy:0.2740, Validation Loss:2.3736, Validation Accuracy:0.2192
Epoch #225: Loss:2.1896, Accuracy:0.2768, Validation Loss:2.3772, Validation Accuracy:0.2225
Epoch #226: Loss:2.1872, Accuracy:0.2761, Validation Loss:2.3796, Validation Accuracy:0.2135
Epoch #227: Loss:2.1898, Accuracy:0.2795, Validation Loss:2.3772, Validation Accuracy:0.2221
Epoch #228: Loss:2.1851, Accuracy:0.2786, Validation Loss:2.3780, Validation Accuracy:0.2188
Epoch #229: Loss:2.1797, Accuracy:0.2824, Validation Loss:2.3708, Validation Accuracy:0.2307
Epoch #230: Loss:2.1756, Accuracy:0.2802, Validation Loss:2.3757, Validation Accuracy:0.2184
Epoch #231: Loss:2.1810, Accuracy:0.2803, Validation Loss:2.3773, Validation Accuracy:0.2196
Epoch #232: Loss:2.1990, Accuracy:0.2704, Validation Loss:2.3768, Validation Accuracy:0.2118
Epoch #233: Loss:2.1875, Accuracy:0.2735, Validation Loss:2.3716, Validation Accuracy:0.2163
Epoch #234: Loss:2.1714, Accuracy:0.2797, Validation Loss:2.3720, Validation Accuracy:0.2217
Epoch #235: Loss:2.1689, Accuracy:0.2840, Validation Loss:2.3791, Validation Accuracy:0.2196
Epoch #236: Loss:2.1718, Accuracy:0.2789, Validation Loss:2.3808, Validation Accuracy:0.2254
Epoch #237: Loss:2.1689, Accuracy:0.2860, Validation Loss:2.3758, Validation Accuracy:0.2167
Epoch #238: Loss:2.1725, Accuracy:0.2810, Validation Loss:2.3751, Validation Accuracy:0.2237
Epoch #239: Loss:2.1740, Accuracy:0.2836, Validation Loss:2.3768, Validation Accuracy:0.2233
Epoch #240: Loss:2.1635, Accuracy:0.2845, Validation Loss:2.3768, Validation Accuracy:0.2266
Epoch #241: Loss:2.1573, Accuracy:0.2875, Validation Loss:2.3807, Validation Accuracy:0.2254
Epoch #242: Loss:2.1620, Accuracy:0.2847, Validation Loss:2.3895, Validation Accuracy:0.2245
Epoch #243: Loss:2.1662, Accuracy:0.2861, Validation Loss:2.3947, Validation Accuracy:0.2196
Epoch #244: Loss:2.1819, Accuracy:0.2729, Validation Loss:2.3805, Validation Accuracy:0.2155
Epoch #245: Loss:2.1672, Accuracy:0.2809, Validation Loss:2.3878, Validation Accuracy:0.2118
Epoch #246: Loss:2.1638, Accuracy:0.2862, Validation Loss:2.3807, Validation Accuracy:0.2122
Epoch #247: Loss:2.1541, Accuracy:0.2875, Validation Loss:2.3752, Validation Accuracy:0.2176
Epoch #248: Loss:2.1553, Accuracy:0.2896, Validation Loss:2.3830, Validation Accuracy:0.2225
Epoch #249: Loss:2.1542, Accuracy:0.2884, Validation Loss:2.3902, Validation Accuracy:0.2184
Epoch #250: Loss:2.1631, Accuracy:0.2853, Validation Loss:2.3870, Validation Accuracy:0.2196
Epoch #251: Loss:2.1623, Accuracy:0.2882, Validation Loss:2.3908, Validation Accuracy:0.2262
Epoch #252: Loss:2.1718, Accuracy:0.2770, Validation Loss:2.3892, Validation Accuracy:0.2213
Epoch #253: Loss:2.1535, Accuracy:0.2861, Validation Loss:2.4106, Validation Accuracy:0.2254
Epoch #254: Loss:2.1729, Accuracy:0.2785, Validation Loss:2.3987, Validation Accuracy:0.2241
Epoch #255: Loss:2.1600, Accuracy:0.2859, Validation Loss:2.3745, Validation Accuracy:0.2245
Epoch #256: Loss:2.1750, Accuracy:0.2822, Validation Loss:2.3771, Validation Accuracy:0.2254
Epoch #257: Loss:2.1461, Accuracy:0.2879, Validation Loss:2.3831, Validation Accuracy:0.2184
Epoch #258: Loss:2.1441, Accuracy:0.2900, Validation Loss:2.3770, Validation Accuracy:0.2266
Epoch #259: Loss:2.1425, Accuracy:0.2911, Validation Loss:2.3810, Validation Accuracy:0.2172
Epoch #260: Loss:2.1363, Accuracy:0.2950, Validation Loss:2.3810, Validation Accuracy:0.2266
Epoch #261: Loss:2.1340, Accuracy:0.2964, Validation Loss:2.3819, Validation Accuracy:0.2225
Epoch #262: Loss:2.1344, Accuracy:0.2941, Validation Loss:2.3871, Validation Accuracy:0.2225
Epoch #263: Loss:2.1505, Accuracy:0.2866, Validation Loss:2.3912, Validation Accuracy:0.2282
Epoch #264: Loss:2.1521, Accuracy:0.2905, Validation Loss:2.3807, Validation Accuracy:0.2213
Epoch #265: Loss:2.1380, Accuracy:0.2972, Validation Loss:2.3818, Validation Accuracy:0.2167
Epoch #266: Loss:2.1372, Accuracy:0.2886, Validation Loss:2.3826, Validation Accuracy:0.2217
Epoch #267: Loss:2.1306, Accuracy:0.2917, Validation Loss:2.3798, Validation Accuracy:0.2167
Epoch #268: Loss:2.1362, Accuracy:0.2938, Validation Loss:2.3779, Validation Accuracy:0.2192
Epoch #269: Loss:2.1265, Accuracy:0.2958, Validation Loss:2.3806, Validation Accuracy:0.2241
Epoch #270: Loss:2.1263, Accuracy:0.3028, Validation Loss:2.3794, Validation Accuracy:0.2225
Epoch #271: Loss:2.1226, Accuracy:0.2987, Validation Loss:2.3899, Validation Accuracy:0.2200
Epoch #272: Loss:2.1373, Accuracy:0.2920, Validation Loss:2.3830, Validation Accuracy:0.2233
Epoch #273: Loss:2.1230, Accuracy:0.2964, Validation Loss:2.3913, Validation Accuracy:0.2287
Epoch #274: Loss:2.1313, Accuracy:0.2926, Validation Loss:2.3855, Validation Accuracy:0.2213
Epoch #275: Loss:2.1279, Accuracy:0.2940, Validation Loss:2.3916, Validation Accuracy:0.2254
Epoch #276: Loss:2.1230, Accuracy:0.2953, Validation Loss:2.3851, Validation Accuracy:0.2221
Epoch #277: Loss:2.1203, Accuracy:0.2978, Validation Loss:2.3838, Validation Accuracy:0.2266
Epoch #278: Loss:2.1235, Accuracy:0.2969, Validation Loss:2.3884, Validation Accuracy:0.2233
Epoch #279: Loss:2.1148, Accuracy:0.2989, Validation Loss:2.3917, Validation Accuracy:0.2307
Epoch #280: Loss:2.1085, Accuracy:0.3047, Validation Loss:2.3849, Validation Accuracy:0.2291
Epoch #281: Loss:2.1110, Accuracy:0.3044, Validation Loss:2.3915, Validation Accuracy:0.2307
Epoch #282: Loss:2.1095, Accuracy:0.3026, Validation Loss:2.3871, Validation Accuracy:0.2332
Epoch #283: Loss:2.1187, Accuracy:0.2991, Validation Loss:2.3832, Validation Accuracy:0.2229
Epoch #284: Loss:2.1152, Accuracy:0.2985, Validation Loss:2.3941, Validation Accuracy:0.2291
Epoch #285: Loss:2.1125, Accuracy:0.3055, Validation Loss:2.3917, Validation Accuracy:0.2303
Epoch #286: Loss:2.1110, Accuracy:0.3026, Validation Loss:2.3936, Validation Accuracy:0.2245
Epoch #287: Loss:2.1140, Accuracy:0.2972, Validation Loss:2.3934, Validation Accuracy:0.2291
Epoch #288: Loss:2.1076, Accuracy:0.3041, Validation Loss:2.3913, Validation Accuracy:0.2274
Epoch #289: Loss:2.1050, Accuracy:0.3042, Validation Loss:2.3975, Validation Accuracy:0.2241
Epoch #290: Loss:2.1277, Accuracy:0.2924, Validation Loss:2.4119, Validation Accuracy:0.2245
Epoch #291: Loss:2.1378, Accuracy:0.2937, Validation Loss:2.4047, Validation Accuracy:0.2250
Epoch #292: Loss:2.1102, Accuracy:0.2977, Validation Loss:2.3879, Validation Accuracy:0.2225
Epoch #293: Loss:2.1428, Accuracy:0.2874, Validation Loss:2.3957, Validation Accuracy:0.2209
Epoch #294: Loss:2.1188, Accuracy:0.2966, Validation Loss:2.3961, Validation Accuracy:0.2237
Epoch #295: Loss:2.1014, Accuracy:0.3046, Validation Loss:2.3853, Validation Accuracy:0.2270
Epoch #296: Loss:2.1090, Accuracy:0.3007, Validation Loss:2.3923, Validation Accuracy:0.2323
Epoch #297: Loss:2.1025, Accuracy:0.3039, Validation Loss:2.4051, Validation Accuracy:0.2307
Epoch #298: Loss:2.1068, Accuracy:0.3010, Validation Loss:2.3919, Validation Accuracy:0.2274
Epoch #299: Loss:2.0949, Accuracy:0.3087, Validation Loss:2.3930, Validation Accuracy:0.2287
Epoch #300: Loss:2.1050, Accuracy:0.3013, Validation Loss:2.3950, Validation Accuracy:0.2278

Test:
Test Loss:2.39496017, Accuracy:0.2278
Labels: ['eo', 'by', 'ek', 'my', 'mb', 'aa', 'sg', 'sk', 'ce', 'yd', 'ib', 'ck', 'eg', 'ds', 'eb']
Confusion Matrix:
      eo  by  ek  my  mb  aa  sg  sk  ce   yd  ib  ck  eg  ds  eb
t:eo  17   9   9   0  13   1  27   6   1   17  12   2   8   2  11
t:by  12  21   8   2  21   6  24   2   0   18   9   1  17   5  16
t:ek   9  14  22   0  19   6  12   8   4   35  10   3  24   6  19
t:my   3   8   4   2   9   5   2   4   0   12  17   0   3  10   1
t:mb   8  12   7   2  55   6  17  11   0   38  14   1  12   6  18
t:aa   2   5   6   1  13   8   7   7   0    8   6   1  25  27  21
t:sg   5   9   6   5  31   0  47   3   0   45  28   1   7   3  13
t:sk   4   4  13   0  13   5   8  14   0   10   5   1  22  14  17
t:ce  14   4   8   0  19   1   5   3   0   14   5   0  16  10  10
t:yd   6   6   6   0  17   0  27   5   0  132  41   0   5   0   4
t:ib   5   2   2   0  19   1  13   5   0   69  79   2  11   4   5
t:ck   9  10   3   0   9   8   6   1   0    9   1   7  13   8   7
t:eg   5   7   4   0  13  17   5  21   0    7   3   0  70  20  26
t:ds   4   7   4   2  11  12   6   7   0    3   4   1  15  38  12
t:eb  10   9  14   0  20   7  16  11   1   26  13   0  19  12  43
Classification Report:
              precision    recall  f1-score   support

          eo       0.15      0.13      0.14       135
          by       0.17      0.13      0.15       162
          ek       0.19      0.12      0.14       191
          my       0.14      0.03      0.04        80
          mb       0.20      0.27      0.22       207
          aa       0.10      0.06      0.07       137
          sg       0.21      0.23      0.22       203
          sk       0.13      0.11      0.12       130
          ce       0.00      0.00      0.00       109
          yd       0.30      0.53      0.38       249
          ib       0.32      0.36      0.34       217
          ck       0.35      0.08      0.13        91
          eg       0.26      0.35      0.30       198
          ds       0.23      0.30      0.26       126
          eb       0.19      0.21      0.20       201

    accuracy                           0.23      2436
   macro avg       0.20      0.19      0.18      2436
weighted avg       0.21      0.23      0.21      2436

============ Config: 1/1 === End Time: 2019.07.30 09:56:34 =========================================
============ Config: 1/1 === Duration: 0 days, 1 hours, 2 minutes, 15 seconds =====================

Ending script after plotting results...

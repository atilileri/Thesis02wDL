======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf64.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.25 00:09:57 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nPhases', 'channelMode': '3Ov', 'classificationMode': 'Posture', 'trainingEpoch': 300, 'stepSize': 6, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 5 Label(s): ['03', '05', '02', '04', '01'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 5 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for nPhases------
---LSTM Classifier---
Train Batch: (2436, 7989, 36)
Test Batch: (610, 7989, 36)
Optimizer: <keras.optimizers.Adam object at 0x0000022A803F4940>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000022AEF976AE8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 65        
=================================================================
Total params: 22,697
Trainable params: 22,697
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.6162, Accuracy:0.1901 Validation Loss:1.6123, Validation Accuracy:0.1803
Epoch #2: Loss:1.6099, Accuracy:0.2159 Validation Loss:1.6083, Validation Accuracy:0.2328
Epoch #3: Loss:1.6080, Accuracy:0.2332 Validation Loss:1.6073, Validation Accuracy:0.2328
Epoch #4: Loss:1.6069, Accuracy:0.2332 Validation Loss:1.6064, Validation Accuracy:0.2328
Epoch #5: Loss:1.6062, Accuracy:0.2332 Validation Loss:1.6060, Validation Accuracy:0.2328
Epoch #6: Loss:1.6057, Accuracy:0.2332 Validation Loss:1.6059, Validation Accuracy:0.2328
Epoch #7: Loss:1.6060, Accuracy:0.2332 Validation Loss:1.6056, Validation Accuracy:0.2328
Epoch #8: Loss:1.6059, Accuracy:0.2332 Validation Loss:1.6055, Validation Accuracy:0.2328
Epoch #9: Loss:1.6054, Accuracy:0.2332 Validation Loss:1.6052, Validation Accuracy:0.2328
Epoch #10: Loss:1.6053, Accuracy:0.2332 Validation Loss:1.6050, Validation Accuracy:0.2328
Epoch #11: Loss:1.6052, Accuracy:0.2332 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #12: Loss:1.6050, Accuracy:0.2332 Validation Loss:1.6047, Validation Accuracy:0.2328
Epoch #13: Loss:1.6049, Accuracy:0.2332 Validation Loss:1.6046, Validation Accuracy:0.2328
Epoch #14: Loss:1.6047, Accuracy:0.2332 Validation Loss:1.6044, Validation Accuracy:0.2328
Epoch #15: Loss:1.6047, Accuracy:0.2332 Validation Loss:1.6041, Validation Accuracy:0.2328
Epoch #16: Loss:1.6045, Accuracy:0.2332 Validation Loss:1.6046, Validation Accuracy:0.2328
Epoch #17: Loss:1.6052, Accuracy:0.2332 Validation Loss:1.6044, Validation Accuracy:0.2328
Epoch #18: Loss:1.6047, Accuracy:0.2332 Validation Loss:1.6045, Validation Accuracy:0.2328
Epoch #19: Loss:1.6048, Accuracy:0.2332 Validation Loss:1.6044, Validation Accuracy:0.2328
Epoch #20: Loss:1.6043, Accuracy:0.2332 Validation Loss:1.6039, Validation Accuracy:0.2328
Epoch #21: Loss:1.6041, Accuracy:0.2332 Validation Loss:1.6035, Validation Accuracy:0.2328
Epoch #22: Loss:1.6041, Accuracy:0.2332 Validation Loss:1.6037, Validation Accuracy:0.2328
Epoch #23: Loss:1.6040, Accuracy:0.2332 Validation Loss:1.6036, Validation Accuracy:0.2328
Epoch #24: Loss:1.6036, Accuracy:0.2332 Validation Loss:1.6036, Validation Accuracy:0.2328
Epoch #25: Loss:1.6034, Accuracy:0.2332 Validation Loss:1.6032, Validation Accuracy:0.2328
Epoch #26: Loss:1.6031, Accuracy:0.2332 Validation Loss:1.6028, Validation Accuracy:0.2328
Epoch #27: Loss:1.6030, Accuracy:0.2332 Validation Loss:1.6023, Validation Accuracy:0.2328
Epoch #28: Loss:1.6029, Accuracy:0.2332 Validation Loss:1.6029, Validation Accuracy:0.2328
Epoch #29: Loss:1.6037, Accuracy:0.2332 Validation Loss:1.6033, Validation Accuracy:0.2328
Epoch #30: Loss:1.6032, Accuracy:0.2332 Validation Loss:1.6021, Validation Accuracy:0.2328
Epoch #31: Loss:1.6033, Accuracy:0.2332 Validation Loss:1.6024, Validation Accuracy:0.2328
Epoch #32: Loss:1.6032, Accuracy:0.2348 Validation Loss:1.6027, Validation Accuracy:0.2377
Epoch #33: Loss:1.6027, Accuracy:0.2385 Validation Loss:1.6023, Validation Accuracy:0.2410
Epoch #34: Loss:1.6025, Accuracy:0.2393 Validation Loss:1.6024, Validation Accuracy:0.2377
Epoch #35: Loss:1.6024, Accuracy:0.2389 Validation Loss:1.6021, Validation Accuracy:0.2393
Epoch #36: Loss:1.6022, Accuracy:0.2393 Validation Loss:1.6018, Validation Accuracy:0.2443
Epoch #37: Loss:1.6018, Accuracy:0.2447 Validation Loss:1.6014, Validation Accuracy:0.2426
Epoch #38: Loss:1.6020, Accuracy:0.2414 Validation Loss:1.6041, Validation Accuracy:0.2328
Epoch #39: Loss:1.6051, Accuracy:0.2332 Validation Loss:1.6041, Validation Accuracy:0.2328
Epoch #40: Loss:1.6030, Accuracy:0.2397 Validation Loss:1.6052, Validation Accuracy:0.2377
Epoch #41: Loss:1.6044, Accuracy:0.2356 Validation Loss:1.6053, Validation Accuracy:0.2328
Epoch #42: Loss:1.6049, Accuracy:0.2344 Validation Loss:1.6031, Validation Accuracy:0.2295
Epoch #43: Loss:1.6026, Accuracy:0.2344 Validation Loss:1.6028, Validation Accuracy:0.2426
Epoch #44: Loss:1.6037, Accuracy:0.2430 Validation Loss:1.6018, Validation Accuracy:0.2426
Epoch #45: Loss:1.6027, Accuracy:0.2373 Validation Loss:1.6027, Validation Accuracy:0.2328
Epoch #46: Loss:1.6026, Accuracy:0.2332 Validation Loss:1.6027, Validation Accuracy:0.2328
Epoch #47: Loss:1.6027, Accuracy:0.2323 Validation Loss:1.6024, Validation Accuracy:0.2410
Epoch #48: Loss:1.6024, Accuracy:0.2426 Validation Loss:1.6023, Validation Accuracy:0.2426
Epoch #49: Loss:1.6019, Accuracy:0.2434 Validation Loss:1.6020, Validation Accuracy:0.2377
Epoch #50: Loss:1.6014, Accuracy:0.2393 Validation Loss:1.6019, Validation Accuracy:0.2393
Epoch #51: Loss:1.6018, Accuracy:0.2381 Validation Loss:1.6020, Validation Accuracy:0.2393
Epoch #52: Loss:1.6013, Accuracy:0.2422 Validation Loss:1.6020, Validation Accuracy:0.2426
Epoch #53: Loss:1.6017, Accuracy:0.2447 Validation Loss:1.6018, Validation Accuracy:0.2426
Epoch #54: Loss:1.6009, Accuracy:0.2455 Validation Loss:1.6022, Validation Accuracy:0.2393
Epoch #55: Loss:1.6017, Accuracy:0.2385 Validation Loss:1.6023, Validation Accuracy:0.2393
Epoch #56: Loss:1.6013, Accuracy:0.2438 Validation Loss:1.6019, Validation Accuracy:0.2426
Epoch #57: Loss:1.6013, Accuracy:0.2422 Validation Loss:1.6016, Validation Accuracy:0.2426
Epoch #58: Loss:1.6006, Accuracy:0.2430 Validation Loss:1.6017, Validation Accuracy:0.2443
Epoch #59: Loss:1.6004, Accuracy:0.2430 Validation Loss:1.6017, Validation Accuracy:0.2377
Epoch #60: Loss:1.6004, Accuracy:0.2443 Validation Loss:1.6018, Validation Accuracy:0.2410
Epoch #61: Loss:1.6002, Accuracy:0.2447 Validation Loss:1.6017, Validation Accuracy:0.2443
Epoch #62: Loss:1.6002, Accuracy:0.2430 Validation Loss:1.6018, Validation Accuracy:0.2443
Epoch #63: Loss:1.6003, Accuracy:0.2430 Validation Loss:1.6018, Validation Accuracy:0.2443
Epoch #64: Loss:1.6001, Accuracy:0.2434 Validation Loss:1.6019, Validation Accuracy:0.2410
Epoch #65: Loss:1.6001, Accuracy:0.2438 Validation Loss:1.6017, Validation Accuracy:0.2410
Epoch #66: Loss:1.6000, Accuracy:0.2414 Validation Loss:1.6015, Validation Accuracy:0.2443
Epoch #67: Loss:1.5996, Accuracy:0.2434 Validation Loss:1.6018, Validation Accuracy:0.2459
Epoch #68: Loss:1.6005, Accuracy:0.2451 Validation Loss:1.6019, Validation Accuracy:0.2443
Epoch #69: Loss:1.5997, Accuracy:0.2438 Validation Loss:1.6023, Validation Accuracy:0.2443
Epoch #70: Loss:1.6014, Accuracy:0.2438 Validation Loss:1.6021, Validation Accuracy:0.2459
Epoch #71: Loss:1.6002, Accuracy:0.2455 Validation Loss:1.6023, Validation Accuracy:0.2459
Epoch #72: Loss:1.6003, Accuracy:0.2443 Validation Loss:1.6032, Validation Accuracy:0.2377
Epoch #73: Loss:1.6005, Accuracy:0.2385 Validation Loss:1.6033, Validation Accuracy:0.2459
Epoch #74: Loss:1.6000, Accuracy:0.2443 Validation Loss:1.6032, Validation Accuracy:0.2393
Epoch #75: Loss:1.6002, Accuracy:0.2418 Validation Loss:1.6035, Validation Accuracy:0.2410
Epoch #76: Loss:1.5999, Accuracy:0.2418 Validation Loss:1.6036, Validation Accuracy:0.2459
Epoch #77: Loss:1.5998, Accuracy:0.2443 Validation Loss:1.6038, Validation Accuracy:0.2393
Epoch #78: Loss:1.5998, Accuracy:0.2410 Validation Loss:1.6036, Validation Accuracy:0.2475
Epoch #79: Loss:1.6007, Accuracy:0.2389 Validation Loss:1.6032, Validation Accuracy:0.2443
Epoch #80: Loss:1.6007, Accuracy:0.2397 Validation Loss:1.6031, Validation Accuracy:0.2410
Epoch #81: Loss:1.6001, Accuracy:0.2381 Validation Loss:1.6033, Validation Accuracy:0.2377
Epoch #82: Loss:1.5997, Accuracy:0.2401 Validation Loss:1.6033, Validation Accuracy:0.2377
Epoch #83: Loss:1.5998, Accuracy:0.2422 Validation Loss:1.6033, Validation Accuracy:0.2393
Epoch #84: Loss:1.5993, Accuracy:0.2463 Validation Loss:1.6036, Validation Accuracy:0.2377
Epoch #85: Loss:1.5994, Accuracy:0.2447 Validation Loss:1.6026, Validation Accuracy:0.2377
Epoch #86: Loss:1.5991, Accuracy:0.2410 Validation Loss:1.6047, Validation Accuracy:0.2344
Epoch #87: Loss:1.5993, Accuracy:0.2459 Validation Loss:1.6037, Validation Accuracy:0.2410
Epoch #88: Loss:1.5996, Accuracy:0.2414 Validation Loss:1.6032, Validation Accuracy:0.2393
Epoch #89: Loss:1.5992, Accuracy:0.2438 Validation Loss:1.6029, Validation Accuracy:0.2361
Epoch #90: Loss:1.6002, Accuracy:0.2397 Validation Loss:1.6038, Validation Accuracy:0.2410
Epoch #91: Loss:1.5998, Accuracy:0.2438 Validation Loss:1.6044, Validation Accuracy:0.2377
Epoch #92: Loss:1.6002, Accuracy:0.2385 Validation Loss:1.6036, Validation Accuracy:0.2361
Epoch #93: Loss:1.5999, Accuracy:0.2406 Validation Loss:1.6036, Validation Accuracy:0.2377
Epoch #94: Loss:1.5997, Accuracy:0.2401 Validation Loss:1.6033, Validation Accuracy:0.2361
Epoch #95: Loss:1.5998, Accuracy:0.2426 Validation Loss:1.6030, Validation Accuracy:0.2426
Epoch #96: Loss:1.6001, Accuracy:0.2344 Validation Loss:1.6027, Validation Accuracy:0.2361
Epoch #97: Loss:1.6006, Accuracy:0.2360 Validation Loss:1.6028, Validation Accuracy:0.2410
Epoch #98: Loss:1.5997, Accuracy:0.2397 Validation Loss:1.6035, Validation Accuracy:0.2377
Epoch #99: Loss:1.6000, Accuracy:0.2393 Validation Loss:1.6023, Validation Accuracy:0.2426
Epoch #100: Loss:1.6000, Accuracy:0.2397 Validation Loss:1.6024, Validation Accuracy:0.2410
Epoch #101: Loss:1.6004, Accuracy:0.2422 Validation Loss:1.6026, Validation Accuracy:0.2426
Epoch #102: Loss:1.6000, Accuracy:0.2356 Validation Loss:1.6030, Validation Accuracy:0.2377
Epoch #103: Loss:1.5995, Accuracy:0.2377 Validation Loss:1.6028, Validation Accuracy:0.2426
Epoch #104: Loss:1.5997, Accuracy:0.2389 Validation Loss:1.6025, Validation Accuracy:0.2361
Epoch #105: Loss:1.5998, Accuracy:0.2397 Validation Loss:1.6032, Validation Accuracy:0.2410
Epoch #106: Loss:1.5996, Accuracy:0.2414 Validation Loss:1.6035, Validation Accuracy:0.2279
Epoch #107: Loss:1.6000, Accuracy:0.2401 Validation Loss:1.6044, Validation Accuracy:0.2377
Epoch #108: Loss:1.5995, Accuracy:0.2352 Validation Loss:1.6041, Validation Accuracy:0.2426
Epoch #109: Loss:1.5998, Accuracy:0.2406 Validation Loss:1.6041, Validation Accuracy:0.2475
Epoch #110: Loss:1.5991, Accuracy:0.2410 Validation Loss:1.6039, Validation Accuracy:0.2262
Epoch #111: Loss:1.5989, Accuracy:0.2381 Validation Loss:1.6041, Validation Accuracy:0.2344
Epoch #112: Loss:1.5995, Accuracy:0.2406 Validation Loss:1.6043, Validation Accuracy:0.2344
Epoch #113: Loss:1.5989, Accuracy:0.2397 Validation Loss:1.6039, Validation Accuracy:0.2213
Epoch #114: Loss:1.5996, Accuracy:0.2397 Validation Loss:1.6036, Validation Accuracy:0.2230
Epoch #115: Loss:1.5984, Accuracy:0.2397 Validation Loss:1.6043, Validation Accuracy:0.2393
Epoch #116: Loss:1.5992, Accuracy:0.2373 Validation Loss:1.6031, Validation Accuracy:0.2426
Epoch #117: Loss:1.5987, Accuracy:0.2385 Validation Loss:1.6032, Validation Accuracy:0.2246
Epoch #118: Loss:1.5985, Accuracy:0.2381 Validation Loss:1.6031, Validation Accuracy:0.2230
Epoch #119: Loss:1.6033, Accuracy:0.2299 Validation Loss:1.6134, Validation Accuracy:0.2148
Epoch #120: Loss:1.6046, Accuracy:0.2365 Validation Loss:1.6044, Validation Accuracy:0.2393
Epoch #121: Loss:1.5997, Accuracy:0.2389 Validation Loss:1.6066, Validation Accuracy:0.2377
Epoch #122: Loss:1.5992, Accuracy:0.2410 Validation Loss:1.6040, Validation Accuracy:0.2213
Epoch #123: Loss:1.6001, Accuracy:0.2381 Validation Loss:1.6046, Validation Accuracy:0.2230
Epoch #124: Loss:1.5993, Accuracy:0.2344 Validation Loss:1.6042, Validation Accuracy:0.2393
Epoch #125: Loss:1.5990, Accuracy:0.2443 Validation Loss:1.6039, Validation Accuracy:0.2410
Epoch #126: Loss:1.5985, Accuracy:0.2438 Validation Loss:1.6041, Validation Accuracy:0.2246
Epoch #127: Loss:1.5984, Accuracy:0.2438 Validation Loss:1.6032, Validation Accuracy:0.2393
Epoch #128: Loss:1.5982, Accuracy:0.2451 Validation Loss:1.6036, Validation Accuracy:0.2410
Epoch #129: Loss:1.5983, Accuracy:0.2414 Validation Loss:1.6033, Validation Accuracy:0.2279
Epoch #130: Loss:1.5980, Accuracy:0.2348 Validation Loss:1.6039, Validation Accuracy:0.2393
Epoch #131: Loss:1.5978, Accuracy:0.2406 Validation Loss:1.6039, Validation Accuracy:0.2213
Epoch #132: Loss:1.5975, Accuracy:0.2393 Validation Loss:1.6040, Validation Accuracy:0.2279
Epoch #133: Loss:1.5976, Accuracy:0.2393 Validation Loss:1.6040, Validation Accuracy:0.2295
Epoch #134: Loss:1.5975, Accuracy:0.2430 Validation Loss:1.6044, Validation Accuracy:0.2410
Epoch #135: Loss:1.5978, Accuracy:0.2414 Validation Loss:1.6046, Validation Accuracy:0.2230
Epoch #136: Loss:1.5975, Accuracy:0.2410 Validation Loss:1.6051, Validation Accuracy:0.2213
Epoch #137: Loss:1.5976, Accuracy:0.2389 Validation Loss:1.6052, Validation Accuracy:0.2262
Epoch #138: Loss:1.5974, Accuracy:0.2401 Validation Loss:1.6055, Validation Accuracy:0.2213
Epoch #139: Loss:1.5976, Accuracy:0.2393 Validation Loss:1.6055, Validation Accuracy:0.2230
Epoch #140: Loss:1.5976, Accuracy:0.2443 Validation Loss:1.6059, Validation Accuracy:0.2279
Epoch #141: Loss:1.5973, Accuracy:0.2418 Validation Loss:1.6055, Validation Accuracy:0.2230
Epoch #142: Loss:1.5974, Accuracy:0.2397 Validation Loss:1.6054, Validation Accuracy:0.2230
Epoch #143: Loss:1.5971, Accuracy:0.2401 Validation Loss:1.6054, Validation Accuracy:0.2230
Epoch #144: Loss:1.5972, Accuracy:0.2426 Validation Loss:1.6056, Validation Accuracy:0.2230
Epoch #145: Loss:1.5978, Accuracy:0.2406 Validation Loss:1.6060, Validation Accuracy:0.2131
Epoch #146: Loss:1.5968, Accuracy:0.2397 Validation Loss:1.6061, Validation Accuracy:0.2262
Epoch #147: Loss:1.5975, Accuracy:0.2401 Validation Loss:1.6060, Validation Accuracy:0.2213
Epoch #148: Loss:1.5970, Accuracy:0.2422 Validation Loss:1.6063, Validation Accuracy:0.2230
Epoch #149: Loss:1.5970, Accuracy:0.2414 Validation Loss:1.6062, Validation Accuracy:0.2213
Epoch #150: Loss:1.5971, Accuracy:0.2389 Validation Loss:1.6064, Validation Accuracy:0.2344
Epoch #151: Loss:1.5965, Accuracy:0.2426 Validation Loss:1.6061, Validation Accuracy:0.2213
Epoch #152: Loss:1.5967, Accuracy:0.2397 Validation Loss:1.6062, Validation Accuracy:0.2213
Epoch #153: Loss:1.5968, Accuracy:0.2422 Validation Loss:1.6063, Validation Accuracy:0.2230
Epoch #154: Loss:1.5966, Accuracy:0.2438 Validation Loss:1.6062, Validation Accuracy:0.2230
Epoch #155: Loss:1.5964, Accuracy:0.2406 Validation Loss:1.6064, Validation Accuracy:0.2213
Epoch #156: Loss:1.5963, Accuracy:0.2418 Validation Loss:1.6066, Validation Accuracy:0.2344
Epoch #157: Loss:1.5970, Accuracy:0.2406 Validation Loss:1.6066, Validation Accuracy:0.2131
Epoch #158: Loss:1.5963, Accuracy:0.2414 Validation Loss:1.6067, Validation Accuracy:0.2230
Epoch #159: Loss:1.5964, Accuracy:0.2426 Validation Loss:1.6066, Validation Accuracy:0.2230
Epoch #160: Loss:1.5967, Accuracy:0.2410 Validation Loss:1.6067, Validation Accuracy:0.2213
Epoch #161: Loss:1.5968, Accuracy:0.2389 Validation Loss:1.6067, Validation Accuracy:0.2230
Epoch #162: Loss:1.5970, Accuracy:0.2401 Validation Loss:1.6066, Validation Accuracy:0.2230
Epoch #163: Loss:1.5975, Accuracy:0.2426 Validation Loss:1.6073, Validation Accuracy:0.2295
Epoch #164: Loss:1.5984, Accuracy:0.2393 Validation Loss:1.6073, Validation Accuracy:0.2148
Epoch #165: Loss:1.5964, Accuracy:0.2434 Validation Loss:1.6074, Validation Accuracy:0.2295
Epoch #166: Loss:1.5967, Accuracy:0.2438 Validation Loss:1.6062, Validation Accuracy:0.2230
Epoch #167: Loss:1.5970, Accuracy:0.2406 Validation Loss:1.6064, Validation Accuracy:0.2148
Epoch #168: Loss:1.5965, Accuracy:0.2426 Validation Loss:1.6068, Validation Accuracy:0.2311
Epoch #169: Loss:1.5964, Accuracy:0.2393 Validation Loss:1.6062, Validation Accuracy:0.2148
Epoch #170: Loss:1.5963, Accuracy:0.2426 Validation Loss:1.6062, Validation Accuracy:0.2230
Epoch #171: Loss:1.5962, Accuracy:0.2434 Validation Loss:1.6063, Validation Accuracy:0.2361
Epoch #172: Loss:1.5962, Accuracy:0.2389 Validation Loss:1.6064, Validation Accuracy:0.2148
Epoch #173: Loss:1.5960, Accuracy:0.2406 Validation Loss:1.6063, Validation Accuracy:0.2230
Epoch #174: Loss:1.5958, Accuracy:0.2426 Validation Loss:1.6063, Validation Accuracy:0.2230
Epoch #175: Loss:1.5959, Accuracy:0.2389 Validation Loss:1.6065, Validation Accuracy:0.2148
Epoch #176: Loss:1.5960, Accuracy:0.2401 Validation Loss:1.6067, Validation Accuracy:0.2361
Epoch #177: Loss:1.5973, Accuracy:0.2426 Validation Loss:1.6070, Validation Accuracy:0.2393
Epoch #178: Loss:1.5961, Accuracy:0.2406 Validation Loss:1.6079, Validation Accuracy:0.2066
Epoch #179: Loss:1.5962, Accuracy:0.2426 Validation Loss:1.6064, Validation Accuracy:0.2230
Epoch #180: Loss:1.5957, Accuracy:0.2479 Validation Loss:1.6075, Validation Accuracy:0.2361
Epoch #181: Loss:1.5962, Accuracy:0.2455 Validation Loss:1.6064, Validation Accuracy:0.2148
Epoch #182: Loss:1.5958, Accuracy:0.2410 Validation Loss:1.6063, Validation Accuracy:0.2148
Epoch #183: Loss:1.5961, Accuracy:0.2410 Validation Loss:1.6064, Validation Accuracy:0.2230
Epoch #184: Loss:1.5957, Accuracy:0.2422 Validation Loss:1.6066, Validation Accuracy:0.2148
Epoch #185: Loss:1.5956, Accuracy:0.2471 Validation Loss:1.6067, Validation Accuracy:0.2311
Epoch #186: Loss:1.5955, Accuracy:0.2426 Validation Loss:1.6066, Validation Accuracy:0.2246
Epoch #187: Loss:1.5956, Accuracy:0.2410 Validation Loss:1.6068, Validation Accuracy:0.2246
Epoch #188: Loss:1.5953, Accuracy:0.2434 Validation Loss:1.6068, Validation Accuracy:0.2197
Epoch #189: Loss:1.5958, Accuracy:0.2369 Validation Loss:1.6071, Validation Accuracy:0.2311
Epoch #190: Loss:1.5955, Accuracy:0.2410 Validation Loss:1.6070, Validation Accuracy:0.2148
Epoch #191: Loss:1.5951, Accuracy:0.2418 Validation Loss:1.6070, Validation Accuracy:0.2246
Epoch #192: Loss:1.5960, Accuracy:0.2422 Validation Loss:1.6073, Validation Accuracy:0.2246
Epoch #193: Loss:1.5967, Accuracy:0.2385 Validation Loss:1.6074, Validation Accuracy:0.2148
Epoch #194: Loss:1.5966, Accuracy:0.2496 Validation Loss:1.6076, Validation Accuracy:0.2377
Epoch #195: Loss:1.5963, Accuracy:0.2401 Validation Loss:1.6072, Validation Accuracy:0.2148
Epoch #196: Loss:1.5951, Accuracy:0.2447 Validation Loss:1.6069, Validation Accuracy:0.2311
Epoch #197: Loss:1.5952, Accuracy:0.2471 Validation Loss:1.6067, Validation Accuracy:0.2377
Epoch #198: Loss:1.5950, Accuracy:0.2422 Validation Loss:1.6066, Validation Accuracy:0.2213
Epoch #199: Loss:1.5955, Accuracy:0.2397 Validation Loss:1.6068, Validation Accuracy:0.2148
Epoch #200: Loss:1.5950, Accuracy:0.2447 Validation Loss:1.6075, Validation Accuracy:0.2377
Epoch #201: Loss:1.5958, Accuracy:0.2455 Validation Loss:1.6067, Validation Accuracy:0.2295
Epoch #202: Loss:1.5967, Accuracy:0.2311 Validation Loss:1.6073, Validation Accuracy:0.2115
Epoch #203: Loss:1.5970, Accuracy:0.2422 Validation Loss:1.6072, Validation Accuracy:0.2377
Epoch #204: Loss:1.5953, Accuracy:0.2430 Validation Loss:1.6066, Validation Accuracy:0.2279
Epoch #205: Loss:1.5953, Accuracy:0.2422 Validation Loss:1.6063, Validation Accuracy:0.2164
Epoch #206: Loss:1.5948, Accuracy:0.2410 Validation Loss:1.6068, Validation Accuracy:0.2508
Epoch #207: Loss:1.5950, Accuracy:0.2397 Validation Loss:1.6066, Validation Accuracy:0.2295
Epoch #208: Loss:1.5952, Accuracy:0.2459 Validation Loss:1.6067, Validation Accuracy:0.2328
Epoch #209: Loss:1.5951, Accuracy:0.2455 Validation Loss:1.6067, Validation Accuracy:0.2148
Epoch #210: Loss:1.5942, Accuracy:0.2484 Validation Loss:1.6071, Validation Accuracy:0.2508
Epoch #211: Loss:1.5951, Accuracy:0.2475 Validation Loss:1.6069, Validation Accuracy:0.2377
Epoch #212: Loss:1.5939, Accuracy:0.2451 Validation Loss:1.6072, Validation Accuracy:0.2295
Epoch #213: Loss:1.5952, Accuracy:0.2340 Validation Loss:1.6070, Validation Accuracy:0.2295
Epoch #214: Loss:1.5953, Accuracy:0.2463 Validation Loss:1.6074, Validation Accuracy:0.2311
Epoch #215: Loss:1.5955, Accuracy:0.2430 Validation Loss:1.6072, Validation Accuracy:0.2131
Epoch #216: Loss:1.5940, Accuracy:0.2479 Validation Loss:1.6074, Validation Accuracy:0.2377
Epoch #217: Loss:1.5947, Accuracy:0.2422 Validation Loss:1.6071, Validation Accuracy:0.2164
Epoch #218: Loss:1.5940, Accuracy:0.2426 Validation Loss:1.6070, Validation Accuracy:0.2213
Epoch #219: Loss:1.5943, Accuracy:0.2410 Validation Loss:1.6072, Validation Accuracy:0.2295
Epoch #220: Loss:1.5940, Accuracy:0.2488 Validation Loss:1.6072, Validation Accuracy:0.2246
Epoch #221: Loss:1.5942, Accuracy:0.2488 Validation Loss:1.6072, Validation Accuracy:0.2246
Epoch #222: Loss:1.5940, Accuracy:0.2455 Validation Loss:1.6072, Validation Accuracy:0.2295
Epoch #223: Loss:1.5939, Accuracy:0.2430 Validation Loss:1.6073, Validation Accuracy:0.2213
Epoch #224: Loss:1.5952, Accuracy:0.2438 Validation Loss:1.6072, Validation Accuracy:0.2148
Epoch #225: Loss:1.5943, Accuracy:0.2484 Validation Loss:1.6082, Validation Accuracy:0.2377
Epoch #226: Loss:1.5937, Accuracy:0.2496 Validation Loss:1.6076, Validation Accuracy:0.2082
Epoch #227: Loss:1.5959, Accuracy:0.2389 Validation Loss:1.6070, Validation Accuracy:0.2082
Epoch #228: Loss:1.5936, Accuracy:0.2479 Validation Loss:1.6081, Validation Accuracy:0.2393
Epoch #229: Loss:1.5943, Accuracy:0.2434 Validation Loss:1.6069, Validation Accuracy:0.2213
Epoch #230: Loss:1.5935, Accuracy:0.2463 Validation Loss:1.6069, Validation Accuracy:0.2295
Epoch #231: Loss:1.5939, Accuracy:0.2438 Validation Loss:1.6070, Validation Accuracy:0.2164
Epoch #232: Loss:1.5936, Accuracy:0.2459 Validation Loss:1.6082, Validation Accuracy:0.2377
Epoch #233: Loss:1.5937, Accuracy:0.2463 Validation Loss:1.6071, Validation Accuracy:0.2164
Epoch #234: Loss:1.5930, Accuracy:0.2463 Validation Loss:1.6071, Validation Accuracy:0.2295
Epoch #235: Loss:1.5937, Accuracy:0.2451 Validation Loss:1.6072, Validation Accuracy:0.2311
Epoch #236: Loss:1.5937, Accuracy:0.2570 Validation Loss:1.6078, Validation Accuracy:0.2197
Epoch #237: Loss:1.5938, Accuracy:0.2467 Validation Loss:1.6078, Validation Accuracy:0.2311
Epoch #238: Loss:1.5938, Accuracy:0.2467 Validation Loss:1.6074, Validation Accuracy:0.2213
Epoch #239: Loss:1.5928, Accuracy:0.2537 Validation Loss:1.6076, Validation Accuracy:0.2508
Epoch #240: Loss:1.5929, Accuracy:0.2541 Validation Loss:1.6071, Validation Accuracy:0.2262
Epoch #241: Loss:1.5940, Accuracy:0.2385 Validation Loss:1.6078, Validation Accuracy:0.2180
Epoch #242: Loss:1.5951, Accuracy:0.2443 Validation Loss:1.6076, Validation Accuracy:0.2508
Epoch #243: Loss:1.5925, Accuracy:0.2599 Validation Loss:1.6074, Validation Accuracy:0.2148
Epoch #244: Loss:1.5952, Accuracy:0.2455 Validation Loss:1.6072, Validation Accuracy:0.2246
Epoch #245: Loss:1.5942, Accuracy:0.2467 Validation Loss:1.6071, Validation Accuracy:0.2475
Epoch #246: Loss:1.5929, Accuracy:0.2549 Validation Loss:1.6071, Validation Accuracy:0.2262
Epoch #247: Loss:1.5928, Accuracy:0.2508 Validation Loss:1.6073, Validation Accuracy:0.2328
Epoch #248: Loss:1.5944, Accuracy:0.2434 Validation Loss:1.6071, Validation Accuracy:0.2393
Epoch #249: Loss:1.5929, Accuracy:0.2463 Validation Loss:1.6072, Validation Accuracy:0.2295
Epoch #250: Loss:1.5935, Accuracy:0.2525 Validation Loss:1.6066, Validation Accuracy:0.2361
Epoch #251: Loss:1.5922, Accuracy:0.2553 Validation Loss:1.6066, Validation Accuracy:0.2361
Epoch #252: Loss:1.5924, Accuracy:0.2459 Validation Loss:1.6064, Validation Accuracy:0.2361
Epoch #253: Loss:1.5916, Accuracy:0.2500 Validation Loss:1.6067, Validation Accuracy:0.2410
Epoch #254: Loss:1.5931, Accuracy:0.2496 Validation Loss:1.6066, Validation Accuracy:0.2410
Epoch #255: Loss:1.5934, Accuracy:0.2484 Validation Loss:1.6070, Validation Accuracy:0.2344
Epoch #256: Loss:1.5930, Accuracy:0.2418 Validation Loss:1.6071, Validation Accuracy:0.2557
Epoch #257: Loss:1.5936, Accuracy:0.2541 Validation Loss:1.6074, Validation Accuracy:0.2361
Epoch #258: Loss:1.5918, Accuracy:0.2541 Validation Loss:1.6065, Validation Accuracy:0.2361
Epoch #259: Loss:1.5923, Accuracy:0.2475 Validation Loss:1.6065, Validation Accuracy:0.2475
Epoch #260: Loss:1.5919, Accuracy:0.2492 Validation Loss:1.6061, Validation Accuracy:0.2361
Epoch #261: Loss:1.5916, Accuracy:0.2512 Validation Loss:1.6071, Validation Accuracy:0.2377
Epoch #262: Loss:1.5919, Accuracy:0.2574 Validation Loss:1.6068, Validation Accuracy:0.2295
Epoch #263: Loss:1.5919, Accuracy:0.2496 Validation Loss:1.6071, Validation Accuracy:0.2328
Epoch #264: Loss:1.5918, Accuracy:0.2500 Validation Loss:1.6070, Validation Accuracy:0.2426
Epoch #265: Loss:1.5916, Accuracy:0.2500 Validation Loss:1.6069, Validation Accuracy:0.2393
Epoch #266: Loss:1.5938, Accuracy:0.2393 Validation Loss:1.6063, Validation Accuracy:0.2426
Epoch #267: Loss:1.5928, Accuracy:0.2545 Validation Loss:1.6068, Validation Accuracy:0.2574
Epoch #268: Loss:1.5916, Accuracy:0.2541 Validation Loss:1.6064, Validation Accuracy:0.2361
Epoch #269: Loss:1.5916, Accuracy:0.2529 Validation Loss:1.6060, Validation Accuracy:0.2377
Epoch #270: Loss:1.5922, Accuracy:0.2500 Validation Loss:1.6059, Validation Accuracy:0.2344
Epoch #271: Loss:1.5921, Accuracy:0.2521 Validation Loss:1.6060, Validation Accuracy:0.2426
Epoch #272: Loss:1.5917, Accuracy:0.2521 Validation Loss:1.6068, Validation Accuracy:0.2426
Epoch #273: Loss:1.5909, Accuracy:0.2545 Validation Loss:1.6065, Validation Accuracy:0.2443
Epoch #274: Loss:1.5916, Accuracy:0.2570 Validation Loss:1.6064, Validation Accuracy:0.2377
Epoch #275: Loss:1.5918, Accuracy:0.2521 Validation Loss:1.6063, Validation Accuracy:0.2377
Epoch #276: Loss:1.5915, Accuracy:0.2594 Validation Loss:1.6069, Validation Accuracy:0.2344
Epoch #277: Loss:1.5913, Accuracy:0.2475 Validation Loss:1.6075, Validation Accuracy:0.2344
Epoch #278: Loss:1.5915, Accuracy:0.2504 Validation Loss:1.6065, Validation Accuracy:0.2393
Epoch #279: Loss:1.5905, Accuracy:0.2508 Validation Loss:1.6063, Validation Accuracy:0.2344
Epoch #280: Loss:1.5919, Accuracy:0.2533 Validation Loss:1.6064, Validation Accuracy:0.2393
Epoch #281: Loss:1.5916, Accuracy:0.2521 Validation Loss:1.6084, Validation Accuracy:0.2443
Epoch #282: Loss:1.5915, Accuracy:0.2484 Validation Loss:1.6063, Validation Accuracy:0.2410
Epoch #283: Loss:1.5914, Accuracy:0.2508 Validation Loss:1.6064, Validation Accuracy:0.2344
Epoch #284: Loss:1.5903, Accuracy:0.2529 Validation Loss:1.6067, Validation Accuracy:0.2311
Epoch #285: Loss:1.5904, Accuracy:0.2504 Validation Loss:1.6063, Validation Accuracy:0.2328
Epoch #286: Loss:1.5927, Accuracy:0.2508 Validation Loss:1.6066, Validation Accuracy:0.2377
Epoch #287: Loss:1.5936, Accuracy:0.2521 Validation Loss:1.6079, Validation Accuracy:0.2574
Epoch #288: Loss:1.5899, Accuracy:0.2553 Validation Loss:1.6079, Validation Accuracy:0.2344
Epoch #289: Loss:1.5924, Accuracy:0.2479 Validation Loss:1.6067, Validation Accuracy:0.2328
Epoch #290: Loss:1.5930, Accuracy:0.2533 Validation Loss:1.6064, Validation Accuracy:0.2475
Epoch #291: Loss:1.5920, Accuracy:0.2504 Validation Loss:1.6078, Validation Accuracy:0.2459
Epoch #292: Loss:1.5916, Accuracy:0.2471 Validation Loss:1.6069, Validation Accuracy:0.2377
Epoch #293: Loss:1.5913, Accuracy:0.2541 Validation Loss:1.6064, Validation Accuracy:0.2459
Epoch #294: Loss:1.5910, Accuracy:0.2578 Validation Loss:1.6070, Validation Accuracy:0.2361
Epoch #295: Loss:1.5903, Accuracy:0.2508 Validation Loss:1.6060, Validation Accuracy:0.2393
Epoch #296: Loss:1.5908, Accuracy:0.2516 Validation Loss:1.6062, Validation Accuracy:0.2410
Epoch #297: Loss:1.5902, Accuracy:0.2533 Validation Loss:1.6065, Validation Accuracy:0.2262
Epoch #298: Loss:1.5905, Accuracy:0.2521 Validation Loss:1.6068, Validation Accuracy:0.2311
Epoch #299: Loss:1.5907, Accuracy:0.2545 Validation Loss:1.6068, Validation Accuracy:0.2393
Epoch #300: Loss:1.5914, Accuracy:0.2418 Validation Loss:1.6075, Validation Accuracy:0.2361

Test:
Test Loss:1.60753620, Accuracy:0.2361
Labels: ['03', '05', '02', '04', '01']
Confusion Matrix:
[[ 3 37  0 23 52]
 [ 5 54  4 36 43]
 [ 8 42  2 23 39]
 [ 5 37  4 37 30]
 [ 5 41  1 31 48]]
Classification Report:
              precision    recall  f1-score   support

          03       0.12      0.03      0.04       115
          05       0.26      0.38      0.31       142
          02       0.18      0.02      0.03       114
          04       0.25      0.33      0.28       113
          01       0.23      0.38      0.28       126

    accuracy                           0.24       610
   macro avg       0.21      0.23      0.19       610
weighted avg       0.21      0.24      0.20       610

============ Config: 1/1 === End Time: 2019.07.25 01:04:41 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 54 minutes, 44 seconds =====================


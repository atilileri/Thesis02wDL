======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf13.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.31 09:36:57 =======================================
Parameters: inputFolder : C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
sampRate : 8
featureMode : FrMgPh
channelMode : Front
classificationMode : Speaker
trainingEpoch : 300
stepSize : 1
batchSize : 512
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3044 Files with 15 Label(s): ['sg', 'mb', 'ib', 'yd', 'by', 'ek', 'my', 'eg', 'sk', 'eo', 'ds', 'ck', 'ce', 'aa', 'eb'].
Padding:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3044 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2435 steps for training, 609 steps for test
Splitting Train and Test Data...
------Model for FrMgPh------
---LSTM Classifier---
Train Batch: (2435, 7991, 42)
Test Batch: (609, 7991, 42)
Optimizer: <keras.optimizers.Adam object at 0x000001A401210240>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001A449958048>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            16136     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 25,131
Trainable params: 25,131
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.7069, Accuracy:0.0686, Validation Loss:2.7023, Validation Accuracy:0.1002
Epoch #2: Loss:2.6976, Accuracy:0.0817, Validation Loss:2.6917, Validation Accuracy:0.0739
Epoch #3: Loss:2.6870, Accuracy:0.0842, Validation Loss:2.6832, Validation Accuracy:0.0805
Epoch #4: Loss:2.6791, Accuracy:0.0834, Validation Loss:2.6764, Validation Accuracy:0.0854
Epoch #5: Loss:2.6717, Accuracy:0.0838, Validation Loss:2.6686, Validation Accuracy:0.0821
Epoch #6: Loss:2.6655, Accuracy:0.0821, Validation Loss:2.6632, Validation Accuracy:0.0837
Epoch #7: Loss:2.6594, Accuracy:0.0830, Validation Loss:2.6561, Validation Accuracy:0.0837
Epoch #8: Loss:2.6539, Accuracy:0.0887, Validation Loss:2.6516, Validation Accuracy:0.1330
Epoch #9: Loss:2.6472, Accuracy:0.1216, Validation Loss:2.6437, Validation Accuracy:0.1593
Epoch #10: Loss:2.6390, Accuracy:0.1368, Validation Loss:2.6346, Validation Accuracy:0.1461
Epoch #11: Loss:2.6293, Accuracy:0.1491, Validation Loss:2.6237, Validation Accuracy:0.1412
Epoch #12: Loss:2.6169, Accuracy:0.1511, Validation Loss:2.6118, Validation Accuracy:0.1626
Epoch #13: Loss:2.6041, Accuracy:0.1618, Validation Loss:2.5972, Validation Accuracy:0.1626
Epoch #14: Loss:2.5918, Accuracy:0.1598, Validation Loss:2.5873, Validation Accuracy:0.1626
Epoch #15: Loss:2.5762, Accuracy:0.1622, Validation Loss:2.5710, Validation Accuracy:0.1626
Epoch #16: Loss:2.5638, Accuracy:0.1618, Validation Loss:2.5595, Validation Accuracy:0.1626
Epoch #17: Loss:2.5520, Accuracy:0.1630, Validation Loss:2.5457, Validation Accuracy:0.1658
Epoch #18: Loss:2.5402, Accuracy:0.1671, Validation Loss:2.5364, Validation Accuracy:0.1658
Epoch #19: Loss:2.5295, Accuracy:0.1667, Validation Loss:2.5284, Validation Accuracy:0.1642
Epoch #20: Loss:2.5209, Accuracy:0.1696, Validation Loss:2.5258, Validation Accuracy:0.1642
Epoch #21: Loss:2.5146, Accuracy:0.1667, Validation Loss:2.5187, Validation Accuracy:0.1658
Epoch #22: Loss:2.5036, Accuracy:0.1737, Validation Loss:2.5126, Validation Accuracy:0.1593
Epoch #23: Loss:2.4966, Accuracy:0.1684, Validation Loss:2.5070, Validation Accuracy:0.1576
Epoch #24: Loss:2.4886, Accuracy:0.1680, Validation Loss:2.4960, Validation Accuracy:0.1708
Epoch #25: Loss:2.4823, Accuracy:0.1692, Validation Loss:2.5014, Validation Accuracy:0.1527
Epoch #26: Loss:2.4790, Accuracy:0.1725, Validation Loss:2.5000, Validation Accuracy:0.1494
Epoch #27: Loss:2.4962, Accuracy:0.1671, Validation Loss:2.5115, Validation Accuracy:0.1724
Epoch #28: Loss:2.4995, Accuracy:0.1602, Validation Loss:2.4821, Validation Accuracy:0.1642
Epoch #29: Loss:2.4716, Accuracy:0.1692, Validation Loss:2.4842, Validation Accuracy:0.1626
Epoch #30: Loss:2.4744, Accuracy:0.1598, Validation Loss:2.5106, Validation Accuracy:0.1511
Epoch #31: Loss:2.5383, Accuracy:0.1483, Validation Loss:2.6009, Validation Accuracy:0.1642
Epoch #32: Loss:2.5485, Accuracy:0.1540, Validation Loss:2.5554, Validation Accuracy:0.1478
Epoch #33: Loss:2.4983, Accuracy:0.1622, Validation Loss:2.4862, Validation Accuracy:0.1724
Epoch #34: Loss:2.4743, Accuracy:0.1819, Validation Loss:2.4733, Validation Accuracy:0.1823
Epoch #35: Loss:2.4665, Accuracy:0.1791, Validation Loss:2.4827, Validation Accuracy:0.1741
Epoch #36: Loss:2.4768, Accuracy:0.1602, Validation Loss:2.4867, Validation Accuracy:0.1691
Epoch #37: Loss:2.4648, Accuracy:0.1708, Validation Loss:2.4821, Validation Accuracy:0.1790
Epoch #38: Loss:2.4631, Accuracy:0.1713, Validation Loss:2.4838, Validation Accuracy:0.1675
Epoch #39: Loss:2.4614, Accuracy:0.1700, Validation Loss:2.4764, Validation Accuracy:0.1741
Epoch #40: Loss:2.4590, Accuracy:0.1754, Validation Loss:2.4746, Validation Accuracy:0.1741
Epoch #41: Loss:2.4584, Accuracy:0.1688, Validation Loss:2.4801, Validation Accuracy:0.1724
Epoch #42: Loss:2.4548, Accuracy:0.1688, Validation Loss:2.4755, Validation Accuracy:0.1839
Epoch #43: Loss:2.4551, Accuracy:0.1737, Validation Loss:2.4781, Validation Accuracy:0.1741
Epoch #44: Loss:2.4521, Accuracy:0.1729, Validation Loss:2.4763, Validation Accuracy:0.1773
Epoch #45: Loss:2.4508, Accuracy:0.1737, Validation Loss:2.4767, Validation Accuracy:0.1708
Epoch #46: Loss:2.4523, Accuracy:0.1696, Validation Loss:2.4767, Validation Accuracy:0.1708
Epoch #47: Loss:2.4512, Accuracy:0.1745, Validation Loss:2.4764, Validation Accuracy:0.1773
Epoch #48: Loss:2.4492, Accuracy:0.1688, Validation Loss:2.4790, Validation Accuracy:0.1790
Epoch #49: Loss:2.4481, Accuracy:0.1700, Validation Loss:2.4755, Validation Accuracy:0.1741
Epoch #50: Loss:2.4477, Accuracy:0.1713, Validation Loss:2.4781, Validation Accuracy:0.1741
Epoch #51: Loss:2.4476, Accuracy:0.1700, Validation Loss:2.4748, Validation Accuracy:0.1806
Epoch #52: Loss:2.4456, Accuracy:0.1741, Validation Loss:2.4731, Validation Accuracy:0.1773
Epoch #53: Loss:2.4469, Accuracy:0.1692, Validation Loss:2.4759, Validation Accuracy:0.1757
Epoch #54: Loss:2.4455, Accuracy:0.1762, Validation Loss:2.4736, Validation Accuracy:0.1790
Epoch #55: Loss:2.4444, Accuracy:0.1754, Validation Loss:2.4765, Validation Accuracy:0.1757
Epoch #56: Loss:2.4432, Accuracy:0.1717, Validation Loss:2.4740, Validation Accuracy:0.1806
Epoch #57: Loss:2.4427, Accuracy:0.1770, Validation Loss:2.4738, Validation Accuracy:0.1806
Epoch #58: Loss:2.4447, Accuracy:0.1721, Validation Loss:2.4764, Validation Accuracy:0.1773
Epoch #59: Loss:2.4421, Accuracy:0.1721, Validation Loss:2.4741, Validation Accuracy:0.1790
Epoch #60: Loss:2.4452, Accuracy:0.1717, Validation Loss:2.4755, Validation Accuracy:0.1806
Epoch #61: Loss:2.4449, Accuracy:0.1725, Validation Loss:2.4743, Validation Accuracy:0.1823
Epoch #62: Loss:2.4417, Accuracy:0.1762, Validation Loss:2.4742, Validation Accuracy:0.1806
Epoch #63: Loss:2.4428, Accuracy:0.1721, Validation Loss:2.4735, Validation Accuracy:0.1773
Epoch #64: Loss:2.4415, Accuracy:0.1741, Validation Loss:2.4708, Validation Accuracy:0.1823
Epoch #65: Loss:2.4422, Accuracy:0.1684, Validation Loss:2.4694, Validation Accuracy:0.1741
Epoch #66: Loss:2.4433, Accuracy:0.1639, Validation Loss:2.4687, Validation Accuracy:0.1757
Epoch #67: Loss:2.4432, Accuracy:0.1688, Validation Loss:2.4731, Validation Accuracy:0.1741
Epoch #68: Loss:2.4399, Accuracy:0.1737, Validation Loss:2.4699, Validation Accuracy:0.1757
Epoch #69: Loss:2.4410, Accuracy:0.1717, Validation Loss:2.4716, Validation Accuracy:0.1806
Epoch #70: Loss:2.4399, Accuracy:0.1708, Validation Loss:2.4690, Validation Accuracy:0.1773
Epoch #71: Loss:2.4402, Accuracy:0.1733, Validation Loss:2.4683, Validation Accuracy:0.1790
Epoch #72: Loss:2.4386, Accuracy:0.1729, Validation Loss:2.4684, Validation Accuracy:0.1757
Epoch #73: Loss:2.4398, Accuracy:0.1725, Validation Loss:2.4701, Validation Accuracy:0.1773
Epoch #74: Loss:2.4393, Accuracy:0.1737, Validation Loss:2.4680, Validation Accuracy:0.1806
Epoch #75: Loss:2.4395, Accuracy:0.1741, Validation Loss:2.4690, Validation Accuracy:0.1773
Epoch #76: Loss:2.4369, Accuracy:0.1700, Validation Loss:2.4683, Validation Accuracy:0.1856
Epoch #77: Loss:2.4359, Accuracy:0.1737, Validation Loss:2.4726, Validation Accuracy:0.1773
Epoch #78: Loss:2.4384, Accuracy:0.1741, Validation Loss:2.4741, Validation Accuracy:0.1773
Epoch #79: Loss:2.4380, Accuracy:0.1749, Validation Loss:2.4748, Validation Accuracy:0.1773
Epoch #80: Loss:2.4379, Accuracy:0.1737, Validation Loss:2.4745, Validation Accuracy:0.1790
Epoch #81: Loss:2.4391, Accuracy:0.1741, Validation Loss:2.4716, Validation Accuracy:0.1773
Epoch #82: Loss:2.4391, Accuracy:0.1733, Validation Loss:2.4716, Validation Accuracy:0.1773
Epoch #83: Loss:2.4379, Accuracy:0.1733, Validation Loss:2.4743, Validation Accuracy:0.1773
Epoch #84: Loss:2.4349, Accuracy:0.1737, Validation Loss:2.4733, Validation Accuracy:0.1773
Epoch #85: Loss:2.4350, Accuracy:0.1737, Validation Loss:2.4751, Validation Accuracy:0.1757
Epoch #86: Loss:2.4350, Accuracy:0.1733, Validation Loss:2.4750, Validation Accuracy:0.1773
Epoch #87: Loss:2.4339, Accuracy:0.1737, Validation Loss:2.4748, Validation Accuracy:0.1757
Epoch #88: Loss:2.4336, Accuracy:0.1745, Validation Loss:2.4760, Validation Accuracy:0.1773
Epoch #89: Loss:2.4337, Accuracy:0.1741, Validation Loss:2.4757, Validation Accuracy:0.1790
Epoch #90: Loss:2.4333, Accuracy:0.1733, Validation Loss:2.4749, Validation Accuracy:0.1757
Epoch #91: Loss:2.4346, Accuracy:0.1729, Validation Loss:2.4743, Validation Accuracy:0.1806
Epoch #92: Loss:2.4342, Accuracy:0.1737, Validation Loss:2.4745, Validation Accuracy:0.1839
Epoch #93: Loss:2.4342, Accuracy:0.1749, Validation Loss:2.4749, Validation Accuracy:0.1839
Epoch #94: Loss:2.4347, Accuracy:0.1758, Validation Loss:2.4766, Validation Accuracy:0.1790
Epoch #95: Loss:2.4359, Accuracy:0.1733, Validation Loss:2.4757, Validation Accuracy:0.1839
Epoch #96: Loss:2.4360, Accuracy:0.1729, Validation Loss:2.4746, Validation Accuracy:0.1806
Epoch #97: Loss:2.4337, Accuracy:0.1717, Validation Loss:2.4765, Validation Accuracy:0.1790
Epoch #98: Loss:2.4351, Accuracy:0.1758, Validation Loss:2.4757, Validation Accuracy:0.1806
Epoch #99: Loss:2.4337, Accuracy:0.1737, Validation Loss:2.4777, Validation Accuracy:0.1757
Epoch #100: Loss:2.4335, Accuracy:0.1758, Validation Loss:2.4770, Validation Accuracy:0.1872
Epoch #101: Loss:2.4324, Accuracy:0.1778, Validation Loss:2.4780, Validation Accuracy:0.1839
Epoch #102: Loss:2.4335, Accuracy:0.1815, Validation Loss:2.4760, Validation Accuracy:0.1872
Epoch #103: Loss:2.4318, Accuracy:0.1811, Validation Loss:2.4772, Validation Accuracy:0.1773
Epoch #104: Loss:2.4324, Accuracy:0.1786, Validation Loss:2.4756, Validation Accuracy:0.1757
Epoch #105: Loss:2.4315, Accuracy:0.1795, Validation Loss:2.4772, Validation Accuracy:0.1741
Epoch #106: Loss:2.4316, Accuracy:0.1803, Validation Loss:2.4784, Validation Accuracy:0.1757
Epoch #107: Loss:2.4330, Accuracy:0.1807, Validation Loss:2.4777, Validation Accuracy:0.1757
Epoch #108: Loss:2.4342, Accuracy:0.1737, Validation Loss:2.4746, Validation Accuracy:0.1773
Epoch #109: Loss:2.4352, Accuracy:0.1832, Validation Loss:2.4751, Validation Accuracy:0.1757
Epoch #110: Loss:2.4373, Accuracy:0.1729, Validation Loss:2.4748, Validation Accuracy:0.1757
Epoch #111: Loss:2.4356, Accuracy:0.1791, Validation Loss:2.4735, Validation Accuracy:0.1856
Epoch #112: Loss:2.4311, Accuracy:0.1770, Validation Loss:2.4780, Validation Accuracy:0.1790
Epoch #113: Loss:2.4353, Accuracy:0.1749, Validation Loss:2.4750, Validation Accuracy:0.1856
Epoch #114: Loss:2.4362, Accuracy:0.1832, Validation Loss:2.4743, Validation Accuracy:0.1790
Epoch #115: Loss:2.4317, Accuracy:0.1778, Validation Loss:2.4762, Validation Accuracy:0.1823
Epoch #116: Loss:2.4320, Accuracy:0.1786, Validation Loss:2.4745, Validation Accuracy:0.1806
Epoch #117: Loss:2.4325, Accuracy:0.1811, Validation Loss:2.4765, Validation Accuracy:0.1773
Epoch #118: Loss:2.4315, Accuracy:0.1799, Validation Loss:2.4784, Validation Accuracy:0.1757
Epoch #119: Loss:2.4317, Accuracy:0.1786, Validation Loss:2.4771, Validation Accuracy:0.1773
Epoch #120: Loss:2.4324, Accuracy:0.1778, Validation Loss:2.4767, Validation Accuracy:0.1773
Epoch #121: Loss:2.4322, Accuracy:0.1778, Validation Loss:2.4776, Validation Accuracy:0.1757
Epoch #122: Loss:2.4325, Accuracy:0.1807, Validation Loss:2.4779, Validation Accuracy:0.1757
Epoch #123: Loss:2.4310, Accuracy:0.1811, Validation Loss:2.4803, Validation Accuracy:0.1741
Epoch #124: Loss:2.4311, Accuracy:0.1799, Validation Loss:2.4797, Validation Accuracy:0.1757
Epoch #125: Loss:2.4305, Accuracy:0.1807, Validation Loss:2.4794, Validation Accuracy:0.1839
Epoch #126: Loss:2.4299, Accuracy:0.1815, Validation Loss:2.4812, Validation Accuracy:0.1741
Epoch #127: Loss:2.4302, Accuracy:0.1799, Validation Loss:2.4799, Validation Accuracy:0.1773
Epoch #128: Loss:2.4305, Accuracy:0.1823, Validation Loss:2.4795, Validation Accuracy:0.1757
Epoch #129: Loss:2.4308, Accuracy:0.1791, Validation Loss:2.4807, Validation Accuracy:0.1741
Epoch #130: Loss:2.4302, Accuracy:0.1778, Validation Loss:2.4817, Validation Accuracy:0.1839
Epoch #131: Loss:2.4311, Accuracy:0.1799, Validation Loss:2.4808, Validation Accuracy:0.1741
Epoch #132: Loss:2.4287, Accuracy:0.1815, Validation Loss:2.4797, Validation Accuracy:0.1823
Epoch #133: Loss:2.4290, Accuracy:0.1782, Validation Loss:2.4807, Validation Accuracy:0.1741
Epoch #134: Loss:2.4290, Accuracy:0.1786, Validation Loss:2.4811, Validation Accuracy:0.1757
Epoch #135: Loss:2.4288, Accuracy:0.1811, Validation Loss:2.4807, Validation Accuracy:0.1741
Epoch #136: Loss:2.4287, Accuracy:0.1791, Validation Loss:2.4807, Validation Accuracy:0.1741
Epoch #137: Loss:2.4281, Accuracy:0.1811, Validation Loss:2.4807, Validation Accuracy:0.1839
Epoch #138: Loss:2.4283, Accuracy:0.1799, Validation Loss:2.4820, Validation Accuracy:0.1741
Epoch #139: Loss:2.4288, Accuracy:0.1778, Validation Loss:2.4815, Validation Accuracy:0.1741
Epoch #140: Loss:2.4290, Accuracy:0.1819, Validation Loss:2.4805, Validation Accuracy:0.1741
Epoch #141: Loss:2.4291, Accuracy:0.1791, Validation Loss:2.4809, Validation Accuracy:0.1741
Epoch #142: Loss:2.4302, Accuracy:0.1799, Validation Loss:2.4810, Validation Accuracy:0.1741
Epoch #143: Loss:2.4324, Accuracy:0.1745, Validation Loss:2.4808, Validation Accuracy:0.1823
Epoch #144: Loss:2.4300, Accuracy:0.1832, Validation Loss:2.4808, Validation Accuracy:0.1823
Epoch #145: Loss:2.4288, Accuracy:0.1795, Validation Loss:2.4811, Validation Accuracy:0.1741
Epoch #146: Loss:2.4272, Accuracy:0.1795, Validation Loss:2.4801, Validation Accuracy:0.1839
Epoch #147: Loss:2.4283, Accuracy:0.1803, Validation Loss:2.4823, Validation Accuracy:0.1741
Epoch #148: Loss:2.4278, Accuracy:0.1807, Validation Loss:2.4809, Validation Accuracy:0.1757
Epoch #149: Loss:2.4272, Accuracy:0.1819, Validation Loss:2.4804, Validation Accuracy:0.1839
Epoch #150: Loss:2.4271, Accuracy:0.1778, Validation Loss:2.4807, Validation Accuracy:0.1741
Epoch #151: Loss:2.4273, Accuracy:0.1786, Validation Loss:2.4805, Validation Accuracy:0.1823
Epoch #152: Loss:2.4277, Accuracy:0.1799, Validation Loss:2.4817, Validation Accuracy:0.1741
Epoch #153: Loss:2.4282, Accuracy:0.1778, Validation Loss:2.4821, Validation Accuracy:0.1741
Epoch #154: Loss:2.4277, Accuracy:0.1774, Validation Loss:2.4808, Validation Accuracy:0.1823
Epoch #155: Loss:2.4270, Accuracy:0.1819, Validation Loss:2.4807, Validation Accuracy:0.1757
Epoch #156: Loss:2.4264, Accuracy:0.1791, Validation Loss:2.4827, Validation Accuracy:0.1741
Epoch #157: Loss:2.4271, Accuracy:0.1791, Validation Loss:2.4811, Validation Accuracy:0.1839
Epoch #158: Loss:2.4271, Accuracy:0.1823, Validation Loss:2.4806, Validation Accuracy:0.1757
Epoch #159: Loss:2.4272, Accuracy:0.1782, Validation Loss:2.4815, Validation Accuracy:0.1757
Epoch #160: Loss:2.4263, Accuracy:0.1799, Validation Loss:2.4827, Validation Accuracy:0.1741
Epoch #161: Loss:2.4296, Accuracy:0.1786, Validation Loss:2.4822, Validation Accuracy:0.1856
Epoch #162: Loss:2.4329, Accuracy:0.1721, Validation Loss:2.4817, Validation Accuracy:0.1741
Epoch #163: Loss:2.4320, Accuracy:0.1782, Validation Loss:2.4807, Validation Accuracy:0.1839
Epoch #164: Loss:2.4297, Accuracy:0.1774, Validation Loss:2.4810, Validation Accuracy:0.1839
Epoch #165: Loss:2.4288, Accuracy:0.1778, Validation Loss:2.4824, Validation Accuracy:0.1741
Epoch #166: Loss:2.4264, Accuracy:0.1823, Validation Loss:2.4822, Validation Accuracy:0.1872
Epoch #167: Loss:2.4260, Accuracy:0.1840, Validation Loss:2.4837, Validation Accuracy:0.1773
Epoch #168: Loss:2.4264, Accuracy:0.1795, Validation Loss:2.4805, Validation Accuracy:0.1839
Epoch #169: Loss:2.4265, Accuracy:0.1782, Validation Loss:2.4824, Validation Accuracy:0.1741
Epoch #170: Loss:2.4251, Accuracy:0.1791, Validation Loss:2.4817, Validation Accuracy:0.1839
Epoch #171: Loss:2.4255, Accuracy:0.1832, Validation Loss:2.4819, Validation Accuracy:0.1741
Epoch #172: Loss:2.4256, Accuracy:0.1762, Validation Loss:2.4813, Validation Accuracy:0.1741
Epoch #173: Loss:2.4257, Accuracy:0.1786, Validation Loss:2.4820, Validation Accuracy:0.1741
Epoch #174: Loss:2.4251, Accuracy:0.1795, Validation Loss:2.4817, Validation Accuracy:0.1741
Epoch #175: Loss:2.4260, Accuracy:0.1758, Validation Loss:2.4812, Validation Accuracy:0.1773
Epoch #176: Loss:2.4277, Accuracy:0.1786, Validation Loss:2.4822, Validation Accuracy:0.1790
Epoch #177: Loss:2.4263, Accuracy:0.1803, Validation Loss:2.4818, Validation Accuracy:0.1872
Epoch #178: Loss:2.4256, Accuracy:0.1758, Validation Loss:2.4821, Validation Accuracy:0.1773
Epoch #179: Loss:2.4257, Accuracy:0.1791, Validation Loss:2.4809, Validation Accuracy:0.1872
Epoch #180: Loss:2.4244, Accuracy:0.1795, Validation Loss:2.4828, Validation Accuracy:0.1806
Epoch #181: Loss:2.4246, Accuracy:0.1828, Validation Loss:2.4828, Validation Accuracy:0.1872
Epoch #182: Loss:2.4252, Accuracy:0.1836, Validation Loss:2.4835, Validation Accuracy:0.1773
Epoch #183: Loss:2.4252, Accuracy:0.1799, Validation Loss:2.4821, Validation Accuracy:0.1872
Epoch #184: Loss:2.4265, Accuracy:0.1811, Validation Loss:2.4830, Validation Accuracy:0.1773
Epoch #185: Loss:2.4267, Accuracy:0.1782, Validation Loss:2.4820, Validation Accuracy:0.1872
Epoch #186: Loss:2.4247, Accuracy:0.1828, Validation Loss:2.4829, Validation Accuracy:0.1806
Epoch #187: Loss:2.4245, Accuracy:0.1811, Validation Loss:2.4821, Validation Accuracy:0.1872
Epoch #188: Loss:2.4238, Accuracy:0.1815, Validation Loss:2.4840, Validation Accuracy:0.1773
Epoch #189: Loss:2.4267, Accuracy:0.1770, Validation Loss:2.4828, Validation Accuracy:0.1872
Epoch #190: Loss:2.4299, Accuracy:0.1762, Validation Loss:2.4829, Validation Accuracy:0.1806
Epoch #191: Loss:2.4253, Accuracy:0.1795, Validation Loss:2.4824, Validation Accuracy:0.1790
Epoch #192: Loss:2.4238, Accuracy:0.1823, Validation Loss:2.4839, Validation Accuracy:0.1790
Epoch #193: Loss:2.4237, Accuracy:0.1811, Validation Loss:2.4823, Validation Accuracy:0.1856
Epoch #194: Loss:2.4235, Accuracy:0.1848, Validation Loss:2.4830, Validation Accuracy:0.1806
Epoch #195: Loss:2.4242, Accuracy:0.1782, Validation Loss:2.4814, Validation Accuracy:0.1872
Epoch #196: Loss:2.4246, Accuracy:0.1840, Validation Loss:2.4845, Validation Accuracy:0.1806
Epoch #197: Loss:2.4239, Accuracy:0.1815, Validation Loss:2.4835, Validation Accuracy:0.1856
Epoch #198: Loss:2.4236, Accuracy:0.1807, Validation Loss:2.4832, Validation Accuracy:0.1839
Epoch #199: Loss:2.4233, Accuracy:0.1778, Validation Loss:2.4832, Validation Accuracy:0.1806
Epoch #200: Loss:2.4229, Accuracy:0.1774, Validation Loss:2.4839, Validation Accuracy:0.1773
Epoch #201: Loss:2.4232, Accuracy:0.1803, Validation Loss:2.4828, Validation Accuracy:0.1856
Epoch #202: Loss:2.4262, Accuracy:0.1815, Validation Loss:2.4837, Validation Accuracy:0.1773
Epoch #203: Loss:2.4244, Accuracy:0.1774, Validation Loss:2.4829, Validation Accuracy:0.1790
Epoch #204: Loss:2.4235, Accuracy:0.1819, Validation Loss:2.4831, Validation Accuracy:0.1872
Epoch #205: Loss:2.4229, Accuracy:0.1828, Validation Loss:2.4846, Validation Accuracy:0.1806
Epoch #206: Loss:2.4236, Accuracy:0.1786, Validation Loss:2.4834, Validation Accuracy:0.1856
Epoch #207: Loss:2.4235, Accuracy:0.1799, Validation Loss:2.4844, Validation Accuracy:0.1790
Epoch #208: Loss:2.4231, Accuracy:0.1774, Validation Loss:2.4842, Validation Accuracy:0.1757
Epoch #209: Loss:2.4233, Accuracy:0.1815, Validation Loss:2.4852, Validation Accuracy:0.1741
Epoch #210: Loss:2.4228, Accuracy:0.1807, Validation Loss:2.4818, Validation Accuracy:0.1839
Epoch #211: Loss:2.4239, Accuracy:0.1819, Validation Loss:2.4813, Validation Accuracy:0.1839
Epoch #212: Loss:2.4241, Accuracy:0.1819, Validation Loss:2.4825, Validation Accuracy:0.1839
Epoch #213: Loss:2.4230, Accuracy:0.1807, Validation Loss:2.4815, Validation Accuracy:0.1872
Epoch #214: Loss:2.4245, Accuracy:0.1807, Validation Loss:2.4819, Validation Accuracy:0.1856
Epoch #215: Loss:2.4231, Accuracy:0.1832, Validation Loss:2.4840, Validation Accuracy:0.1757
Epoch #216: Loss:2.4230, Accuracy:0.1856, Validation Loss:2.4826, Validation Accuracy:0.1823
Epoch #217: Loss:2.4221, Accuracy:0.1840, Validation Loss:2.4829, Validation Accuracy:0.1856
Epoch #218: Loss:2.4224, Accuracy:0.1819, Validation Loss:2.4846, Validation Accuracy:0.1757
Epoch #219: Loss:2.4230, Accuracy:0.1807, Validation Loss:2.4813, Validation Accuracy:0.1888
Epoch #220: Loss:2.4241, Accuracy:0.1823, Validation Loss:2.4815, Validation Accuracy:0.1806
Epoch #221: Loss:2.4278, Accuracy:0.1758, Validation Loss:2.4815, Validation Accuracy:0.1888
Epoch #222: Loss:2.4274, Accuracy:0.1778, Validation Loss:2.4789, Validation Accuracy:0.1905
Epoch #223: Loss:2.4267, Accuracy:0.1828, Validation Loss:2.4783, Validation Accuracy:0.1839
Epoch #224: Loss:2.4251, Accuracy:0.1754, Validation Loss:2.4777, Validation Accuracy:0.1856
Epoch #225: Loss:2.4247, Accuracy:0.1819, Validation Loss:2.4769, Validation Accuracy:0.1905
Epoch #226: Loss:2.4251, Accuracy:0.1758, Validation Loss:2.4792, Validation Accuracy:0.1888
Epoch #227: Loss:2.4240, Accuracy:0.1815, Validation Loss:2.4785, Validation Accuracy:0.1888
Epoch #228: Loss:2.4238, Accuracy:0.1852, Validation Loss:2.4785, Validation Accuracy:0.1790
Epoch #229: Loss:2.4236, Accuracy:0.1766, Validation Loss:2.4761, Validation Accuracy:0.1888
Epoch #230: Loss:2.4247, Accuracy:0.1844, Validation Loss:2.4778, Validation Accuracy:0.1806
Epoch #231: Loss:2.4246, Accuracy:0.1795, Validation Loss:2.4764, Validation Accuracy:0.1905
Epoch #232: Loss:2.4238, Accuracy:0.1852, Validation Loss:2.4762, Validation Accuracy:0.1905
Epoch #233: Loss:2.4239, Accuracy:0.1823, Validation Loss:2.4806, Validation Accuracy:0.1888
Epoch #234: Loss:2.4239, Accuracy:0.1791, Validation Loss:2.4766, Validation Accuracy:0.1888
Epoch #235: Loss:2.4209, Accuracy:0.1836, Validation Loss:2.4784, Validation Accuracy:0.1888
Epoch #236: Loss:2.4248, Accuracy:0.1815, Validation Loss:2.4759, Validation Accuracy:0.1872
Epoch #237: Loss:2.4237, Accuracy:0.1848, Validation Loss:2.4783, Validation Accuracy:0.1872
Epoch #238: Loss:2.4235, Accuracy:0.1795, Validation Loss:2.4753, Validation Accuracy:0.1888
Epoch #239: Loss:2.4258, Accuracy:0.1803, Validation Loss:2.4759, Validation Accuracy:0.1888
Epoch #240: Loss:2.4226, Accuracy:0.1791, Validation Loss:2.4787, Validation Accuracy:0.1872
Epoch #241: Loss:2.4229, Accuracy:0.1807, Validation Loss:2.4760, Validation Accuracy:0.1872
Epoch #242: Loss:2.4215, Accuracy:0.1840, Validation Loss:2.4791, Validation Accuracy:0.1954
Epoch #243: Loss:2.4208, Accuracy:0.1811, Validation Loss:2.4756, Validation Accuracy:0.1888
Epoch #244: Loss:2.4228, Accuracy:0.1782, Validation Loss:2.4778, Validation Accuracy:0.1938
Epoch #245: Loss:2.4219, Accuracy:0.1832, Validation Loss:2.4768, Validation Accuracy:0.1905
Epoch #246: Loss:2.4214, Accuracy:0.1836, Validation Loss:2.4782, Validation Accuracy:0.1888
Epoch #247: Loss:2.4214, Accuracy:0.1823, Validation Loss:2.4767, Validation Accuracy:0.1888
Epoch #248: Loss:2.4200, Accuracy:0.1852, Validation Loss:2.4776, Validation Accuracy:0.1856
Epoch #249: Loss:2.4202, Accuracy:0.1832, Validation Loss:2.4786, Validation Accuracy:0.1905
Epoch #250: Loss:2.4203, Accuracy:0.1828, Validation Loss:2.4785, Validation Accuracy:0.1872
Epoch #251: Loss:2.4212, Accuracy:0.1791, Validation Loss:2.4799, Validation Accuracy:0.1872
Epoch #252: Loss:2.4212, Accuracy:0.1828, Validation Loss:2.4787, Validation Accuracy:0.1839
Epoch #253: Loss:2.4223, Accuracy:0.1840, Validation Loss:2.4821, Validation Accuracy:0.1921
Epoch #254: Loss:2.4262, Accuracy:0.1774, Validation Loss:2.4796, Validation Accuracy:0.1839
Epoch #255: Loss:2.4248, Accuracy:0.1832, Validation Loss:2.4840, Validation Accuracy:0.1790
Epoch #256: Loss:2.4308, Accuracy:0.1786, Validation Loss:2.4754, Validation Accuracy:0.1806
Epoch #257: Loss:2.4263, Accuracy:0.1754, Validation Loss:2.4831, Validation Accuracy:0.1757
Epoch #258: Loss:2.4267, Accuracy:0.1766, Validation Loss:2.4786, Validation Accuracy:0.1773
Epoch #259: Loss:2.4260, Accuracy:0.1791, Validation Loss:2.4811, Validation Accuracy:0.1757
Epoch #260: Loss:2.4261, Accuracy:0.1729, Validation Loss:2.4840, Validation Accuracy:0.1773
Epoch #261: Loss:2.4250, Accuracy:0.1754, Validation Loss:2.4813, Validation Accuracy:0.1806
Epoch #262: Loss:2.4256, Accuracy:0.1823, Validation Loss:2.4819, Validation Accuracy:0.1823
Epoch #263: Loss:2.4240, Accuracy:0.1815, Validation Loss:2.4823, Validation Accuracy:0.1823
Epoch #264: Loss:2.4259, Accuracy:0.1832, Validation Loss:2.4830, Validation Accuracy:0.1839
Epoch #265: Loss:2.4223, Accuracy:0.1791, Validation Loss:2.4828, Validation Accuracy:0.1839
Epoch #266: Loss:2.4229, Accuracy:0.1778, Validation Loss:2.4871, Validation Accuracy:0.1757
Epoch #267: Loss:2.4225, Accuracy:0.1786, Validation Loss:2.4848, Validation Accuracy:0.1806
Epoch #268: Loss:2.4224, Accuracy:0.1836, Validation Loss:2.4850, Validation Accuracy:0.1806
Epoch #269: Loss:2.4225, Accuracy:0.1836, Validation Loss:2.4852, Validation Accuracy:0.1806
Epoch #270: Loss:2.4225, Accuracy:0.1840, Validation Loss:2.4850, Validation Accuracy:0.1823
Epoch #271: Loss:2.4222, Accuracy:0.1840, Validation Loss:2.4845, Validation Accuracy:0.1806
Epoch #272: Loss:2.4230, Accuracy:0.1828, Validation Loss:2.4849, Validation Accuracy:0.1823
Epoch #273: Loss:2.4239, Accuracy:0.1840, Validation Loss:2.4856, Validation Accuracy:0.1823
Epoch #274: Loss:2.4233, Accuracy:0.1819, Validation Loss:2.4843, Validation Accuracy:0.1823
Epoch #275: Loss:2.4231, Accuracy:0.1828, Validation Loss:2.4855, Validation Accuracy:0.1823
Epoch #276: Loss:2.4233, Accuracy:0.1807, Validation Loss:2.4842, Validation Accuracy:0.1823
Epoch #277: Loss:2.4229, Accuracy:0.1815, Validation Loss:2.4864, Validation Accuracy:0.1823
Epoch #278: Loss:2.4229, Accuracy:0.1844, Validation Loss:2.4855, Validation Accuracy:0.1823
Epoch #279: Loss:2.4230, Accuracy:0.1815, Validation Loss:2.4857, Validation Accuracy:0.1823
Epoch #280: Loss:2.4228, Accuracy:0.1832, Validation Loss:2.4869, Validation Accuracy:0.1823
Epoch #281: Loss:2.4231, Accuracy:0.1828, Validation Loss:2.4854, Validation Accuracy:0.1823
Epoch #282: Loss:2.4226, Accuracy:0.1811, Validation Loss:2.4857, Validation Accuracy:0.1823
Epoch #283: Loss:2.4230, Accuracy:0.1819, Validation Loss:2.4860, Validation Accuracy:0.1823
Epoch #284: Loss:2.4239, Accuracy:0.1823, Validation Loss:2.4879, Validation Accuracy:0.1823
Epoch #285: Loss:2.4244, Accuracy:0.1819, Validation Loss:2.4857, Validation Accuracy:0.1806
Epoch #286: Loss:2.4228, Accuracy:0.1815, Validation Loss:2.4843, Validation Accuracy:0.1856
Epoch #287: Loss:2.4225, Accuracy:0.1832, Validation Loss:2.4865, Validation Accuracy:0.1823
Epoch #288: Loss:2.4221, Accuracy:0.1832, Validation Loss:2.4832, Validation Accuracy:0.1823
Epoch #289: Loss:2.4220, Accuracy:0.1828, Validation Loss:2.4869, Validation Accuracy:0.1823
Epoch #290: Loss:2.4221, Accuracy:0.1828, Validation Loss:2.4849, Validation Accuracy:0.1823
Epoch #291: Loss:2.4213, Accuracy:0.1852, Validation Loss:2.4854, Validation Accuracy:0.1823
Epoch #292: Loss:2.4218, Accuracy:0.1815, Validation Loss:2.4851, Validation Accuracy:0.1823
Epoch #293: Loss:2.4214, Accuracy:0.1832, Validation Loss:2.4846, Validation Accuracy:0.1823
Epoch #294: Loss:2.4218, Accuracy:0.1795, Validation Loss:2.4848, Validation Accuracy:0.1823
Epoch #295: Loss:2.4211, Accuracy:0.1791, Validation Loss:2.4834, Validation Accuracy:0.1856
Epoch #296: Loss:2.4226, Accuracy:0.1815, Validation Loss:2.4852, Validation Accuracy:0.1823
Epoch #297: Loss:2.4210, Accuracy:0.1803, Validation Loss:2.4834, Validation Accuracy:0.1823
Epoch #298: Loss:2.4206, Accuracy:0.1807, Validation Loss:2.4875, Validation Accuracy:0.1823
Epoch #299: Loss:2.4244, Accuracy:0.1819, Validation Loss:2.4852, Validation Accuracy:0.1823
Epoch #300: Loss:2.4212, Accuracy:0.1832, Validation Loss:2.4852, Validation Accuracy:0.1823

Test:

======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf51.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.24 12:27:48 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'nMags', 'channelMode': '1Ov', 'classificationMode': 'Speaker', 'trainingEpoch': 300, 'stepSize': 6, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 15 Label(s): ['eo', 'my', 'ib', 'sg', 'sk', 'eg', 'ck', 'ce', 'ek', 'by', 'eb', 'aa', 'mb', 'ds', 'yd'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for nMags------
---LSTM Classifier---
Train Batch: (2436, 7989, 36)
Test Batch: (610, 7989, 36)
Optimizer: <keras.optimizers.Adam object at 0x000002048019FBA8>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x00000204F6DD6AE8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            13832     
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 22,827
Trainable params: 22,827
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.7084, Accuracy:0.0686 Validation Loss:2.7004, Validation Accuracy:0.0836
Epoch #2: Loss:2.6972, Accuracy:0.0829 Validation Loss:2.6918, Validation Accuracy:0.0836
Epoch #3: Loss:2.6894, Accuracy:0.0829 Validation Loss:2.6857, Validation Accuracy:0.0836
Epoch #4: Loss:2.6838, Accuracy:0.0829 Validation Loss:2.6802, Validation Accuracy:0.0836
Epoch #5: Loss:2.6786, Accuracy:0.0829 Validation Loss:2.6756, Validation Accuracy:0.0836
Epoch #6: Loss:2.6740, Accuracy:0.0829 Validation Loss:2.6713, Validation Accuracy:0.0836
Epoch #7: Loss:2.6696, Accuracy:0.0899 Validation Loss:2.6669, Validation Accuracy:0.1148
Epoch #8: Loss:2.6655, Accuracy:0.1322 Validation Loss:2.6621, Validation Accuracy:0.1328
Epoch #9: Loss:2.6608, Accuracy:0.1433 Validation Loss:2.6567, Validation Accuracy:0.1344
Epoch #10: Loss:2.6555, Accuracy:0.1429 Validation Loss:2.6503, Validation Accuracy:0.1393
Epoch #11: Loss:2.6489, Accuracy:0.1420 Validation Loss:2.6422, Validation Accuracy:0.1393
Epoch #12: Loss:2.6407, Accuracy:0.1416 Validation Loss:2.6317, Validation Accuracy:0.1410
Epoch #13: Loss:2.6305, Accuracy:0.1379 Validation Loss:2.6192, Validation Accuracy:0.1393
Epoch #14: Loss:2.6189, Accuracy:0.1408 Validation Loss:2.6056, Validation Accuracy:0.1459
Epoch #15: Loss:2.6061, Accuracy:0.1502 Validation Loss:2.5917, Validation Accuracy:0.1393
Epoch #16: Loss:2.5934, Accuracy:0.1548 Validation Loss:2.5764, Validation Accuracy:0.1492
Epoch #17: Loss:2.5806, Accuracy:0.1572 Validation Loss:2.5626, Validation Accuracy:0.1393
Epoch #18: Loss:2.5681, Accuracy:0.1568 Validation Loss:2.5479, Validation Accuracy:0.1541
Epoch #19: Loss:2.5553, Accuracy:0.1552 Validation Loss:2.5348, Validation Accuracy:0.1459
Epoch #20: Loss:2.5434, Accuracy:0.1560 Validation Loss:2.5210, Validation Accuracy:0.1475
Epoch #21: Loss:2.5318, Accuracy:0.1564 Validation Loss:2.5111, Validation Accuracy:0.1393
Epoch #22: Loss:2.5221, Accuracy:0.1572 Validation Loss:2.5008, Validation Accuracy:0.1443
Epoch #23: Loss:2.5124, Accuracy:0.1576 Validation Loss:2.4912, Validation Accuracy:0.1410
Epoch #24: Loss:2.5031, Accuracy:0.1580 Validation Loss:2.4851, Validation Accuracy:0.1393
Epoch #25: Loss:2.4962, Accuracy:0.1663 Validation Loss:2.4799, Validation Accuracy:0.1475
Epoch #26: Loss:2.4885, Accuracy:0.1741 Validation Loss:2.4736, Validation Accuracy:0.1574
Epoch #27: Loss:2.4867, Accuracy:0.1732 Validation Loss:2.4713, Validation Accuracy:0.1590
Epoch #28: Loss:2.4811, Accuracy:0.1741 Validation Loss:2.4692, Validation Accuracy:0.1443
Epoch #29: Loss:2.4752, Accuracy:0.1773 Validation Loss:2.4631, Validation Accuracy:0.1475
Epoch #30: Loss:2.4736, Accuracy:0.1823 Validation Loss:2.4587, Validation Accuracy:0.1639
Epoch #31: Loss:2.4700, Accuracy:0.1753 Validation Loss:2.4615, Validation Accuracy:0.1525
Epoch #32: Loss:2.4662, Accuracy:0.1773 Validation Loss:2.4594, Validation Accuracy:0.1639
Epoch #33: Loss:2.4636, Accuracy:0.1814 Validation Loss:2.4559, Validation Accuracy:0.1623
Epoch #34: Loss:2.4622, Accuracy:0.1778 Validation Loss:2.4544, Validation Accuracy:0.1607
Epoch #35: Loss:2.4586, Accuracy:0.1798 Validation Loss:2.4538, Validation Accuracy:0.1541
Epoch #36: Loss:2.4560, Accuracy:0.1847 Validation Loss:2.4549, Validation Accuracy:0.1738
Epoch #37: Loss:2.4518, Accuracy:0.1901 Validation Loss:2.4547, Validation Accuracy:0.1672
Epoch #38: Loss:2.4517, Accuracy:0.1814 Validation Loss:2.4511, Validation Accuracy:0.1607
Epoch #39: Loss:2.4482, Accuracy:0.1843 Validation Loss:2.4518, Validation Accuracy:0.1590
Epoch #40: Loss:2.4458, Accuracy:0.1872 Validation Loss:2.4478, Validation Accuracy:0.1639
Epoch #41: Loss:2.4437, Accuracy:0.1856 Validation Loss:2.4481, Validation Accuracy:0.1639
Epoch #42: Loss:2.4419, Accuracy:0.1888 Validation Loss:2.4480, Validation Accuracy:0.1689
Epoch #43: Loss:2.4401, Accuracy:0.1864 Validation Loss:2.4488, Validation Accuracy:0.1689
Epoch #44: Loss:2.4392, Accuracy:0.1856 Validation Loss:2.4488, Validation Accuracy:0.1639
Epoch #45: Loss:2.4366, Accuracy:0.1880 Validation Loss:2.4463, Validation Accuracy:0.1590
Epoch #46: Loss:2.4357, Accuracy:0.1847 Validation Loss:2.4474, Validation Accuracy:0.1689
Epoch #47: Loss:2.4346, Accuracy:0.1860 Validation Loss:2.4476, Validation Accuracy:0.1672
Epoch #48: Loss:2.4342, Accuracy:0.1860 Validation Loss:2.4518, Validation Accuracy:0.1672
Epoch #49: Loss:2.4308, Accuracy:0.1905 Validation Loss:2.4486, Validation Accuracy:0.1689
Epoch #50: Loss:2.4336, Accuracy:0.1897 Validation Loss:2.4510, Validation Accuracy:0.1705
Epoch #51: Loss:2.4310, Accuracy:0.1880 Validation Loss:2.4459, Validation Accuracy:0.1590
Epoch #52: Loss:2.4290, Accuracy:0.1901 Validation Loss:2.4493, Validation Accuracy:0.1623
Epoch #53: Loss:2.4269, Accuracy:0.1876 Validation Loss:2.4467, Validation Accuracy:0.1607
Epoch #54: Loss:2.4277, Accuracy:0.1884 Validation Loss:2.4523, Validation Accuracy:0.1770
Epoch #55: Loss:2.4289, Accuracy:0.1864 Validation Loss:2.4457, Validation Accuracy:0.1590
Epoch #56: Loss:2.4239, Accuracy:0.1888 Validation Loss:2.4452, Validation Accuracy:0.1623
Epoch #57: Loss:2.4245, Accuracy:0.1868 Validation Loss:2.4519, Validation Accuracy:0.1639
Epoch #58: Loss:2.4223, Accuracy:0.1909 Validation Loss:2.4475, Validation Accuracy:0.1672
Epoch #59: Loss:2.4203, Accuracy:0.1909 Validation Loss:2.4444, Validation Accuracy:0.1639
Epoch #60: Loss:2.4207, Accuracy:0.1954 Validation Loss:2.4506, Validation Accuracy:0.1721
Epoch #61: Loss:2.4294, Accuracy:0.1835 Validation Loss:2.4474, Validation Accuracy:0.1557
Epoch #62: Loss:2.4271, Accuracy:0.1860 Validation Loss:2.4566, Validation Accuracy:0.1705
Epoch #63: Loss:2.4200, Accuracy:0.1942 Validation Loss:2.4502, Validation Accuracy:0.1590
Epoch #64: Loss:2.4217, Accuracy:0.1933 Validation Loss:2.4505, Validation Accuracy:0.1607
Epoch #65: Loss:2.4195, Accuracy:0.1913 Validation Loss:2.4506, Validation Accuracy:0.1574
Epoch #66: Loss:2.4182, Accuracy:0.1901 Validation Loss:2.4487, Validation Accuracy:0.1607
Epoch #67: Loss:2.4198, Accuracy:0.1917 Validation Loss:2.4522, Validation Accuracy:0.1574
Epoch #68: Loss:2.4140, Accuracy:0.1950 Validation Loss:2.4500, Validation Accuracy:0.1607
Epoch #69: Loss:2.4135, Accuracy:0.1975 Validation Loss:2.4586, Validation Accuracy:0.1721
Epoch #70: Loss:2.4121, Accuracy:0.1999 Validation Loss:2.4503, Validation Accuracy:0.1623
Epoch #71: Loss:2.4197, Accuracy:0.1987 Validation Loss:2.4465, Validation Accuracy:0.1590
Epoch #72: Loss:2.4181, Accuracy:0.1921 Validation Loss:2.4587, Validation Accuracy:0.1656
Epoch #73: Loss:2.4142, Accuracy:0.1970 Validation Loss:2.4557, Validation Accuracy:0.1607
Epoch #74: Loss:2.4153, Accuracy:0.1942 Validation Loss:2.4554, Validation Accuracy:0.1590
Epoch #75: Loss:2.4135, Accuracy:0.1962 Validation Loss:2.4521, Validation Accuracy:0.1639
Epoch #76: Loss:2.4114, Accuracy:0.1987 Validation Loss:2.4526, Validation Accuracy:0.1623
Epoch #77: Loss:2.4099, Accuracy:0.1966 Validation Loss:2.4549, Validation Accuracy:0.1689
Epoch #78: Loss:2.4050, Accuracy:0.2007 Validation Loss:2.4540, Validation Accuracy:0.1689
Epoch #79: Loss:2.4054, Accuracy:0.2048 Validation Loss:2.4533, Validation Accuracy:0.1557
Epoch #80: Loss:2.4124, Accuracy:0.1950 Validation Loss:2.4511, Validation Accuracy:0.1754
Epoch #81: Loss:2.4079, Accuracy:0.1954 Validation Loss:2.4570, Validation Accuracy:0.1721
Epoch #82: Loss:2.4065, Accuracy:0.1975 Validation Loss:2.4540, Validation Accuracy:0.1672
Epoch #83: Loss:2.4031, Accuracy:0.2036 Validation Loss:2.4518, Validation Accuracy:0.1787
Epoch #84: Loss:2.4015, Accuracy:0.2057 Validation Loss:2.4511, Validation Accuracy:0.1689
Epoch #85: Loss:2.3978, Accuracy:0.2106 Validation Loss:2.4589, Validation Accuracy:0.1770
Epoch #86: Loss:2.3964, Accuracy:0.2069 Validation Loss:2.4529, Validation Accuracy:0.1541
Epoch #87: Loss:2.4002, Accuracy:0.2036 Validation Loss:2.4597, Validation Accuracy:0.1607
Epoch #88: Loss:2.3979, Accuracy:0.2061 Validation Loss:2.4555, Validation Accuracy:0.1689
Epoch #89: Loss:2.3957, Accuracy:0.2065 Validation Loss:2.4543, Validation Accuracy:0.1623
Epoch #90: Loss:2.3917, Accuracy:0.2098 Validation Loss:2.4480, Validation Accuracy:0.1721
Epoch #91: Loss:2.3899, Accuracy:0.2126 Validation Loss:2.4622, Validation Accuracy:0.1705
Epoch #92: Loss:2.3894, Accuracy:0.2020 Validation Loss:2.4574, Validation Accuracy:0.1639
Epoch #93: Loss:2.3903, Accuracy:0.2135 Validation Loss:2.4522, Validation Accuracy:0.1738
Epoch #94: Loss:2.3865, Accuracy:0.2114 Validation Loss:2.4632, Validation Accuracy:0.1574
Epoch #95: Loss:2.3857, Accuracy:0.2126 Validation Loss:2.4564, Validation Accuracy:0.1787
Epoch #96: Loss:2.3841, Accuracy:0.2016 Validation Loss:2.4647, Validation Accuracy:0.1623
Epoch #97: Loss:2.3871, Accuracy:0.2126 Validation Loss:2.4733, Validation Accuracy:0.1705
Epoch #98: Loss:2.3835, Accuracy:0.2118 Validation Loss:2.4658, Validation Accuracy:0.1623
Epoch #99: Loss:2.3770, Accuracy:0.2188 Validation Loss:2.4587, Validation Accuracy:0.1623
Epoch #100: Loss:2.3801, Accuracy:0.2114 Validation Loss:2.4627, Validation Accuracy:0.1623
Epoch #101: Loss:2.3828, Accuracy:0.2200 Validation Loss:2.4663, Validation Accuracy:0.1639
Epoch #102: Loss:2.3763, Accuracy:0.2184 Validation Loss:2.4632, Validation Accuracy:0.1672
Epoch #103: Loss:2.3738, Accuracy:0.2184 Validation Loss:2.4734, Validation Accuracy:0.1623
Epoch #104: Loss:2.3706, Accuracy:0.2126 Validation Loss:2.4687, Validation Accuracy:0.1623
Epoch #105: Loss:2.3701, Accuracy:0.2233 Validation Loss:2.4682, Validation Accuracy:0.1590
Epoch #106: Loss:2.3723, Accuracy:0.2151 Validation Loss:2.4638, Validation Accuracy:0.1705
Epoch #107: Loss:2.3734, Accuracy:0.2204 Validation Loss:2.4749, Validation Accuracy:0.1639
Epoch #108: Loss:2.3822, Accuracy:0.2089 Validation Loss:2.4799, Validation Accuracy:0.1541
Epoch #109: Loss:2.3698, Accuracy:0.2188 Validation Loss:2.4750, Validation Accuracy:0.1541
Epoch #110: Loss:2.3682, Accuracy:0.2159 Validation Loss:2.4739, Validation Accuracy:0.1574
Epoch #111: Loss:2.3632, Accuracy:0.2237 Validation Loss:2.4743, Validation Accuracy:0.1721
Epoch #112: Loss:2.3621, Accuracy:0.2225 Validation Loss:2.4769, Validation Accuracy:0.1672
Epoch #113: Loss:2.3608, Accuracy:0.2229 Validation Loss:2.4797, Validation Accuracy:0.1623
Epoch #114: Loss:2.3568, Accuracy:0.2241 Validation Loss:2.4745, Validation Accuracy:0.1557
Epoch #115: Loss:2.3535, Accuracy:0.2258 Validation Loss:2.4747, Validation Accuracy:0.1656
Epoch #116: Loss:2.3509, Accuracy:0.2336 Validation Loss:2.4819, Validation Accuracy:0.1623
Epoch #117: Loss:2.3548, Accuracy:0.2225 Validation Loss:2.4915, Validation Accuracy:0.1607
Epoch #118: Loss:2.3553, Accuracy:0.2188 Validation Loss:2.4793, Validation Accuracy:0.1475
Epoch #119: Loss:2.3507, Accuracy:0.2250 Validation Loss:2.4848, Validation Accuracy:0.1607
Epoch #120: Loss:2.3473, Accuracy:0.2311 Validation Loss:2.4859, Validation Accuracy:0.1590
Epoch #121: Loss:2.3427, Accuracy:0.2303 Validation Loss:2.4933, Validation Accuracy:0.1639
Epoch #122: Loss:2.3463, Accuracy:0.2221 Validation Loss:2.4993, Validation Accuracy:0.1623
Epoch #123: Loss:2.3425, Accuracy:0.2303 Validation Loss:2.4878, Validation Accuracy:0.1508
Epoch #124: Loss:2.3345, Accuracy:0.2319 Validation Loss:2.4942, Validation Accuracy:0.1508
Epoch #125: Loss:2.3310, Accuracy:0.2377 Validation Loss:2.4911, Validation Accuracy:0.1492
Epoch #126: Loss:2.3286, Accuracy:0.2406 Validation Loss:2.4962, Validation Accuracy:0.1443
Epoch #127: Loss:2.3273, Accuracy:0.2336 Validation Loss:2.5031, Validation Accuracy:0.1508
Epoch #128: Loss:2.3289, Accuracy:0.2348 Validation Loss:2.5005, Validation Accuracy:0.1525
Epoch #129: Loss:2.3341, Accuracy:0.2245 Validation Loss:2.5051, Validation Accuracy:0.1590
Epoch #130: Loss:2.3348, Accuracy:0.2307 Validation Loss:2.5510, Validation Accuracy:0.1623
Epoch #131: Loss:2.3456, Accuracy:0.2217 Validation Loss:2.4988, Validation Accuracy:0.1541
Epoch #132: Loss:2.3435, Accuracy:0.2274 Validation Loss:2.5016, Validation Accuracy:0.1508
Epoch #133: Loss:2.3219, Accuracy:0.2393 Validation Loss:2.5127, Validation Accuracy:0.1475
Epoch #134: Loss:2.3194, Accuracy:0.2475 Validation Loss:2.5094, Validation Accuracy:0.1590
Epoch #135: Loss:2.3197, Accuracy:0.2373 Validation Loss:2.5087, Validation Accuracy:0.1475
Epoch #136: Loss:2.3156, Accuracy:0.2434 Validation Loss:2.5114, Validation Accuracy:0.1623
Epoch #137: Loss:2.3109, Accuracy:0.2377 Validation Loss:2.5206, Validation Accuracy:0.1623
Epoch #138: Loss:2.3131, Accuracy:0.2401 Validation Loss:2.5179, Validation Accuracy:0.1393
Epoch #139: Loss:2.3055, Accuracy:0.2426 Validation Loss:2.5129, Validation Accuracy:0.1525
Epoch #140: Loss:2.3065, Accuracy:0.2471 Validation Loss:2.5170, Validation Accuracy:0.1574
Epoch #141: Loss:2.3070, Accuracy:0.2504 Validation Loss:2.5126, Validation Accuracy:0.1574
Epoch #142: Loss:2.3010, Accuracy:0.2438 Validation Loss:2.5116, Validation Accuracy:0.1525
Epoch #143: Loss:2.2925, Accuracy:0.2504 Validation Loss:2.5223, Validation Accuracy:0.1443
Epoch #144: Loss:2.2927, Accuracy:0.2455 Validation Loss:2.5193, Validation Accuracy:0.1410
Epoch #145: Loss:2.2903, Accuracy:0.2484 Validation Loss:2.5231, Validation Accuracy:0.1623
Epoch #146: Loss:2.2864, Accuracy:0.2512 Validation Loss:2.5213, Validation Accuracy:0.1607
Epoch #147: Loss:2.2869, Accuracy:0.2537 Validation Loss:2.5281, Validation Accuracy:0.1590
Epoch #148: Loss:2.2873, Accuracy:0.2484 Validation Loss:2.5352, Validation Accuracy:0.1590
Epoch #149: Loss:2.2857, Accuracy:0.2508 Validation Loss:2.5383, Validation Accuracy:0.1508
Epoch #150: Loss:2.2758, Accuracy:0.2545 Validation Loss:2.5393, Validation Accuracy:0.1541
Epoch #151: Loss:2.2760, Accuracy:0.2599 Validation Loss:2.5408, Validation Accuracy:0.1492
Epoch #152: Loss:2.2759, Accuracy:0.2492 Validation Loss:2.5374, Validation Accuracy:0.1590
Epoch #153: Loss:2.2736, Accuracy:0.2488 Validation Loss:2.5441, Validation Accuracy:0.1623
Epoch #154: Loss:2.2742, Accuracy:0.2594 Validation Loss:2.5483, Validation Accuracy:0.1541
Epoch #155: Loss:2.2708, Accuracy:0.2549 Validation Loss:2.5539, Validation Accuracy:0.1590
Epoch #156: Loss:2.2926, Accuracy:0.2451 Validation Loss:2.5580, Validation Accuracy:0.1541
Epoch #157: Loss:2.2945, Accuracy:0.2381 Validation Loss:2.5590, Validation Accuracy:0.1656
Epoch #158: Loss:2.2780, Accuracy:0.2521 Validation Loss:2.5607, Validation Accuracy:0.1541
Epoch #159: Loss:2.2748, Accuracy:0.2521 Validation Loss:2.5637, Validation Accuracy:0.1607
Epoch #160: Loss:2.2752, Accuracy:0.2504 Validation Loss:2.5592, Validation Accuracy:0.1541
Epoch #161: Loss:2.2771, Accuracy:0.2430 Validation Loss:2.5546, Validation Accuracy:0.1525
Epoch #162: Loss:2.2593, Accuracy:0.2570 Validation Loss:2.5530, Validation Accuracy:0.1623
Epoch #163: Loss:2.2560, Accuracy:0.2660 Validation Loss:2.5565, Validation Accuracy:0.1738
Epoch #164: Loss:2.2602, Accuracy:0.2508 Validation Loss:2.5540, Validation Accuracy:0.1705
Epoch #165: Loss:2.2538, Accuracy:0.2594 Validation Loss:2.5912, Validation Accuracy:0.1607
Epoch #166: Loss:2.2642, Accuracy:0.2545 Validation Loss:2.5531, Validation Accuracy:0.1492
Epoch #167: Loss:2.2515, Accuracy:0.2668 Validation Loss:2.5630, Validation Accuracy:0.1705
Epoch #168: Loss:2.2509, Accuracy:0.2738 Validation Loss:2.5656, Validation Accuracy:0.1508
Epoch #169: Loss:2.2398, Accuracy:0.2689 Validation Loss:2.5659, Validation Accuracy:0.1623
Epoch #170: Loss:2.2403, Accuracy:0.2599 Validation Loss:2.5607, Validation Accuracy:0.1607
Epoch #171: Loss:2.2381, Accuracy:0.2705 Validation Loss:2.5818, Validation Accuracy:0.1623
Epoch #172: Loss:2.2364, Accuracy:0.2718 Validation Loss:2.5756, Validation Accuracy:0.1557
Epoch #173: Loss:2.2305, Accuracy:0.2746 Validation Loss:2.5880, Validation Accuracy:0.1557
Epoch #174: Loss:2.2367, Accuracy:0.2586 Validation Loss:2.5837, Validation Accuracy:0.1607
Epoch #175: Loss:2.2334, Accuracy:0.2603 Validation Loss:2.5818, Validation Accuracy:0.1689
Epoch #176: Loss:2.2264, Accuracy:0.2750 Validation Loss:2.5885, Validation Accuracy:0.1721
Epoch #177: Loss:2.2299, Accuracy:0.2709 Validation Loss:2.5774, Validation Accuracy:0.1672
Epoch #178: Loss:2.2277, Accuracy:0.2730 Validation Loss:2.5884, Validation Accuracy:0.1705
Epoch #179: Loss:2.2294, Accuracy:0.2738 Validation Loss:2.5856, Validation Accuracy:0.1656
Epoch #180: Loss:2.2190, Accuracy:0.2677 Validation Loss:2.5869, Validation Accuracy:0.1656
Epoch #181: Loss:2.2161, Accuracy:0.2771 Validation Loss:2.5841, Validation Accuracy:0.1672
Epoch #182: Loss:2.2072, Accuracy:0.2861 Validation Loss:2.5905, Validation Accuracy:0.1607
Epoch #183: Loss:2.2105, Accuracy:0.2746 Validation Loss:2.5953, Validation Accuracy:0.1574
Epoch #184: Loss:2.2135, Accuracy:0.2750 Validation Loss:2.5951, Validation Accuracy:0.1623
Epoch #185: Loss:2.2313, Accuracy:0.2627 Validation Loss:2.5929, Validation Accuracy:0.1705
Epoch #186: Loss:2.2445, Accuracy:0.2619 Validation Loss:2.6075, Validation Accuracy:0.1607
Epoch #187: Loss:2.2395, Accuracy:0.2582 Validation Loss:2.5949, Validation Accuracy:0.1557
Epoch #188: Loss:2.2338, Accuracy:0.2656 Validation Loss:2.5899, Validation Accuracy:0.1557
Epoch #189: Loss:2.2136, Accuracy:0.2800 Validation Loss:2.5965, Validation Accuracy:0.1541
Epoch #190: Loss:2.2095, Accuracy:0.2800 Validation Loss:2.6036, Validation Accuracy:0.1656
Epoch #191: Loss:2.1992, Accuracy:0.2845 Validation Loss:2.5917, Validation Accuracy:0.1623
Epoch #192: Loss:2.1960, Accuracy:0.2820 Validation Loss:2.5980, Validation Accuracy:0.1689
Epoch #193: Loss:2.1916, Accuracy:0.2906 Validation Loss:2.6053, Validation Accuracy:0.1705
Epoch #194: Loss:2.1959, Accuracy:0.2857 Validation Loss:2.6007, Validation Accuracy:0.1525
Epoch #195: Loss:2.1862, Accuracy:0.2906 Validation Loss:2.6162, Validation Accuracy:0.1590
Epoch #196: Loss:2.1942, Accuracy:0.2763 Validation Loss:2.6078, Validation Accuracy:0.1607
Epoch #197: Loss:2.1904, Accuracy:0.2869 Validation Loss:2.6146, Validation Accuracy:0.1721
Epoch #198: Loss:2.1738, Accuracy:0.2993 Validation Loss:2.6118, Validation Accuracy:0.1607
Epoch #199: Loss:2.1737, Accuracy:0.2952 Validation Loss:2.6147, Validation Accuracy:0.1656
Epoch #200: Loss:2.1734, Accuracy:0.3005 Validation Loss:2.6289, Validation Accuracy:0.1607
Epoch #201: Loss:2.1756, Accuracy:0.2947 Validation Loss:2.6132, Validation Accuracy:0.1557
Epoch #202: Loss:2.1734, Accuracy:0.2939 Validation Loss:2.6341, Validation Accuracy:0.1656
Epoch #203: Loss:2.1806, Accuracy:0.2923 Validation Loss:2.6265, Validation Accuracy:0.1574
Epoch #204: Loss:2.1774, Accuracy:0.2976 Validation Loss:2.6241, Validation Accuracy:0.1607
Epoch #205: Loss:2.1707, Accuracy:0.3013 Validation Loss:2.6243, Validation Accuracy:0.1590
Epoch #206: Loss:2.1624, Accuracy:0.2993 Validation Loss:2.6303, Validation Accuracy:0.1574
Epoch #207: Loss:2.1639, Accuracy:0.2993 Validation Loss:2.6279, Validation Accuracy:0.1607
Epoch #208: Loss:2.1567, Accuracy:0.2997 Validation Loss:2.6406, Validation Accuracy:0.1607
Epoch #209: Loss:2.1787, Accuracy:0.2861 Validation Loss:2.6300, Validation Accuracy:0.1508
Epoch #210: Loss:2.1949, Accuracy:0.2865 Validation Loss:2.6567, Validation Accuracy:0.1607
Epoch #211: Loss:2.1821, Accuracy:0.2894 Validation Loss:2.6668, Validation Accuracy:0.1590
Epoch #212: Loss:2.2027, Accuracy:0.2759 Validation Loss:2.6328, Validation Accuracy:0.1541
Epoch #213: Loss:2.1751, Accuracy:0.2931 Validation Loss:2.6335, Validation Accuracy:0.1557
Epoch #214: Loss:2.1820, Accuracy:0.2861 Validation Loss:2.6460, Validation Accuracy:0.1656
Epoch #215: Loss:2.1668, Accuracy:0.2828 Validation Loss:2.6346, Validation Accuracy:0.1672
Epoch #216: Loss:2.1631, Accuracy:0.2968 Validation Loss:2.6443, Validation Accuracy:0.1623
Epoch #217: Loss:2.1591, Accuracy:0.2968 Validation Loss:2.6366, Validation Accuracy:0.1607
Epoch #218: Loss:2.1520, Accuracy:0.2972 Validation Loss:2.6572, Validation Accuracy:0.1574
Epoch #219: Loss:2.1481, Accuracy:0.3042 Validation Loss:2.6543, Validation Accuracy:0.1492
Epoch #220: Loss:2.1470, Accuracy:0.3071 Validation Loss:2.6715, Validation Accuracy:0.1607
Epoch #221: Loss:2.1617, Accuracy:0.2993 Validation Loss:2.6688, Validation Accuracy:0.1574
Epoch #222: Loss:2.1372, Accuracy:0.3095 Validation Loss:2.6506, Validation Accuracy:0.1623
Epoch #223: Loss:2.1330, Accuracy:0.3099 Validation Loss:2.6547, Validation Accuracy:0.1557
Epoch #224: Loss:2.1286, Accuracy:0.3157 Validation Loss:2.6649, Validation Accuracy:0.1557
Epoch #225: Loss:2.1314, Accuracy:0.3128 Validation Loss:2.6601, Validation Accuracy:0.1672
Epoch #226: Loss:2.1353, Accuracy:0.3099 Validation Loss:2.6683, Validation Accuracy:0.1607
Epoch #227: Loss:2.1316, Accuracy:0.3083 Validation Loss:2.6589, Validation Accuracy:0.1623
Epoch #228: Loss:2.1222, Accuracy:0.3120 Validation Loss:2.6595, Validation Accuracy:0.1557
Epoch #229: Loss:2.1228, Accuracy:0.3149 Validation Loss:2.6676, Validation Accuracy:0.1623
Epoch #230: Loss:2.1263, Accuracy:0.3132 Validation Loss:2.6693, Validation Accuracy:0.1557
Epoch #231: Loss:2.1235, Accuracy:0.3140 Validation Loss:2.6685, Validation Accuracy:0.1557
Epoch #232: Loss:2.1212, Accuracy:0.3161 Validation Loss:2.6716, Validation Accuracy:0.1639
Epoch #233: Loss:2.1317, Accuracy:0.3083 Validation Loss:2.6777, Validation Accuracy:0.1738
Epoch #234: Loss:2.1257, Accuracy:0.3099 Validation Loss:2.6679, Validation Accuracy:0.1639
Epoch #235: Loss:2.1321, Accuracy:0.3083 Validation Loss:2.6811, Validation Accuracy:0.1754
Epoch #236: Loss:2.1126, Accuracy:0.3173 Validation Loss:2.6731, Validation Accuracy:0.1590
Epoch #237: Loss:2.1093, Accuracy:0.3227 Validation Loss:2.6842, Validation Accuracy:0.1639
Epoch #238: Loss:2.1010, Accuracy:0.3210 Validation Loss:2.6866, Validation Accuracy:0.1656
Epoch #239: Loss:2.1143, Accuracy:0.3091 Validation Loss:2.6970, Validation Accuracy:0.1590
Epoch #240: Loss:2.1197, Accuracy:0.3095 Validation Loss:2.6863, Validation Accuracy:0.1607
Epoch #241: Loss:2.1050, Accuracy:0.3186 Validation Loss:2.6818, Validation Accuracy:0.1721
Epoch #242: Loss:2.1065, Accuracy:0.3120 Validation Loss:2.6929, Validation Accuracy:0.1705
Epoch #243: Loss:2.1074, Accuracy:0.3177 Validation Loss:2.7043, Validation Accuracy:0.1574
Epoch #244: Loss:2.1147, Accuracy:0.3173 Validation Loss:2.7061, Validation Accuracy:0.1557
Epoch #245: Loss:2.1445, Accuracy:0.2976 Validation Loss:2.7033, Validation Accuracy:0.1705
Epoch #246: Loss:2.1162, Accuracy:0.3181 Validation Loss:2.7023, Validation Accuracy:0.1656
Epoch #247: Loss:2.1107, Accuracy:0.3144 Validation Loss:2.6972, Validation Accuracy:0.1656
Epoch #248: Loss:2.1169, Accuracy:0.3153 Validation Loss:2.7125, Validation Accuracy:0.1607
Epoch #249: Loss:2.1228, Accuracy:0.3124 Validation Loss:2.7090, Validation Accuracy:0.1656
Epoch #250: Loss:2.1145, Accuracy:0.3091 Validation Loss:2.7214, Validation Accuracy:0.1574
Epoch #251: Loss:2.1234, Accuracy:0.3112 Validation Loss:2.6921, Validation Accuracy:0.1541
Epoch #252: Loss:2.1097, Accuracy:0.3120 Validation Loss:2.6861, Validation Accuracy:0.1508
Epoch #253: Loss:2.0937, Accuracy:0.3165 Validation Loss:2.6984, Validation Accuracy:0.1705
Epoch #254: Loss:2.0896, Accuracy:0.3222 Validation Loss:2.6949, Validation Accuracy:0.1656
Epoch #255: Loss:2.0837, Accuracy:0.3300 Validation Loss:2.7032, Validation Accuracy:0.1705
Epoch #256: Loss:2.0713, Accuracy:0.3370 Validation Loss:2.6978, Validation Accuracy:0.1607
Epoch #257: Loss:2.0708, Accuracy:0.3325 Validation Loss:2.7044, Validation Accuracy:0.1590
Epoch #258: Loss:2.0672, Accuracy:0.3342 Validation Loss:2.7080, Validation Accuracy:0.1590
Epoch #259: Loss:2.0747, Accuracy:0.3329 Validation Loss:2.7212, Validation Accuracy:0.1623
Epoch #260: Loss:2.0799, Accuracy:0.3251 Validation Loss:2.7224, Validation Accuracy:0.1639
Epoch #261: Loss:2.1072, Accuracy:0.3116 Validation Loss:2.7345, Validation Accuracy:0.1574
Epoch #262: Loss:2.0984, Accuracy:0.3132 Validation Loss:2.7074, Validation Accuracy:0.1639
Epoch #263: Loss:2.0808, Accuracy:0.3247 Validation Loss:2.7118, Validation Accuracy:0.1525
Epoch #264: Loss:2.0720, Accuracy:0.3346 Validation Loss:2.7196, Validation Accuracy:0.1607
Epoch #265: Loss:2.0728, Accuracy:0.3346 Validation Loss:2.7119, Validation Accuracy:0.1541
Epoch #266: Loss:2.0658, Accuracy:0.3354 Validation Loss:2.7149, Validation Accuracy:0.1525
Epoch #267: Loss:2.0655, Accuracy:0.3313 Validation Loss:2.7189, Validation Accuracy:0.1672
Epoch #268: Loss:2.0487, Accuracy:0.3415 Validation Loss:2.7144, Validation Accuracy:0.1656
Epoch #269: Loss:2.0506, Accuracy:0.3407 Validation Loss:2.7224, Validation Accuracy:0.1574
Epoch #270: Loss:2.0470, Accuracy:0.3378 Validation Loss:2.7234, Validation Accuracy:0.1672
Epoch #271: Loss:2.0446, Accuracy:0.3366 Validation Loss:2.7179, Validation Accuracy:0.1590
Epoch #272: Loss:2.0459, Accuracy:0.3448 Validation Loss:2.7207, Validation Accuracy:0.1607
Epoch #273: Loss:2.0443, Accuracy:0.3387 Validation Loss:2.7311, Validation Accuracy:0.1803
Epoch #274: Loss:2.0554, Accuracy:0.3354 Validation Loss:2.7354, Validation Accuracy:0.1525
Epoch #275: Loss:2.0637, Accuracy:0.3280 Validation Loss:2.7364, Validation Accuracy:0.1557
Epoch #276: Loss:2.0492, Accuracy:0.3374 Validation Loss:2.7331, Validation Accuracy:0.1721
Epoch #277: Loss:2.0331, Accuracy:0.3420 Validation Loss:2.7279, Validation Accuracy:0.1623
Epoch #278: Loss:2.0307, Accuracy:0.3444 Validation Loss:2.7343, Validation Accuracy:0.1590
Epoch #279: Loss:2.0369, Accuracy:0.3473 Validation Loss:2.7389, Validation Accuracy:0.1770
Epoch #280: Loss:2.0309, Accuracy:0.3498 Validation Loss:2.7552, Validation Accuracy:0.1639
Epoch #281: Loss:2.0295, Accuracy:0.3510 Validation Loss:2.7484, Validation Accuracy:0.1705
Epoch #282: Loss:2.0432, Accuracy:0.3358 Validation Loss:2.7377, Validation Accuracy:0.1656
Epoch #283: Loss:2.0382, Accuracy:0.3403 Validation Loss:2.7433, Validation Accuracy:0.1639
Epoch #284: Loss:2.0451, Accuracy:0.3387 Validation Loss:2.7448, Validation Accuracy:0.1623
Epoch #285: Loss:2.0418, Accuracy:0.3309 Validation Loss:2.7471, Validation Accuracy:0.1721
Epoch #286: Loss:2.0467, Accuracy:0.3465 Validation Loss:2.7517, Validation Accuracy:0.1656
Epoch #287: Loss:2.0518, Accuracy:0.3403 Validation Loss:2.7459, Validation Accuracy:0.1689
Epoch #288: Loss:2.0609, Accuracy:0.3206 Validation Loss:2.7647, Validation Accuracy:0.1721
Epoch #289: Loss:2.0453, Accuracy:0.3284 Validation Loss:2.7356, Validation Accuracy:0.1656
Epoch #290: Loss:2.0261, Accuracy:0.3452 Validation Loss:2.7468, Validation Accuracy:0.1754
Epoch #291: Loss:2.0317, Accuracy:0.3411 Validation Loss:2.7556, Validation Accuracy:0.1639
Epoch #292: Loss:2.0423, Accuracy:0.3350 Validation Loss:2.7511, Validation Accuracy:0.1590
Epoch #293: Loss:2.0523, Accuracy:0.3362 Validation Loss:2.7638, Validation Accuracy:0.1689
Epoch #294: Loss:2.0473, Accuracy:0.3362 Validation Loss:2.7673, Validation Accuracy:0.1754
Epoch #295: Loss:2.0337, Accuracy:0.3399 Validation Loss:2.7570, Validation Accuracy:0.1672
Epoch #296: Loss:2.0173, Accuracy:0.3481 Validation Loss:2.7546, Validation Accuracy:0.1738
Epoch #297: Loss:1.9971, Accuracy:0.3588 Validation Loss:2.7628, Validation Accuracy:0.1738
Epoch #298: Loss:1.9971, Accuracy:0.3539 Validation Loss:2.7710, Validation Accuracy:0.1705
Epoch #299: Loss:1.9944, Accuracy:0.3584 Validation Loss:2.7688, Validation Accuracy:0.1689
Epoch #300: Loss:1.9973, Accuracy:0.3584 Validation Loss:2.7718, Validation Accuracy:0.1803

Test:
Test Loss:2.77179956, Accuracy:0.1803
Labels: ['eo', 'my', 'ib', 'sg', 'sk', 'eg', 'ck', 'ce', 'ek', 'by', 'eb', 'aa', 'mb', 'ds', 'yd']
Confusion Matrix:
[[ 7  0  1  7  0  3  0  0  2  5  0  0  2  1  6]
 [ 1  0  1  2  0  8  0  0  1  0  1  0  3  1  2]
 [ 4  0 15 13  0  2  0  0  1  0  1  0  2  1 15]
 [ 3  0  5 16  0  0  0  0  5  3  3  0  6  1  9]
 [ 0  0  2  3  0 13  0  0  2  3  6  0  1  2  1]
 [ 6  0  1  1  0 21  0  0  4  7  4  2  0  4  0]
 [ 1  0  0  1  0  7  0  0  4  2  6  0  0  2  0]
 [ 3  0  2  3  0  7  0  0  1  5  1  0  1  1  3]
 [ 6  0  3  4  0  8  0  0  3  7  5  0  5  3  4]
 [ 8  0  0  3  0  8  0  0  4  5  1  0  5  0  6]
 [ 2  0  8  6  0 12  0  0  0  4  8  0  7  3  1]
 [ 2  0  1  2  0 13  0  0  2  1  4  2  2  4  1]
 [ 3  0  8  3  0  8  0  0  2  6  2  0  7  2 11]
 [ 1  0  0  2  0  5  0  0  2  2  7  3  2  6  1]
 [ 4  0 14 14  1  1  0  0  3  4  0  0  1  0 20]]
Classification Report:
              precision    recall  f1-score   support

          eo       0.14      0.21      0.16        34
          my       0.00      0.00      0.00        20
          ib       0.25      0.28      0.26        54
          sg       0.20      0.31      0.24        51
          sk       0.00      0.00      0.00        33
          eg       0.18      0.42      0.25        50
          ck       0.00      0.00      0.00        23
          ce       0.00      0.00      0.00        27
          ek       0.08      0.06      0.07        48
          by       0.09      0.12      0.11        40
          eb       0.16      0.16      0.16        51
          aa       0.29      0.06      0.10        34
          mb       0.16      0.13      0.15        52
          ds       0.19      0.19      0.19        31
          yd       0.25      0.32      0.28        62

    accuracy                           0.18       610
   macro avg       0.13      0.15      0.13       610
weighted avg       0.15      0.18      0.16       610

============ Config: 1/1 === End Time: 2019.07.24 13:21:25 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 53 minutes, 36 seconds =====================


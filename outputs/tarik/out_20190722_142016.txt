======= Running File: lstmKeras.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf15.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.22 14:20:16 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'channelMode': '0', 'classificationMode': 'Speaker', 'trainingEpoch': 300, 'stepSize': 4, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3046 Files with 15 Label(s): ['ib', 'sk', 'eb', 'eo', 'aa', 'my', 'ek', 'ce', 'mb', 'eg', 'sg', 'yd', 'ck', 'ds', 'by'].
Padding:......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3046 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 15 classes
2436 steps for training, 610 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (2436, 11988, 9)
Test Batch: (610, 11988, 9)
Optimizer: <keras.optimizers.Adam object at 0x0000017CB9200898>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000017C2E7E6A60>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 249, 8)            3464      
_________________________________________________________________
activation_1 (Activation)    (None, 249, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 10, 16)            3088      
_________________________________________________________________
activation_2 (Activation)    (None, 10, 16)            0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 10, 24)            3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 15)                195       
=================================================================
Total params: 12,459
Trainable params: 12,459
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.6983, Accuracy:0.0829 Validation Loss:2.6914, Validation Accuracy:0.0836
Epoch #2: Loss:2.6884, Accuracy:0.0829 Validation Loss:2.6831, Validation Accuracy:0.0836
Epoch #3: Loss:2.6815, Accuracy:0.0829 Validation Loss:2.6777, Validation Accuracy:0.0836
Epoch #4: Loss:2.6770, Accuracy:0.0829 Validation Loss:2.6738, Validation Accuracy:0.0836
Epoch #5: Loss:2.6737, Accuracy:0.0829 Validation Loss:2.6705, Validation Accuracy:0.0836
Epoch #6: Loss:2.6703, Accuracy:0.0809 Validation Loss:2.6678, Validation Accuracy:0.1016
Epoch #7: Loss:2.6675, Accuracy:0.1022 Validation Loss:2.6657, Validation Accuracy:0.1016
Epoch #8: Loss:2.6656, Accuracy:0.1022 Validation Loss:2.6638, Validation Accuracy:0.1016
Epoch #9: Loss:2.6636, Accuracy:0.1022 Validation Loss:2.6619, Validation Accuracy:0.1016
Epoch #10: Loss:2.6616, Accuracy:0.1022 Validation Loss:2.6597, Validation Accuracy:0.1016
Epoch #11: Loss:2.6589, Accuracy:0.1026 Validation Loss:2.6561, Validation Accuracy:0.1016
Epoch #12: Loss:2.6545, Accuracy:0.1026 Validation Loss:2.6496, Validation Accuracy:0.1016
Epoch #13: Loss:2.6457, Accuracy:0.1071 Validation Loss:2.6354, Validation Accuracy:0.1180
Epoch #14: Loss:2.6261, Accuracy:0.1301 Validation Loss:2.6051, Validation Accuracy:0.1197
Epoch #15: Loss:2.5876, Accuracy:0.1396 Validation Loss:2.5584, Validation Accuracy:0.1885
Epoch #16: Loss:2.5408, Accuracy:0.1892 Validation Loss:2.5144, Validation Accuracy:0.1820
Epoch #17: Loss:2.4996, Accuracy:0.1876 Validation Loss:2.4813, Validation Accuracy:0.1852
Epoch #18: Loss:2.4688, Accuracy:0.1905 Validation Loss:2.4548, Validation Accuracy:0.1902
Epoch #19: Loss:2.4407, Accuracy:0.1921 Validation Loss:2.4258, Validation Accuracy:0.1951
Epoch #20: Loss:2.4154, Accuracy:0.1999 Validation Loss:2.4016, Validation Accuracy:0.2180
Epoch #21: Loss:2.3893, Accuracy:0.2122 Validation Loss:2.3870, Validation Accuracy:0.2066
Epoch #22: Loss:2.3659, Accuracy:0.2172 Validation Loss:2.3518, Validation Accuracy:0.2443
Epoch #23: Loss:2.3424, Accuracy:0.2356 Validation Loss:2.3301, Validation Accuracy:0.2344
Epoch #24: Loss:2.3205, Accuracy:0.2319 Validation Loss:2.3218, Validation Accuracy:0.2246
Epoch #25: Loss:2.3048, Accuracy:0.2229 Validation Loss:2.2983, Validation Accuracy:0.2344
Epoch #26: Loss:2.2831, Accuracy:0.2418 Validation Loss:2.2764, Validation Accuracy:0.2623
Epoch #27: Loss:2.2664, Accuracy:0.2438 Validation Loss:2.2623, Validation Accuracy:0.2410
Epoch #28: Loss:2.2516, Accuracy:0.2401 Validation Loss:2.2464, Validation Accuracy:0.2443
Epoch #29: Loss:2.2358, Accuracy:0.2447 Validation Loss:2.2396, Validation Accuracy:0.2410
Epoch #30: Loss:2.2266, Accuracy:0.2516 Validation Loss:2.2224, Validation Accuracy:0.2689
Epoch #31: Loss:2.2221, Accuracy:0.2443 Validation Loss:2.2114, Validation Accuracy:0.2541
Epoch #32: Loss:2.2043, Accuracy:0.2484 Validation Loss:2.2054, Validation Accuracy:0.2459
Epoch #33: Loss:2.1902, Accuracy:0.2537 Validation Loss:2.1830, Validation Accuracy:0.2492
Epoch #34: Loss:2.1748, Accuracy:0.2545 Validation Loss:2.1683, Validation Accuracy:0.2672
Epoch #35: Loss:2.1627, Accuracy:0.2611 Validation Loss:2.1556, Validation Accuracy:0.2672
Epoch #36: Loss:2.1544, Accuracy:0.2640 Validation Loss:2.1457, Validation Accuracy:0.2689
Epoch #37: Loss:2.1481, Accuracy:0.2603 Validation Loss:2.1424, Validation Accuracy:0.2770
Epoch #38: Loss:2.1420, Accuracy:0.2750 Validation Loss:2.1496, Validation Accuracy:0.2574
Epoch #39: Loss:2.1514, Accuracy:0.2578 Validation Loss:2.1227, Validation Accuracy:0.2672
Epoch #40: Loss:2.1230, Accuracy:0.2791 Validation Loss:2.1482, Validation Accuracy:0.2590
Epoch #41: Loss:2.1261, Accuracy:0.2718 Validation Loss:2.1096, Validation Accuracy:0.2672
Epoch #42: Loss:2.1175, Accuracy:0.2742 Validation Loss:2.1107, Validation Accuracy:0.2738
Epoch #43: Loss:2.1120, Accuracy:0.2763 Validation Loss:2.0930, Validation Accuracy:0.2754
Epoch #44: Loss:2.0948, Accuracy:0.2816 Validation Loss:2.0911, Validation Accuracy:0.2787
Epoch #45: Loss:2.0937, Accuracy:0.2849 Validation Loss:2.1038, Validation Accuracy:0.2705
Epoch #46: Loss:2.0915, Accuracy:0.2816 Validation Loss:2.1066, Validation Accuracy:0.2623
Epoch #47: Loss:2.0867, Accuracy:0.2837 Validation Loss:2.0657, Validation Accuracy:0.2869
Epoch #48: Loss:2.0775, Accuracy:0.2824 Validation Loss:2.0705, Validation Accuracy:0.2902
Epoch #49: Loss:2.0856, Accuracy:0.2845 Validation Loss:2.0877, Validation Accuracy:0.2820
Epoch #50: Loss:2.0860, Accuracy:0.2812 Validation Loss:2.0887, Validation Accuracy:0.2656
Epoch #51: Loss:2.0740, Accuracy:0.2874 Validation Loss:2.0782, Validation Accuracy:0.2738
Epoch #52: Loss:2.0650, Accuracy:0.2894 Validation Loss:2.0733, Validation Accuracy:0.2787
Epoch #53: Loss:2.0704, Accuracy:0.2820 Validation Loss:2.0590, Validation Accuracy:0.2705
Epoch #54: Loss:2.0531, Accuracy:0.2808 Validation Loss:2.0557, Validation Accuracy:0.2705
Epoch #55: Loss:2.0416, Accuracy:0.2927 Validation Loss:2.0223, Validation Accuracy:0.2934
Epoch #56: Loss:2.0278, Accuracy:0.3017 Validation Loss:2.0225, Validation Accuracy:0.2934
Epoch #57: Loss:2.0207, Accuracy:0.3095 Validation Loss:2.0281, Validation Accuracy:0.2902
Epoch #58: Loss:2.0143, Accuracy:0.3067 Validation Loss:2.0050, Validation Accuracy:0.2967
Epoch #59: Loss:2.0059, Accuracy:0.3062 Validation Loss:1.9967, Validation Accuracy:0.3049
Epoch #60: Loss:1.9995, Accuracy:0.3140 Validation Loss:1.9961, Validation Accuracy:0.3098
Epoch #61: Loss:1.9924, Accuracy:0.3181 Validation Loss:1.9928, Validation Accuracy:0.2934
Epoch #62: Loss:1.9877, Accuracy:0.3161 Validation Loss:2.0018, Validation Accuracy:0.3033
Epoch #63: Loss:1.9812, Accuracy:0.3165 Validation Loss:2.0022, Validation Accuracy:0.3033
Epoch #64: Loss:1.9790, Accuracy:0.3108 Validation Loss:1.9909, Validation Accuracy:0.3082
Epoch #65: Loss:1.9756, Accuracy:0.3140 Validation Loss:1.9781, Validation Accuracy:0.3098
Epoch #66: Loss:1.9678, Accuracy:0.3186 Validation Loss:2.0072, Validation Accuracy:0.2984
Epoch #67: Loss:1.9784, Accuracy:0.3280 Validation Loss:1.9770, Validation Accuracy:0.3082
Epoch #68: Loss:1.9628, Accuracy:0.3210 Validation Loss:1.9508, Validation Accuracy:0.3262
Epoch #69: Loss:1.9487, Accuracy:0.3218 Validation Loss:1.9569, Validation Accuracy:0.3098
Epoch #70: Loss:1.9472, Accuracy:0.3264 Validation Loss:1.9414, Validation Accuracy:0.3246
Epoch #71: Loss:1.9380, Accuracy:0.3305 Validation Loss:1.9376, Validation Accuracy:0.3361
Epoch #72: Loss:1.9295, Accuracy:0.3305 Validation Loss:1.9623, Validation Accuracy:0.3066
Epoch #73: Loss:1.9358, Accuracy:0.3362 Validation Loss:1.9511, Validation Accuracy:0.3066
Epoch #74: Loss:1.9274, Accuracy:0.3309 Validation Loss:1.9323, Validation Accuracy:0.3230
Epoch #75: Loss:1.9183, Accuracy:0.3395 Validation Loss:1.9130, Validation Accuracy:0.3393
Epoch #76: Loss:1.9145, Accuracy:0.3411 Validation Loss:1.9234, Validation Accuracy:0.3328
Epoch #77: Loss:1.9161, Accuracy:0.3395 Validation Loss:1.8995, Validation Accuracy:0.3377
Epoch #78: Loss:1.9198, Accuracy:0.3378 Validation Loss:1.9006, Validation Accuracy:0.3344
Epoch #79: Loss:1.9089, Accuracy:0.3403 Validation Loss:1.8965, Validation Accuracy:0.3508
Epoch #80: Loss:1.9053, Accuracy:0.3399 Validation Loss:1.9055, Validation Accuracy:0.3361
Epoch #81: Loss:1.9023, Accuracy:0.3440 Validation Loss:1.8811, Validation Accuracy:0.3410
Epoch #82: Loss:1.8888, Accuracy:0.3407 Validation Loss:1.8723, Validation Accuracy:0.3410
Epoch #83: Loss:1.8791, Accuracy:0.3514 Validation Loss:1.8769, Validation Accuracy:0.3328
Epoch #84: Loss:1.8727, Accuracy:0.3514 Validation Loss:1.8646, Validation Accuracy:0.3328
Epoch #85: Loss:1.8674, Accuracy:0.3510 Validation Loss:1.8608, Validation Accuracy:0.3459
Epoch #86: Loss:1.8643, Accuracy:0.3584 Validation Loss:1.8544, Validation Accuracy:0.3279
Epoch #87: Loss:1.8588, Accuracy:0.3518 Validation Loss:1.8593, Validation Accuracy:0.3443
Epoch #88: Loss:1.8560, Accuracy:0.3543 Validation Loss:1.8472, Validation Accuracy:0.3410
Epoch #89: Loss:1.8541, Accuracy:0.3510 Validation Loss:1.8413, Validation Accuracy:0.3459
Epoch #90: Loss:1.8451, Accuracy:0.3555 Validation Loss:1.8420, Validation Accuracy:0.3459
Epoch #91: Loss:1.8428, Accuracy:0.3559 Validation Loss:1.8360, Validation Accuracy:0.3426
Epoch #92: Loss:1.8428, Accuracy:0.3559 Validation Loss:1.8301, Validation Accuracy:0.3492
Epoch #93: Loss:1.8344, Accuracy:0.3588 Validation Loss:1.8308, Validation Accuracy:0.3459
Epoch #94: Loss:1.8350, Accuracy:0.3612 Validation Loss:1.8454, Validation Accuracy:0.3492
Epoch #95: Loss:1.8305, Accuracy:0.3571 Validation Loss:1.8313, Validation Accuracy:0.3541
Epoch #96: Loss:1.8218, Accuracy:0.3641 Validation Loss:1.8204, Validation Accuracy:0.3508
Epoch #97: Loss:1.8160, Accuracy:0.3596 Validation Loss:1.8266, Validation Accuracy:0.3541
Epoch #98: Loss:1.8173, Accuracy:0.3641 Validation Loss:1.8151, Validation Accuracy:0.3590
Epoch #99: Loss:1.8167, Accuracy:0.3567 Validation Loss:1.8046, Validation Accuracy:0.3607
Epoch #100: Loss:1.8124, Accuracy:0.3621 Validation Loss:1.8082, Validation Accuracy:0.3738
Epoch #101: Loss:1.8138, Accuracy:0.3604 Validation Loss:1.8105, Validation Accuracy:0.3508
Epoch #102: Loss:1.8110, Accuracy:0.3686 Validation Loss:1.7991, Validation Accuracy:0.3689
Epoch #103: Loss:1.8001, Accuracy:0.3719 Validation Loss:1.7933, Validation Accuracy:0.3656
Epoch #104: Loss:1.7916, Accuracy:0.3723 Validation Loss:1.7971, Validation Accuracy:0.3820
Epoch #105: Loss:1.7936, Accuracy:0.3707 Validation Loss:1.7846, Validation Accuracy:0.3672
Epoch #106: Loss:1.7883, Accuracy:0.3732 Validation Loss:1.7877, Validation Accuracy:0.3590
Epoch #107: Loss:1.7806, Accuracy:0.3748 Validation Loss:1.8093, Validation Accuracy:0.3459
Epoch #108: Loss:1.7841, Accuracy:0.3764 Validation Loss:1.7829, Validation Accuracy:0.3607
Epoch #109: Loss:1.7868, Accuracy:0.3740 Validation Loss:1.7739, Validation Accuracy:0.3705
Epoch #110: Loss:1.7871, Accuracy:0.3740 Validation Loss:1.7914, Validation Accuracy:0.3672
Epoch #111: Loss:1.7769, Accuracy:0.3855 Validation Loss:1.7805, Validation Accuracy:0.3689
Epoch #112: Loss:1.7871, Accuracy:0.3888 Validation Loss:1.7888, Validation Accuracy:0.3656
Epoch #113: Loss:1.7812, Accuracy:0.3810 Validation Loss:1.7974, Validation Accuracy:0.3574
Epoch #114: Loss:1.7730, Accuracy:0.3818 Validation Loss:1.7760, Validation Accuracy:0.3672
Epoch #115: Loss:1.7673, Accuracy:0.3859 Validation Loss:1.7900, Validation Accuracy:0.3689
Epoch #116: Loss:1.7787, Accuracy:0.3846 Validation Loss:1.7752, Validation Accuracy:0.3672
Epoch #117: Loss:1.7601, Accuracy:0.3797 Validation Loss:1.7762, Validation Accuracy:0.3738
Epoch #118: Loss:1.7632, Accuracy:0.3937 Validation Loss:1.7848, Validation Accuracy:0.3541
Epoch #119: Loss:1.7535, Accuracy:0.3924 Validation Loss:1.7704, Validation Accuracy:0.3705
Epoch #120: Loss:1.7518, Accuracy:0.3867 Validation Loss:1.7524, Validation Accuracy:0.3820
Epoch #121: Loss:1.7502, Accuracy:0.3916 Validation Loss:1.7593, Validation Accuracy:0.3852
Epoch #122: Loss:1.7438, Accuracy:0.3933 Validation Loss:1.7514, Validation Accuracy:0.3689
Epoch #123: Loss:1.7537, Accuracy:0.3883 Validation Loss:1.7417, Validation Accuracy:0.3869
Epoch #124: Loss:1.7391, Accuracy:0.3920 Validation Loss:1.7412, Validation Accuracy:0.3869
Epoch #125: Loss:1.7350, Accuracy:0.3945 Validation Loss:1.7468, Validation Accuracy:0.3738
Epoch #126: Loss:1.7338, Accuracy:0.3908 Validation Loss:1.7504, Validation Accuracy:0.3656
Epoch #127: Loss:1.7423, Accuracy:0.3879 Validation Loss:1.7509, Validation Accuracy:0.3689
Epoch #128: Loss:1.7449, Accuracy:0.3859 Validation Loss:1.7378, Validation Accuracy:0.3885
Epoch #129: Loss:1.7333, Accuracy:0.3986 Validation Loss:1.7323, Validation Accuracy:0.3820
Epoch #130: Loss:1.7336, Accuracy:0.3937 Validation Loss:1.7261, Validation Accuracy:0.3770
Epoch #131: Loss:1.7284, Accuracy:0.3974 Validation Loss:1.7239, Validation Accuracy:0.3951
Epoch #132: Loss:1.7248, Accuracy:0.4027 Validation Loss:1.7412, Validation Accuracy:0.4016
Epoch #133: Loss:1.7314, Accuracy:0.3994 Validation Loss:1.8139, Validation Accuracy:0.3656
Epoch #134: Loss:1.7411, Accuracy:0.4064 Validation Loss:1.7477, Validation Accuracy:0.3852
Epoch #135: Loss:1.7284, Accuracy:0.3961 Validation Loss:1.7179, Validation Accuracy:0.3967
Epoch #136: Loss:1.7230, Accuracy:0.3916 Validation Loss:1.7174, Validation Accuracy:0.4000
Epoch #137: Loss:1.7179, Accuracy:0.4039 Validation Loss:1.7123, Validation Accuracy:0.3984
Epoch #138: Loss:1.7222, Accuracy:0.4052 Validation Loss:1.7355, Validation Accuracy:0.3918
Epoch #139: Loss:1.7312, Accuracy:0.3953 Validation Loss:1.7412, Validation Accuracy:0.3787
Epoch #140: Loss:1.7222, Accuracy:0.3970 Validation Loss:1.7469, Validation Accuracy:0.3820
Epoch #141: Loss:1.7253, Accuracy:0.4068 Validation Loss:1.7194, Validation Accuracy:0.3902
Epoch #142: Loss:1.7139, Accuracy:0.3978 Validation Loss:1.7099, Validation Accuracy:0.4049
Epoch #143: Loss:1.7117, Accuracy:0.4064 Validation Loss:1.7148, Validation Accuracy:0.4016
Epoch #144: Loss:1.7073, Accuracy:0.4064 Validation Loss:1.7048, Validation Accuracy:0.4016
Epoch #145: Loss:1.6988, Accuracy:0.4060 Validation Loss:1.6987, Validation Accuracy:0.4098
Epoch #146: Loss:1.6940, Accuracy:0.4089 Validation Loss:1.7031, Validation Accuracy:0.4066
Epoch #147: Loss:1.6952, Accuracy:0.4113 Validation Loss:1.7127, Validation Accuracy:0.3852
Epoch #148: Loss:1.7076, Accuracy:0.4019 Validation Loss:1.7101, Validation Accuracy:0.3902
Epoch #149: Loss:1.7117, Accuracy:0.4039 Validation Loss:1.7026, Validation Accuracy:0.4148
Epoch #150: Loss:1.7039, Accuracy:0.4097 Validation Loss:1.6952, Validation Accuracy:0.4066
Epoch #151: Loss:1.7017, Accuracy:0.4085 Validation Loss:1.7022, Validation Accuracy:0.3902
Epoch #152: Loss:1.6936, Accuracy:0.4072 Validation Loss:1.6921, Validation Accuracy:0.4148
Epoch #153: Loss:1.6990, Accuracy:0.4056 Validation Loss:1.6903, Validation Accuracy:0.4098
Epoch #154: Loss:1.6889, Accuracy:0.4134 Validation Loss:1.6906, Validation Accuracy:0.4082
Epoch #155: Loss:1.6792, Accuracy:0.4154 Validation Loss:1.6836, Validation Accuracy:0.4148
Epoch #156: Loss:1.6732, Accuracy:0.4158 Validation Loss:1.6896, Validation Accuracy:0.4115
Epoch #157: Loss:1.6741, Accuracy:0.4191 Validation Loss:1.7000, Validation Accuracy:0.3951
Epoch #158: Loss:1.6783, Accuracy:0.4150 Validation Loss:1.6913, Validation Accuracy:0.4066
Epoch #159: Loss:1.6773, Accuracy:0.4167 Validation Loss:1.6874, Validation Accuracy:0.4164
Epoch #160: Loss:1.6676, Accuracy:0.4224 Validation Loss:1.6789, Validation Accuracy:0.4213
Epoch #161: Loss:1.6672, Accuracy:0.4187 Validation Loss:1.6827, Validation Accuracy:0.4098
Epoch #162: Loss:1.6702, Accuracy:0.4150 Validation Loss:1.6854, Validation Accuracy:0.4082
Epoch #163: Loss:1.6668, Accuracy:0.4265 Validation Loss:1.6912, Validation Accuracy:0.4033
Epoch #164: Loss:1.6713, Accuracy:0.4179 Validation Loss:1.6791, Validation Accuracy:0.4098
Epoch #165: Loss:1.6614, Accuracy:0.4269 Validation Loss:1.6664, Validation Accuracy:0.4197
Epoch #166: Loss:1.6678, Accuracy:0.4224 Validation Loss:1.6677, Validation Accuracy:0.4246
Epoch #167: Loss:1.6582, Accuracy:0.4306 Validation Loss:1.6693, Validation Accuracy:0.4180
Epoch #168: Loss:1.6641, Accuracy:0.4224 Validation Loss:1.6659, Validation Accuracy:0.4246
Epoch #169: Loss:1.6547, Accuracy:0.4298 Validation Loss:1.6677, Validation Accuracy:0.4197
Epoch #170: Loss:1.6501, Accuracy:0.4376 Validation Loss:1.6622, Validation Accuracy:0.4213
Epoch #171: Loss:1.6556, Accuracy:0.4278 Validation Loss:1.6573, Validation Accuracy:0.4295
Epoch #172: Loss:1.6493, Accuracy:0.4347 Validation Loss:1.6660, Validation Accuracy:0.4328
Epoch #173: Loss:1.6485, Accuracy:0.4323 Validation Loss:1.6630, Validation Accuracy:0.4230
Epoch #174: Loss:1.6507, Accuracy:0.4253 Validation Loss:1.6648, Validation Accuracy:0.4459
Epoch #175: Loss:1.6498, Accuracy:0.4310 Validation Loss:1.6492, Validation Accuracy:0.4410
Epoch #176: Loss:1.6453, Accuracy:0.4364 Validation Loss:1.6513, Validation Accuracy:0.4410
Epoch #177: Loss:1.6370, Accuracy:0.4372 Validation Loss:1.6501, Validation Accuracy:0.4344
Epoch #178: Loss:1.6435, Accuracy:0.4360 Validation Loss:1.6486, Validation Accuracy:0.4262
Epoch #179: Loss:1.6384, Accuracy:0.4360 Validation Loss:1.6528, Validation Accuracy:0.4279
Epoch #180: Loss:1.6403, Accuracy:0.4331 Validation Loss:1.6575, Validation Accuracy:0.4443
Epoch #181: Loss:1.6334, Accuracy:0.4384 Validation Loss:1.6444, Validation Accuracy:0.4328
Epoch #182: Loss:1.6307, Accuracy:0.4384 Validation Loss:1.6699, Validation Accuracy:0.4197
Epoch #183: Loss:1.6322, Accuracy:0.4409 Validation Loss:1.6399, Validation Accuracy:0.4344
Epoch #184: Loss:1.6243, Accuracy:0.4417 Validation Loss:1.6373, Validation Accuracy:0.4475
Epoch #185: Loss:1.6209, Accuracy:0.4446 Validation Loss:1.6385, Validation Accuracy:0.4459
Epoch #186: Loss:1.6202, Accuracy:0.4401 Validation Loss:1.6362, Validation Accuracy:0.4410
Epoch #187: Loss:1.6187, Accuracy:0.4409 Validation Loss:1.6303, Validation Accuracy:0.4475
Epoch #188: Loss:1.6139, Accuracy:0.4433 Validation Loss:1.6247, Validation Accuracy:0.4459
Epoch #189: Loss:1.6182, Accuracy:0.4421 Validation Loss:1.6332, Validation Accuracy:0.4557
Epoch #190: Loss:1.6182, Accuracy:0.4372 Validation Loss:1.6212, Validation Accuracy:0.4492
Epoch #191: Loss:1.6086, Accuracy:0.4397 Validation Loss:1.6173, Validation Accuracy:0.4541
Epoch #192: Loss:1.6093, Accuracy:0.4470 Validation Loss:1.6378, Validation Accuracy:0.4525
Epoch #193: Loss:1.6091, Accuracy:0.4429 Validation Loss:1.6129, Validation Accuracy:0.4492
Epoch #194: Loss:1.6010, Accuracy:0.4446 Validation Loss:1.6122, Validation Accuracy:0.4607
Epoch #195: Loss:1.5950, Accuracy:0.4507 Validation Loss:1.6091, Validation Accuracy:0.4557
Epoch #196: Loss:1.5995, Accuracy:0.4479 Validation Loss:1.6078, Validation Accuracy:0.4508
Epoch #197: Loss:1.5969, Accuracy:0.4470 Validation Loss:1.6132, Validation Accuracy:0.4525
Epoch #198: Loss:1.5957, Accuracy:0.4511 Validation Loss:1.6049, Validation Accuracy:0.4525
Epoch #199: Loss:1.5964, Accuracy:0.4532 Validation Loss:1.6120, Validation Accuracy:0.4623
Epoch #200: Loss:1.5949, Accuracy:0.4573 Validation Loss:1.5996, Validation Accuracy:0.4590
Epoch #201: Loss:1.5874, Accuracy:0.4528 Validation Loss:1.6032, Validation Accuracy:0.4492
Epoch #202: Loss:1.5926, Accuracy:0.4524 Validation Loss:1.6027, Validation Accuracy:0.4508
Epoch #203: Loss:1.5882, Accuracy:0.4540 Validation Loss:1.6046, Validation Accuracy:0.4443
Epoch #204: Loss:1.5875, Accuracy:0.4573 Validation Loss:1.5948, Validation Accuracy:0.4574
Epoch #205: Loss:1.5795, Accuracy:0.4622 Validation Loss:1.6204, Validation Accuracy:0.4426
Epoch #206: Loss:1.6053, Accuracy:0.4569 Validation Loss:1.6108, Validation Accuracy:0.4410
Epoch #207: Loss:1.6180, Accuracy:0.4557 Validation Loss:1.6006, Validation Accuracy:0.4459
Epoch #208: Loss:1.5869, Accuracy:0.4598 Validation Loss:1.5913, Validation Accuracy:0.4557
Epoch #209: Loss:1.5906, Accuracy:0.4606 Validation Loss:1.5847, Validation Accuracy:0.4590
Epoch #210: Loss:1.5837, Accuracy:0.4594 Validation Loss:1.6039, Validation Accuracy:0.4393
Epoch #211: Loss:1.5834, Accuracy:0.4589 Validation Loss:1.5815, Validation Accuracy:0.4574
Epoch #212: Loss:1.5821, Accuracy:0.4573 Validation Loss:1.6050, Validation Accuracy:0.4459
Epoch #213: Loss:1.5790, Accuracy:0.4602 Validation Loss:1.5893, Validation Accuracy:0.4574
Epoch #214: Loss:1.5783, Accuracy:0.4692 Validation Loss:1.5996, Validation Accuracy:0.4475
Epoch #215: Loss:1.5788, Accuracy:0.4626 Validation Loss:1.5832, Validation Accuracy:0.4426
Epoch #216: Loss:1.5911, Accuracy:0.4540 Validation Loss:1.5848, Validation Accuracy:0.4525
Epoch #217: Loss:1.5693, Accuracy:0.4713 Validation Loss:1.5759, Validation Accuracy:0.4508
Epoch #218: Loss:1.5632, Accuracy:0.4696 Validation Loss:1.5825, Validation Accuracy:0.4574
Epoch #219: Loss:1.5577, Accuracy:0.4717 Validation Loss:1.5722, Validation Accuracy:0.4607
Epoch #220: Loss:1.5626, Accuracy:0.4762 Validation Loss:1.5785, Validation Accuracy:0.4590
Epoch #221: Loss:1.5581, Accuracy:0.4766 Validation Loss:1.5769, Validation Accuracy:0.4689
Epoch #222: Loss:1.5556, Accuracy:0.4737 Validation Loss:1.5685, Validation Accuracy:0.4672
Epoch #223: Loss:1.5537, Accuracy:0.4758 Validation Loss:1.5763, Validation Accuracy:0.4557
Epoch #224: Loss:1.5571, Accuracy:0.4750 Validation Loss:1.5739, Validation Accuracy:0.4574
Epoch #225: Loss:1.5586, Accuracy:0.4733 Validation Loss:1.6093, Validation Accuracy:0.4377
Epoch #226: Loss:1.5581, Accuracy:0.4737 Validation Loss:1.5684, Validation Accuracy:0.4557
Epoch #227: Loss:1.5535, Accuracy:0.4778 Validation Loss:1.5775, Validation Accuracy:0.4574
Epoch #228: Loss:1.5515, Accuracy:0.4782 Validation Loss:1.5673, Validation Accuracy:0.4557
Epoch #229: Loss:1.5489, Accuracy:0.4799 Validation Loss:1.5591, Validation Accuracy:0.4656
Epoch #230: Loss:1.5514, Accuracy:0.4717 Validation Loss:1.5882, Validation Accuracy:0.4426
Epoch #231: Loss:1.5640, Accuracy:0.4745 Validation Loss:1.5899, Validation Accuracy:0.4525
Epoch #232: Loss:1.5628, Accuracy:0.4692 Validation Loss:1.5610, Validation Accuracy:0.4508
Epoch #233: Loss:1.5390, Accuracy:0.4815 Validation Loss:1.5652, Validation Accuracy:0.4639
Epoch #234: Loss:1.5524, Accuracy:0.4815 Validation Loss:1.5831, Validation Accuracy:0.4377
Epoch #235: Loss:1.5618, Accuracy:0.4692 Validation Loss:1.5695, Validation Accuracy:0.4557
Epoch #236: Loss:1.5535, Accuracy:0.4741 Validation Loss:1.5577, Validation Accuracy:0.4590
Epoch #237: Loss:1.5457, Accuracy:0.4799 Validation Loss:1.5545, Validation Accuracy:0.4689
Epoch #238: Loss:1.5523, Accuracy:0.4745 Validation Loss:1.5479, Validation Accuracy:0.4541
Epoch #239: Loss:1.5400, Accuracy:0.4836 Validation Loss:1.5464, Validation Accuracy:0.4656
Epoch #240: Loss:1.5302, Accuracy:0.4860 Validation Loss:1.5549, Validation Accuracy:0.4574
Epoch #241: Loss:1.5255, Accuracy:0.4918 Validation Loss:1.5452, Validation Accuracy:0.4639
Epoch #242: Loss:1.5243, Accuracy:0.4844 Validation Loss:1.5519, Validation Accuracy:0.4590
Epoch #243: Loss:1.5318, Accuracy:0.4860 Validation Loss:1.5492, Validation Accuracy:0.4689
Epoch #244: Loss:1.5288, Accuracy:0.4881 Validation Loss:1.5464, Validation Accuracy:0.4656
Epoch #245: Loss:1.5325, Accuracy:0.4848 Validation Loss:1.5473, Validation Accuracy:0.4639
Epoch #246: Loss:1.5221, Accuracy:0.4918 Validation Loss:1.5426, Validation Accuracy:0.4672
Epoch #247: Loss:1.5218, Accuracy:0.4877 Validation Loss:1.5403, Validation Accuracy:0.4672
Epoch #248: Loss:1.5153, Accuracy:0.4881 Validation Loss:1.5459, Validation Accuracy:0.4541
Epoch #249: Loss:1.5218, Accuracy:0.4881 Validation Loss:1.5409, Validation Accuracy:0.4705
Epoch #250: Loss:1.5258, Accuracy:0.4869 Validation Loss:1.5496, Validation Accuracy:0.4574
Epoch #251: Loss:1.5232, Accuracy:0.4832 Validation Loss:1.5780, Validation Accuracy:0.4492
Epoch #252: Loss:1.5284, Accuracy:0.4856 Validation Loss:1.5553, Validation Accuracy:0.4607
Epoch #253: Loss:1.5356, Accuracy:0.4869 Validation Loss:1.5500, Validation Accuracy:0.4672
Epoch #254: Loss:1.5182, Accuracy:0.4967 Validation Loss:1.5670, Validation Accuracy:0.4574
Epoch #255: Loss:1.5329, Accuracy:0.4869 Validation Loss:1.5651, Validation Accuracy:0.4459
Epoch #256: Loss:1.5245, Accuracy:0.4844 Validation Loss:1.5399, Validation Accuracy:0.4590
Epoch #257: Loss:1.5394, Accuracy:0.4807 Validation Loss:1.5448, Validation Accuracy:0.4623
Epoch #258: Loss:1.5518, Accuracy:0.4713 Validation Loss:1.5430, Validation Accuracy:0.4738
Epoch #259: Loss:1.5513, Accuracy:0.4782 Validation Loss:1.5591, Validation Accuracy:0.4590
Epoch #260: Loss:1.5299, Accuracy:0.4770 Validation Loss:1.5349, Validation Accuracy:0.4689
Epoch #261: Loss:1.5275, Accuracy:0.4815 Validation Loss:1.5378, Validation Accuracy:0.4623
Epoch #262: Loss:1.5124, Accuracy:0.4934 Validation Loss:1.5330, Validation Accuracy:0.4705
Epoch #263: Loss:1.5074, Accuracy:0.4889 Validation Loss:1.5264, Validation Accuracy:0.4656
Epoch #264: Loss:1.5141, Accuracy:0.4975 Validation Loss:1.5358, Validation Accuracy:0.4689
Epoch #265: Loss:1.5253, Accuracy:0.4877 Validation Loss:1.5343, Validation Accuracy:0.4721
Epoch #266: Loss:1.5263, Accuracy:0.4836 Validation Loss:1.5341, Validation Accuracy:0.4705
Epoch #267: Loss:1.5232, Accuracy:0.4885 Validation Loss:1.5433, Validation Accuracy:0.4672
Epoch #268: Loss:1.5146, Accuracy:0.4910 Validation Loss:1.5245, Validation Accuracy:0.4770
Epoch #269: Loss:1.4957, Accuracy:0.5004 Validation Loss:1.5263, Validation Accuracy:0.4787
Epoch #270: Loss:1.4983, Accuracy:0.4963 Validation Loss:1.5360, Validation Accuracy:0.4754
Epoch #271: Loss:1.4967, Accuracy:0.4914 Validation Loss:1.5361, Validation Accuracy:0.4738
Epoch #272: Loss:1.5047, Accuracy:0.4988 Validation Loss:1.5289, Validation Accuracy:0.4770
Epoch #273: Loss:1.5021, Accuracy:0.4959 Validation Loss:1.5428, Validation Accuracy:0.4672
Epoch #274: Loss:1.5068, Accuracy:0.4901 Validation Loss:1.5247, Validation Accuracy:0.4721
Epoch #275: Loss:1.4943, Accuracy:0.4996 Validation Loss:1.5727, Validation Accuracy:0.4557
Epoch #276: Loss:1.5116, Accuracy:0.4934 Validation Loss:1.5602, Validation Accuracy:0.4590
Epoch #277: Loss:1.5100, Accuracy:0.4889 Validation Loss:1.5291, Validation Accuracy:0.4721
Epoch #278: Loss:1.4969, Accuracy:0.4984 Validation Loss:1.5242, Validation Accuracy:0.4770
Epoch #279: Loss:1.4930, Accuracy:0.5012 Validation Loss:1.5275, Validation Accuracy:0.4820
Epoch #280: Loss:1.4957, Accuracy:0.4930 Validation Loss:1.5558, Validation Accuracy:0.4623
Epoch #281: Loss:1.5097, Accuracy:0.4947 Validation Loss:1.5637, Validation Accuracy:0.4574
Epoch #282: Loss:1.5215, Accuracy:0.4807 Validation Loss:1.5199, Validation Accuracy:0.4770
Epoch #283: Loss:1.5076, Accuracy:0.4906 Validation Loss:1.5189, Validation Accuracy:0.4852
Epoch #284: Loss:1.4877, Accuracy:0.5000 Validation Loss:1.5494, Validation Accuracy:0.4738
Epoch #285: Loss:1.4920, Accuracy:0.4967 Validation Loss:1.5339, Validation Accuracy:0.4787
Epoch #286: Loss:1.4909, Accuracy:0.4975 Validation Loss:1.5364, Validation Accuracy:0.4803
Epoch #287: Loss:1.4924, Accuracy:0.4963 Validation Loss:1.5154, Validation Accuracy:0.4803
Epoch #288: Loss:1.4817, Accuracy:0.5016 Validation Loss:1.5160, Validation Accuracy:0.4770
Epoch #289: Loss:1.4798, Accuracy:0.4979 Validation Loss:1.5113, Validation Accuracy:0.4918
Epoch #290: Loss:1.4791, Accuracy:0.4992 Validation Loss:1.5224, Validation Accuracy:0.4820
Epoch #291: Loss:1.4762, Accuracy:0.5049 Validation Loss:1.5121, Validation Accuracy:0.4869
Epoch #292: Loss:1.4746, Accuracy:0.5021 Validation Loss:1.5132, Validation Accuracy:0.4852
Epoch #293: Loss:1.4764, Accuracy:0.5037 Validation Loss:1.5207, Validation Accuracy:0.4869
Epoch #294: Loss:1.4789, Accuracy:0.5029 Validation Loss:1.5474, Validation Accuracy:0.4705
Epoch #295: Loss:1.4827, Accuracy:0.4955 Validation Loss:1.5095, Validation Accuracy:0.4885
Epoch #296: Loss:1.4768, Accuracy:0.5029 Validation Loss:1.5086, Validation Accuracy:0.4869
Epoch #297: Loss:1.4789, Accuracy:0.5004 Validation Loss:1.5043, Validation Accuracy:0.4902
Epoch #298: Loss:1.4700, Accuracy:0.5078 Validation Loss:1.5102, Validation Accuracy:0.4869
Epoch #299: Loss:1.4693, Accuracy:0.5103 Validation Loss:1.5231, Validation Accuracy:0.4754
Epoch #300: Loss:1.4804, Accuracy:0.5021 Validation Loss:1.5142, Validation Accuracy:0.4836

Test:
Test Loss:1.51419652, Accuracy:0.4836
Labels: ['ib', 'sk', 'eb', 'eo', 'aa', 'my', 'ek', 'ce', 'mb', 'eg', 'sg', 'yd', 'ck', 'ds', 'by']
Confusion Matrix:
[[30  0  0  0  0  0  0  2  2  3 12  4  0  0  1]
 [ 0  1  3  0  2  0  8  0 12  5  0  0  2  0  0]
 [ 0  0 36  0  0  0 14  0  1  0  0  0  0  0  0]
 [ 2  0  0 21  0  0  0  1  0  5  0  0  0  0  5]
 [ 0  0  0  0 19  0  7  0  2  1  1  2  0  0  2]
 [ 0  1  5  0  0  0  3  0  9  2  0  0  0  0  0]
 [ 0  0  4  0  7  0 33  0  2  0  0  2  0  0  0]
 [ 4  0  0  1  0  0  0  7  2  5  0  2  2  1  3]
 [ 6  2  1  0  2  0  2  0 28  3  1  2  4  1  0]
 [ 5  0  1  2 14  0  0  0  2 22  1  2  1  0  0]
 [11  0  0  0  1  0  0  0  1  1 17 19  0  0  1]
 [ 3  0  0  0  1  0  3  0  1  0  4 50  0  0  0]
 [ 0  0  0  0  1  0  2  1  4  5  0  0  7  3  0]
 [ 0  1  6  0  0  0  7  0  3  2  0  1  6  5  0]
 [ 1  0  0  4  1  0  0  1  0  1  5  8  0  0 19]]
Classification Report:
              precision    recall  f1-score   support

          ib       0.48      0.56      0.52        54
          sk       0.20      0.03      0.05        33
          eb       0.64      0.71      0.67        51
          eo       0.75      0.62      0.68        34
          aa       0.40      0.56      0.46        34
          my       0.00      0.00      0.00        20
          ek       0.42      0.69      0.52        48
          ce       0.58      0.26      0.36        27
          mb       0.41      0.54      0.46        52
          eg       0.40      0.44      0.42        50
          sg       0.41      0.33      0.37        51
          yd       0.54      0.81      0.65        62
          ck       0.32      0.30      0.31        23
          ds       0.50      0.16      0.24        31
          by       0.61      0.47      0.54        40

    accuracy                           0.48       610
   macro avg       0.44      0.43      0.42       610
weighted avg       0.46      0.48      0.46       610

============ Config: 1/1 === End Time: 2019.07.22 14:44:47 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 24 minutes, 31 seconds =====================


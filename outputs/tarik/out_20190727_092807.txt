======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: C:\Users\ATIL\PycharmProjects\Thesis02wDL\confFiles\conf36.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.07.27 09:28:07 =======================================
Parameters: {'inputFolder': 'C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/', 'featureMode': 'Mags', 'channelMode': 'Front', 'classificationMode': 'Posture3', 'trainingEpoch': 300, 'stepSize': 1, 'sampRate': 8, 'batchSize': 512, 'learningRate': 0.001, 'lossFunction': 'CatCrosEnt', 'optimizer': 'Adam', 'clsModel': 'LSTM'}
Initial Scan.
Shuffling...
Reading:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Generating Labels...
3044 Files with 3 Label(s): ['01', '02', '03'].
Padding:....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................

Total of 3044 inputs loaded @ C:/Users/ATIL/Desktop/Dataset/inputsFrom_max_sample_set/
Total of 3 classes
2435 steps for training, 609 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (2435, 7991, 7)
Test Batch: (609, 7991, 7)
Optimizer: <keras.optimizers.Adam object at 0x00000213856B4E10>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000021382E36EA0>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 166, 8)            2696      
_________________________________________________________________
activation_1 (Activation)    (None, 166, 8)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 6, 16)             3088      
_________________________________________________________________
activation_2 (Activation)    (None, 6, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 24)             3936      
_________________________________________________________________
lstm_2 (LSTM)                (None, 12)                1776      
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 39        
=================================================================
Total params: 11,535
Trainable params: 11,535
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:1.0892, Accuracy:0.3729, Validation Loss:1.0795, Validation Accuracy:0.3727
Epoch #2: Loss:1.0762, Accuracy:0.3860, Validation Loss:1.0744, Validation Accuracy:0.3941
Epoch #3: Loss:1.0744, Accuracy:0.3943, Validation Loss:1.0755, Validation Accuracy:0.3941
Epoch #4: Loss:1.0758, Accuracy:0.3943, Validation Loss:1.0759, Validation Accuracy:0.3941
Epoch #5: Loss:1.0752, Accuracy:0.3943, Validation Loss:1.0745, Validation Accuracy:0.3941
Epoch #6: Loss:1.0742, Accuracy:0.3943, Validation Loss:1.0743, Validation Accuracy:0.3941
Epoch #7: Loss:1.0742, Accuracy:0.3943, Validation Loss:1.0745, Validation Accuracy:0.3941
Epoch #8: Loss:1.0744, Accuracy:0.3943, Validation Loss:1.0744, Validation Accuracy:0.3941
Epoch #9: Loss:1.0742, Accuracy:0.3943, Validation Loss:1.0742, Validation Accuracy:0.3941
Epoch #10: Loss:1.0740, Accuracy:0.3943, Validation Loss:1.0740, Validation Accuracy:0.3941
Epoch #11: Loss:1.0739, Accuracy:0.3943, Validation Loss:1.0740, Validation Accuracy:0.3941
Epoch #12: Loss:1.0739, Accuracy:0.3943, Validation Loss:1.0738, Validation Accuracy:0.3941
Epoch #13: Loss:1.0737, Accuracy:0.3943, Validation Loss:1.0735, Validation Accuracy:0.3941
Epoch #14: Loss:1.0734, Accuracy:0.3943, Validation Loss:1.0732, Validation Accuracy:0.3941
Epoch #15: Loss:1.0731, Accuracy:0.3943, Validation Loss:1.0727, Validation Accuracy:0.3941
Epoch #16: Loss:1.0727, Accuracy:0.3959, Validation Loss:1.0721, Validation Accuracy:0.4023
Epoch #17: Loss:1.0720, Accuracy:0.4021, Validation Loss:1.0711, Validation Accuracy:0.4089
Epoch #18: Loss:1.0709, Accuracy:0.4127, Validation Loss:1.0695, Validation Accuracy:0.4187
Epoch #19: Loss:1.0695, Accuracy:0.4324, Validation Loss:1.0671, Validation Accuracy:0.4483
Epoch #20: Loss:1.0668, Accuracy:0.4419, Validation Loss:1.0633, Validation Accuracy:0.4417
Epoch #21: Loss:1.0629, Accuracy:0.4374, Validation Loss:1.0572, Validation Accuracy:0.4647
Epoch #22: Loss:1.0572, Accuracy:0.4657, Validation Loss:1.0481, Validation Accuracy:0.4614
Epoch #23: Loss:1.0482, Accuracy:0.4727, Validation Loss:1.0354, Validation Accuracy:0.4729
Epoch #24: Loss:1.0374, Accuracy:0.4739, Validation Loss:1.0222, Validation Accuracy:0.4762
Epoch #25: Loss:1.0270, Accuracy:0.4739, Validation Loss:1.0137, Validation Accuracy:0.4762
Epoch #26: Loss:1.0238, Accuracy:0.4735, Validation Loss:1.0123, Validation Accuracy:0.4762
Epoch #27: Loss:1.0239, Accuracy:0.4702, Validation Loss:1.0122, Validation Accuracy:0.4745
Epoch #28: Loss:1.0222, Accuracy:0.4760, Validation Loss:1.0117, Validation Accuracy:0.4713
Epoch #29: Loss:1.0199, Accuracy:0.4727, Validation Loss:1.0131, Validation Accuracy:0.4614
Epoch #30: Loss:1.0186, Accuracy:0.4756, Validation Loss:1.0107, Validation Accuracy:0.4778
Epoch #31: Loss:1.0203, Accuracy:0.4768, Validation Loss:1.0102, Validation Accuracy:0.4680
Epoch #32: Loss:1.0194, Accuracy:0.4735, Validation Loss:1.0099, Validation Accuracy:0.4647
Epoch #33: Loss:1.0193, Accuracy:0.4772, Validation Loss:1.0085, Validation Accuracy:0.4795
Epoch #34: Loss:1.0176, Accuracy:0.4739, Validation Loss:1.0089, Validation Accuracy:0.4647
Epoch #35: Loss:1.0153, Accuracy:0.4813, Validation Loss:1.0071, Validation Accuracy:0.4680
Epoch #36: Loss:1.0138, Accuracy:0.4838, Validation Loss:1.0071, Validation Accuracy:0.4647
Epoch #37: Loss:1.0128, Accuracy:0.4854, Validation Loss:1.0059, Validation Accuracy:0.4795
Epoch #38: Loss:1.0120, Accuracy:0.4936, Validation Loss:1.0045, Validation Accuracy:0.4877
Epoch #39: Loss:1.0108, Accuracy:0.4932, Validation Loss:1.0033, Validation Accuracy:0.4910
Epoch #40: Loss:1.0102, Accuracy:0.4957, Validation Loss:1.0041, Validation Accuracy:0.4910
Epoch #41: Loss:1.0098, Accuracy:0.4924, Validation Loss:1.0015, Validation Accuracy:0.4860
Epoch #42: Loss:1.0119, Accuracy:0.4879, Validation Loss:1.0056, Validation Accuracy:0.4844
Epoch #43: Loss:1.0099, Accuracy:0.4899, Validation Loss:1.0005, Validation Accuracy:0.5041
Epoch #44: Loss:1.0064, Accuracy:0.5031, Validation Loss:1.0025, Validation Accuracy:0.4959
Epoch #45: Loss:1.0054, Accuracy:0.5023, Validation Loss:0.9988, Validation Accuracy:0.4877
Epoch #46: Loss:1.0034, Accuracy:0.5051, Validation Loss:0.9986, Validation Accuracy:0.4943
Epoch #47: Loss:1.0024, Accuracy:0.5072, Validation Loss:0.9963, Validation Accuracy:0.4877
Epoch #48: Loss:1.0014, Accuracy:0.5043, Validation Loss:0.9970, Validation Accuracy:0.4959
Epoch #49: Loss:1.0048, Accuracy:0.4994, Validation Loss:0.9963, Validation Accuracy:0.4975
Epoch #50: Loss:1.0033, Accuracy:0.4940, Validation Loss:0.9962, Validation Accuracy:0.4959
Epoch #51: Loss:0.9988, Accuracy:0.5014, Validation Loss:0.9930, Validation Accuracy:0.4910
Epoch #52: Loss:0.9984, Accuracy:0.5051, Validation Loss:0.9945, Validation Accuracy:0.4926
Epoch #53: Loss:0.9967, Accuracy:0.5060, Validation Loss:0.9925, Validation Accuracy:0.5041
Epoch #54: Loss:0.9972, Accuracy:0.5039, Validation Loss:0.9914, Validation Accuracy:0.5025
Epoch #55: Loss:0.9940, Accuracy:0.5088, Validation Loss:0.9890, Validation Accuracy:0.5025
Epoch #56: Loss:0.9928, Accuracy:0.5084, Validation Loss:0.9884, Validation Accuracy:0.5041
Epoch #57: Loss:0.9909, Accuracy:0.5129, Validation Loss:0.9868, Validation Accuracy:0.5057
Epoch #58: Loss:0.9900, Accuracy:0.5097, Validation Loss:0.9855, Validation Accuracy:0.5074
Epoch #59: Loss:0.9883, Accuracy:0.5105, Validation Loss:0.9839, Validation Accuracy:0.5123
Epoch #60: Loss:0.9875, Accuracy:0.5129, Validation Loss:0.9848, Validation Accuracy:0.5140
Epoch #61: Loss:0.9876, Accuracy:0.5113, Validation Loss:0.9860, Validation Accuracy:0.5057
Epoch #62: Loss:0.9858, Accuracy:0.5088, Validation Loss:0.9796, Validation Accuracy:0.5057
Epoch #63: Loss:0.9816, Accuracy:0.5179, Validation Loss:0.9791, Validation Accuracy:0.5172
Epoch #64: Loss:0.9829, Accuracy:0.5088, Validation Loss:0.9803, Validation Accuracy:0.5074
Epoch #65: Loss:0.9814, Accuracy:0.5154, Validation Loss:0.9834, Validation Accuracy:0.5025
Epoch #66: Loss:0.9852, Accuracy:0.5072, Validation Loss:0.9939, Validation Accuracy:0.5222
Epoch #67: Loss:0.9865, Accuracy:0.5092, Validation Loss:0.9787, Validation Accuracy:0.5057
Epoch #68: Loss:0.9810, Accuracy:0.5138, Validation Loss:0.9725, Validation Accuracy:0.5041
Epoch #69: Loss:0.9733, Accuracy:0.5187, Validation Loss:0.9668, Validation Accuracy:0.5238
Epoch #70: Loss:0.9690, Accuracy:0.5207, Validation Loss:0.9663, Validation Accuracy:0.5156
Epoch #71: Loss:0.9678, Accuracy:0.5236, Validation Loss:0.9628, Validation Accuracy:0.5255
Epoch #72: Loss:0.9639, Accuracy:0.5269, Validation Loss:0.9639, Validation Accuracy:0.5287
Epoch #73: Loss:0.9647, Accuracy:0.5203, Validation Loss:0.9575, Validation Accuracy:0.5271
Epoch #74: Loss:0.9605, Accuracy:0.5265, Validation Loss:0.9538, Validation Accuracy:0.5287
Epoch #75: Loss:0.9564, Accuracy:0.5310, Validation Loss:0.9589, Validation Accuracy:0.5320
Epoch #76: Loss:0.9505, Accuracy:0.5318, Validation Loss:0.9490, Validation Accuracy:0.5287
Epoch #77: Loss:0.9453, Accuracy:0.5372, Validation Loss:0.9415, Validation Accuracy:0.5435
Epoch #78: Loss:0.9382, Accuracy:0.5376, Validation Loss:0.9432, Validation Accuracy:0.5369
Epoch #79: Loss:0.9370, Accuracy:0.5372, Validation Loss:0.9307, Validation Accuracy:0.5337
Epoch #80: Loss:0.9273, Accuracy:0.5392, Validation Loss:0.9243, Validation Accuracy:0.5353
Epoch #81: Loss:0.9192, Accuracy:0.5425, Validation Loss:0.9601, Validation Accuracy:0.5304
Epoch #82: Loss:0.9303, Accuracy:0.5384, Validation Loss:0.9458, Validation Accuracy:0.5205
Epoch #83: Loss:0.9493, Accuracy:0.5244, Validation Loss:0.9670, Validation Accuracy:0.5090
Epoch #84: Loss:0.9556, Accuracy:0.5060, Validation Loss:0.9106, Validation Accuracy:0.5386
Epoch #85: Loss:0.9433, Accuracy:0.5154, Validation Loss:0.9459, Validation Accuracy:0.5189
Epoch #86: Loss:0.9322, Accuracy:0.5310, Validation Loss:0.9178, Validation Accuracy:0.5353
Epoch #87: Loss:0.9143, Accuracy:0.5483, Validation Loss:0.9163, Validation Accuracy:0.5550
Epoch #88: Loss:0.9154, Accuracy:0.5421, Validation Loss:0.9116, Validation Accuracy:0.5402
Epoch #89: Loss:0.9167, Accuracy:0.5446, Validation Loss:0.9248, Validation Accuracy:0.5304
Epoch #90: Loss:0.9124, Accuracy:0.5462, Validation Loss:0.9061, Validation Accuracy:0.5304
Epoch #91: Loss:0.9070, Accuracy:0.5483, Validation Loss:0.9092, Validation Accuracy:0.5435
Epoch #92: Loss:0.9089, Accuracy:0.5487, Validation Loss:0.9397, Validation Accuracy:0.5353
Epoch #93: Loss:0.9203, Accuracy:0.5335, Validation Loss:0.9221, Validation Accuracy:0.5238
Epoch #94: Loss:0.9153, Accuracy:0.5433, Validation Loss:0.9119, Validation Accuracy:0.5271
Epoch #95: Loss:0.9033, Accuracy:0.5454, Validation Loss:0.9026, Validation Accuracy:0.5369
Epoch #96: Loss:0.8999, Accuracy:0.5552, Validation Loss:0.9176, Validation Accuracy:0.5402
Epoch #97: Loss:0.9082, Accuracy:0.5433, Validation Loss:0.8963, Validation Accuracy:0.5550
Epoch #98: Loss:0.9158, Accuracy:0.5355, Validation Loss:0.9591, Validation Accuracy:0.5090
Epoch #99: Loss:0.9185, Accuracy:0.5437, Validation Loss:0.9089, Validation Accuracy:0.5271
Epoch #100: Loss:0.9028, Accuracy:0.5483, Validation Loss:0.9028, Validation Accuracy:0.5304
Epoch #101: Loss:0.8949, Accuracy:0.5511, Validation Loss:0.9065, Validation Accuracy:0.5337
Epoch #102: Loss:0.8914, Accuracy:0.5520, Validation Loss:0.8967, Validation Accuracy:0.5468
Epoch #103: Loss:0.8865, Accuracy:0.5569, Validation Loss:0.8985, Validation Accuracy:0.5501
Epoch #104: Loss:0.8880, Accuracy:0.5606, Validation Loss:0.8984, Validation Accuracy:0.5419
Epoch #105: Loss:0.8876, Accuracy:0.5569, Validation Loss:0.8943, Validation Accuracy:0.5501
Epoch #106: Loss:0.8827, Accuracy:0.5602, Validation Loss:0.8975, Validation Accuracy:0.5501
Epoch #107: Loss:0.8894, Accuracy:0.5552, Validation Loss:0.9120, Validation Accuracy:0.5517
Epoch #108: Loss:0.8951, Accuracy:0.5536, Validation Loss:0.9063, Validation Accuracy:0.5517
Epoch #109: Loss:0.8901, Accuracy:0.5552, Validation Loss:0.8941, Validation Accuracy:0.5320
Epoch #110: Loss:0.8817, Accuracy:0.5618, Validation Loss:0.9097, Validation Accuracy:0.5369
Epoch #111: Loss:0.8830, Accuracy:0.5548, Validation Loss:0.8900, Validation Accuracy:0.5501
Epoch #112: Loss:0.8779, Accuracy:0.5663, Validation Loss:0.8911, Validation Accuracy:0.5517
Epoch #113: Loss:0.8804, Accuracy:0.5643, Validation Loss:0.8920, Validation Accuracy:0.5550
Epoch #114: Loss:0.8798, Accuracy:0.5618, Validation Loss:0.8920, Validation Accuracy:0.5501
Epoch #115: Loss:0.8756, Accuracy:0.5696, Validation Loss:0.8977, Validation Accuracy:0.5402
Epoch #116: Loss:0.8780, Accuracy:0.5626, Validation Loss:0.8895, Validation Accuracy:0.5484
Epoch #117: Loss:0.8762, Accuracy:0.5634, Validation Loss:0.8930, Validation Accuracy:0.5452
Epoch #118: Loss:0.8759, Accuracy:0.5696, Validation Loss:0.8875, Validation Accuracy:0.5534
Epoch #119: Loss:0.8750, Accuracy:0.5688, Validation Loss:0.8873, Validation Accuracy:0.5501
Epoch #120: Loss:0.8704, Accuracy:0.5733, Validation Loss:0.8868, Validation Accuracy:0.5501
Epoch #121: Loss:0.8697, Accuracy:0.5680, Validation Loss:0.8868, Validation Accuracy:0.5484
Epoch #122: Loss:0.8726, Accuracy:0.5717, Validation Loss:0.8914, Validation Accuracy:0.5402
Epoch #123: Loss:0.8692, Accuracy:0.5626, Validation Loss:0.8855, Validation Accuracy:0.5501
Epoch #124: Loss:0.8692, Accuracy:0.5758, Validation Loss:0.8898, Validation Accuracy:0.5402
Epoch #125: Loss:0.8717, Accuracy:0.5659, Validation Loss:0.8899, Validation Accuracy:0.5435
Epoch #126: Loss:0.8708, Accuracy:0.5680, Validation Loss:0.8846, Validation Accuracy:0.5517
Epoch #127: Loss:0.8657, Accuracy:0.5708, Validation Loss:0.8840, Validation Accuracy:0.5484
Epoch #128: Loss:0.8664, Accuracy:0.5717, Validation Loss:0.8845, Validation Accuracy:0.5452
Epoch #129: Loss:0.8687, Accuracy:0.5692, Validation Loss:0.8896, Validation Accuracy:0.5402
Epoch #130: Loss:0.8700, Accuracy:0.5737, Validation Loss:0.8930, Validation Accuracy:0.5369
Epoch #131: Loss:0.8702, Accuracy:0.5696, Validation Loss:0.8902, Validation Accuracy:0.5435
Epoch #132: Loss:0.8684, Accuracy:0.5659, Validation Loss:0.8873, Validation Accuracy:0.5452
Epoch #133: Loss:0.8663, Accuracy:0.5696, Validation Loss:0.8822, Validation Accuracy:0.5435
Epoch #134: Loss:0.8620, Accuracy:0.5749, Validation Loss:0.8859, Validation Accuracy:0.5501
Epoch #135: Loss:0.8658, Accuracy:0.5737, Validation Loss:0.8819, Validation Accuracy:0.5452
Epoch #136: Loss:0.8660, Accuracy:0.5729, Validation Loss:0.8889, Validation Accuracy:0.5517
Epoch #137: Loss:0.8741, Accuracy:0.5602, Validation Loss:0.9215, Validation Accuracy:0.5304
Epoch #138: Loss:0.8932, Accuracy:0.5507, Validation Loss:0.9065, Validation Accuracy:0.5468
Epoch #139: Loss:0.8795, Accuracy:0.5614, Validation Loss:0.8795, Validation Accuracy:0.5517
Epoch #140: Loss:0.8665, Accuracy:0.5708, Validation Loss:0.9028, Validation Accuracy:0.5353
Epoch #141: Loss:0.8747, Accuracy:0.5647, Validation Loss:0.8818, Validation Accuracy:0.5484
Epoch #142: Loss:0.8631, Accuracy:0.5688, Validation Loss:0.8905, Validation Accuracy:0.5402
Epoch #143: Loss:0.8669, Accuracy:0.5671, Validation Loss:0.8784, Validation Accuracy:0.5419
Epoch #144: Loss:0.8667, Accuracy:0.5696, Validation Loss:0.9030, Validation Accuracy:0.5419
Epoch #145: Loss:0.8709, Accuracy:0.5626, Validation Loss:0.8882, Validation Accuracy:0.5435
Epoch #146: Loss:0.8713, Accuracy:0.5639, Validation Loss:0.8904, Validation Accuracy:0.5287
Epoch #147: Loss:0.8637, Accuracy:0.5696, Validation Loss:0.8853, Validation Accuracy:0.5402
Epoch #148: Loss:0.8664, Accuracy:0.5692, Validation Loss:0.8789, Validation Accuracy:0.5452
Epoch #149: Loss:0.8581, Accuracy:0.5725, Validation Loss:0.8894, Validation Accuracy:0.5468
Epoch #150: Loss:0.8625, Accuracy:0.5708, Validation Loss:0.8771, Validation Accuracy:0.5468
Epoch #151: Loss:0.8556, Accuracy:0.5704, Validation Loss:0.8872, Validation Accuracy:0.5402
Epoch #152: Loss:0.8599, Accuracy:0.5708, Validation Loss:0.8782, Validation Accuracy:0.5468
Epoch #153: Loss:0.8581, Accuracy:0.5717, Validation Loss:0.8885, Validation Accuracy:0.5402
Epoch #154: Loss:0.8575, Accuracy:0.5717, Validation Loss:0.8792, Validation Accuracy:0.5419
Epoch #155: Loss:0.8606, Accuracy:0.5733, Validation Loss:0.8796, Validation Accuracy:0.5419
Epoch #156: Loss:0.8640, Accuracy:0.5626, Validation Loss:0.8885, Validation Accuracy:0.5287
Epoch #157: Loss:0.8587, Accuracy:0.5630, Validation Loss:0.8775, Validation Accuracy:0.5419
Epoch #158: Loss:0.8556, Accuracy:0.5717, Validation Loss:0.8769, Validation Accuracy:0.5468
Epoch #159: Loss:0.8548, Accuracy:0.5737, Validation Loss:0.8832, Validation Accuracy:0.5402
Epoch #160: Loss:0.8558, Accuracy:0.5717, Validation Loss:0.8821, Validation Accuracy:0.5337
Epoch #161: Loss:0.8569, Accuracy:0.5614, Validation Loss:0.8781, Validation Accuracy:0.5452
Epoch #162: Loss:0.8562, Accuracy:0.5676, Validation Loss:0.8806, Validation Accuracy:0.5386
Epoch #163: Loss:0.8539, Accuracy:0.5737, Validation Loss:0.8786, Validation Accuracy:0.5452
Epoch #164: Loss:0.8603, Accuracy:0.5688, Validation Loss:0.8868, Validation Accuracy:0.5337
Epoch #165: Loss:0.8595, Accuracy:0.5634, Validation Loss:0.8773, Validation Accuracy:0.5419
Epoch #166: Loss:0.8511, Accuracy:0.5692, Validation Loss:0.8814, Validation Accuracy:0.5320
Epoch #167: Loss:0.8542, Accuracy:0.5676, Validation Loss:0.8811, Validation Accuracy:0.5419
Epoch #168: Loss:0.8533, Accuracy:0.5758, Validation Loss:0.8824, Validation Accuracy:0.5419
Epoch #169: Loss:0.8573, Accuracy:0.5663, Validation Loss:0.8858, Validation Accuracy:0.5337
Epoch #170: Loss:0.8588, Accuracy:0.5680, Validation Loss:0.8786, Validation Accuracy:0.5484
Epoch #171: Loss:0.8630, Accuracy:0.5676, Validation Loss:0.8819, Validation Accuracy:0.5402
Epoch #172: Loss:0.8610, Accuracy:0.5655, Validation Loss:0.8859, Validation Accuracy:0.5320
Epoch #173: Loss:0.8599, Accuracy:0.5626, Validation Loss:0.8841, Validation Accuracy:0.5353
Epoch #174: Loss:0.8694, Accuracy:0.5647, Validation Loss:0.8729, Validation Accuracy:0.5402
Epoch #175: Loss:0.8540, Accuracy:0.5766, Validation Loss:0.9081, Validation Accuracy:0.5435
Epoch #176: Loss:0.8669, Accuracy:0.5639, Validation Loss:0.8724, Validation Accuracy:0.5435
Epoch #177: Loss:0.8573, Accuracy:0.5684, Validation Loss:0.8899, Validation Accuracy:0.5304
Epoch #178: Loss:0.8597, Accuracy:0.5639, Validation Loss:0.8715, Validation Accuracy:0.5386
Epoch #179: Loss:0.8588, Accuracy:0.5704, Validation Loss:0.8759, Validation Accuracy:0.5320
Epoch #180: Loss:0.8563, Accuracy:0.5713, Validation Loss:0.8958, Validation Accuracy:0.5435
Epoch #181: Loss:0.8753, Accuracy:0.5614, Validation Loss:0.8759, Validation Accuracy:0.5402
Epoch #182: Loss:0.8635, Accuracy:0.5663, Validation Loss:0.8993, Validation Accuracy:0.5287
Epoch #183: Loss:0.8662, Accuracy:0.5598, Validation Loss:0.8704, Validation Accuracy:0.5402
Epoch #184: Loss:0.8507, Accuracy:0.5721, Validation Loss:0.8754, Validation Accuracy:0.5287
Epoch #185: Loss:0.8486, Accuracy:0.5680, Validation Loss:0.8707, Validation Accuracy:0.5452
Epoch #186: Loss:0.8458, Accuracy:0.5733, Validation Loss:0.8716, Validation Accuracy:0.5452
Epoch #187: Loss:0.8461, Accuracy:0.5708, Validation Loss:0.8720, Validation Accuracy:0.5369
Epoch #188: Loss:0.8459, Accuracy:0.5684, Validation Loss:0.8726, Validation Accuracy:0.5353
Epoch #189: Loss:0.8465, Accuracy:0.5737, Validation Loss:0.8821, Validation Accuracy:0.5369
Epoch #190: Loss:0.8550, Accuracy:0.5745, Validation Loss:0.8759, Validation Accuracy:0.5419
Epoch #191: Loss:0.8665, Accuracy:0.5606, Validation Loss:0.9284, Validation Accuracy:0.5435
Epoch #192: Loss:0.8855, Accuracy:0.5446, Validation Loss:0.8865, Validation Accuracy:0.5320
Epoch #193: Loss:0.8610, Accuracy:0.5630, Validation Loss:0.8792, Validation Accuracy:0.5304
Epoch #194: Loss:0.8531, Accuracy:0.5680, Validation Loss:0.8748, Validation Accuracy:0.5386
Epoch #195: Loss:0.8522, Accuracy:0.5729, Validation Loss:0.8798, Validation Accuracy:0.5369
Epoch #196: Loss:0.8501, Accuracy:0.5659, Validation Loss:0.8866, Validation Accuracy:0.5337
Epoch #197: Loss:0.8607, Accuracy:0.5618, Validation Loss:0.8868, Validation Accuracy:0.5320
Epoch #198: Loss:0.8555, Accuracy:0.5717, Validation Loss:0.8917, Validation Accuracy:0.5435
Epoch #199: Loss:0.8537, Accuracy:0.5667, Validation Loss:0.8693, Validation Accuracy:0.5337
Epoch #200: Loss:0.8452, Accuracy:0.5762, Validation Loss:0.8749, Validation Accuracy:0.5337
Epoch #201: Loss:0.8440, Accuracy:0.5745, Validation Loss:0.8712, Validation Accuracy:0.5419
Epoch #202: Loss:0.8454, Accuracy:0.5762, Validation Loss:0.8865, Validation Accuracy:0.5435
Epoch #203: Loss:0.8531, Accuracy:0.5692, Validation Loss:0.8703, Validation Accuracy:0.5337
Epoch #204: Loss:0.8440, Accuracy:0.5717, Validation Loss:0.8821, Validation Accuracy:0.5353
Epoch #205: Loss:0.8516, Accuracy:0.5700, Validation Loss:0.8736, Validation Accuracy:0.5320
Epoch #206: Loss:0.8446, Accuracy:0.5684, Validation Loss:0.8787, Validation Accuracy:0.5402
Epoch #207: Loss:0.8478, Accuracy:0.5708, Validation Loss:0.8766, Validation Accuracy:0.5402
Epoch #208: Loss:0.8457, Accuracy:0.5741, Validation Loss:0.8720, Validation Accuracy:0.5353
Epoch #209: Loss:0.8443, Accuracy:0.5721, Validation Loss:0.8745, Validation Accuracy:0.5353
Epoch #210: Loss:0.8417, Accuracy:0.5737, Validation Loss:0.8712, Validation Accuracy:0.5386
Epoch #211: Loss:0.8458, Accuracy:0.5733, Validation Loss:0.8698, Validation Accuracy:0.5369
Epoch #212: Loss:0.8431, Accuracy:0.5737, Validation Loss:0.8898, Validation Accuracy:0.5435
Epoch #213: Loss:0.8490, Accuracy:0.5717, Validation Loss:0.8704, Validation Accuracy:0.5419
Epoch #214: Loss:0.8473, Accuracy:0.5696, Validation Loss:0.8717, Validation Accuracy:0.5320
Epoch #215: Loss:0.8383, Accuracy:0.5737, Validation Loss:0.8703, Validation Accuracy:0.5304
Epoch #216: Loss:0.8387, Accuracy:0.5733, Validation Loss:0.8713, Validation Accuracy:0.5353
Epoch #217: Loss:0.8400, Accuracy:0.5774, Validation Loss:0.8702, Validation Accuracy:0.5337
Epoch #218: Loss:0.8389, Accuracy:0.5745, Validation Loss:0.8717, Validation Accuracy:0.5386
Epoch #219: Loss:0.8448, Accuracy:0.5708, Validation Loss:0.8814, Validation Accuracy:0.5419
Epoch #220: Loss:0.8420, Accuracy:0.5754, Validation Loss:0.8716, Validation Accuracy:0.5320
Epoch #221: Loss:0.8406, Accuracy:0.5721, Validation Loss:0.8710, Validation Accuracy:0.5304
Epoch #222: Loss:0.8398, Accuracy:0.5774, Validation Loss:0.8687, Validation Accuracy:0.5304
Epoch #223: Loss:0.8370, Accuracy:0.5770, Validation Loss:0.8692, Validation Accuracy:0.5304
Epoch #224: Loss:0.8398, Accuracy:0.5729, Validation Loss:0.8721, Validation Accuracy:0.5353
Epoch #225: Loss:0.8396, Accuracy:0.5737, Validation Loss:0.8750, Validation Accuracy:0.5287
Epoch #226: Loss:0.8417, Accuracy:0.5696, Validation Loss:0.8879, Validation Accuracy:0.5484
Epoch #227: Loss:0.8417, Accuracy:0.5770, Validation Loss:0.8733, Validation Accuracy:0.5320
Epoch #228: Loss:0.8401, Accuracy:0.5762, Validation Loss:0.8702, Validation Accuracy:0.5304
Epoch #229: Loss:0.8382, Accuracy:0.5749, Validation Loss:0.8706, Validation Accuracy:0.5353
Epoch #230: Loss:0.8381, Accuracy:0.5758, Validation Loss:0.8727, Validation Accuracy:0.5320
Epoch #231: Loss:0.8415, Accuracy:0.5713, Validation Loss:0.8710, Validation Accuracy:0.5320
Epoch #232: Loss:0.8470, Accuracy:0.5704, Validation Loss:0.8903, Validation Accuracy:0.5320
Epoch #233: Loss:0.8511, Accuracy:0.5676, Validation Loss:0.8765, Validation Accuracy:0.5222
Epoch #234: Loss:0.8460, Accuracy:0.5733, Validation Loss:0.8668, Validation Accuracy:0.5287
Epoch #235: Loss:0.8486, Accuracy:0.5667, Validation Loss:0.8663, Validation Accuracy:0.5255
Epoch #236: Loss:0.8401, Accuracy:0.5749, Validation Loss:0.8803, Validation Accuracy:0.5419
Epoch #237: Loss:0.8440, Accuracy:0.5680, Validation Loss:0.8787, Validation Accuracy:0.5419
Epoch #238: Loss:0.8464, Accuracy:0.5708, Validation Loss:0.8907, Validation Accuracy:0.5255
Epoch #239: Loss:0.8528, Accuracy:0.5655, Validation Loss:0.8734, Validation Accuracy:0.5238
Epoch #240: Loss:0.8400, Accuracy:0.5770, Validation Loss:0.8688, Validation Accuracy:0.5484
Epoch #241: Loss:0.8350, Accuracy:0.5786, Validation Loss:0.8669, Validation Accuracy:0.5337
Epoch #242: Loss:0.8363, Accuracy:0.5762, Validation Loss:0.8684, Validation Accuracy:0.5287
Epoch #243: Loss:0.8328, Accuracy:0.5770, Validation Loss:0.8676, Validation Accuracy:0.5238
Epoch #244: Loss:0.8325, Accuracy:0.5836, Validation Loss:0.8702, Validation Accuracy:0.5402
Epoch #245: Loss:0.8338, Accuracy:0.5799, Validation Loss:0.8714, Validation Accuracy:0.5402
Epoch #246: Loss:0.8351, Accuracy:0.5770, Validation Loss:0.8735, Validation Accuracy:0.5320
Epoch #247: Loss:0.8338, Accuracy:0.5782, Validation Loss:0.8680, Validation Accuracy:0.5320
Epoch #248: Loss:0.8352, Accuracy:0.5819, Validation Loss:0.8753, Validation Accuracy:0.5287
Epoch #249: Loss:0.8404, Accuracy:0.5770, Validation Loss:0.8760, Validation Accuracy:0.5337
Epoch #250: Loss:0.8418, Accuracy:0.5754, Validation Loss:0.8669, Validation Accuracy:0.5320
Epoch #251: Loss:0.8299, Accuracy:0.5795, Validation Loss:0.8771, Validation Accuracy:0.5419
Epoch #252: Loss:0.8333, Accuracy:0.5795, Validation Loss:0.8668, Validation Accuracy:0.5320
Epoch #253: Loss:0.8342, Accuracy:0.5782, Validation Loss:0.8675, Validation Accuracy:0.5320
Epoch #254: Loss:0.8340, Accuracy:0.5803, Validation Loss:0.8667, Validation Accuracy:0.5320
Epoch #255: Loss:0.8405, Accuracy:0.5774, Validation Loss:0.8995, Validation Accuracy:0.5238
Epoch #256: Loss:0.8482, Accuracy:0.5696, Validation Loss:0.8635, Validation Accuracy:0.5435
Epoch #257: Loss:0.8347, Accuracy:0.5774, Validation Loss:0.8695, Validation Accuracy:0.5501
Epoch #258: Loss:0.8311, Accuracy:0.5807, Validation Loss:0.8647, Validation Accuracy:0.5337
Epoch #259: Loss:0.8296, Accuracy:0.5799, Validation Loss:0.8644, Validation Accuracy:0.5287
Epoch #260: Loss:0.8292, Accuracy:0.5762, Validation Loss:0.8653, Validation Accuracy:0.5386
Epoch #261: Loss:0.8292, Accuracy:0.5803, Validation Loss:0.8699, Validation Accuracy:0.5484
Epoch #262: Loss:0.8307, Accuracy:0.5840, Validation Loss:0.8713, Validation Accuracy:0.5452
Epoch #263: Loss:0.8314, Accuracy:0.5791, Validation Loss:0.8695, Validation Accuracy:0.5304
Epoch #264: Loss:0.8345, Accuracy:0.5786, Validation Loss:0.8885, Validation Accuracy:0.5205
Epoch #265: Loss:0.8424, Accuracy:0.5803, Validation Loss:0.8644, Validation Accuracy:0.5386
Epoch #266: Loss:0.8302, Accuracy:0.5803, Validation Loss:0.8637, Validation Accuracy:0.5320
Epoch #267: Loss:0.8285, Accuracy:0.5832, Validation Loss:0.8671, Validation Accuracy:0.5419
Epoch #268: Loss:0.8297, Accuracy:0.5815, Validation Loss:0.8659, Validation Accuracy:0.5304
Epoch #269: Loss:0.8282, Accuracy:0.5786, Validation Loss:0.8680, Validation Accuracy:0.5468
Epoch #270: Loss:0.8291, Accuracy:0.5815, Validation Loss:0.9019, Validation Accuracy:0.5402
Epoch #271: Loss:0.8457, Accuracy:0.5725, Validation Loss:0.8772, Validation Accuracy:0.5484
Epoch #272: Loss:0.8320, Accuracy:0.5803, Validation Loss:0.8635, Validation Accuracy:0.5304
Epoch #273: Loss:0.8300, Accuracy:0.5803, Validation Loss:0.8640, Validation Accuracy:0.5337
Epoch #274: Loss:0.8286, Accuracy:0.5807, Validation Loss:0.8659, Validation Accuracy:0.5255
Epoch #275: Loss:0.8272, Accuracy:0.5811, Validation Loss:0.8628, Validation Accuracy:0.5287
Epoch #276: Loss:0.8252, Accuracy:0.5840, Validation Loss:0.8633, Validation Accuracy:0.5435
Epoch #277: Loss:0.8249, Accuracy:0.5864, Validation Loss:0.8631, Validation Accuracy:0.5337
Epoch #278: Loss:0.8269, Accuracy:0.5811, Validation Loss:0.8633, Validation Accuracy:0.5402
Epoch #279: Loss:0.8259, Accuracy:0.5869, Validation Loss:0.8639, Validation Accuracy:0.5402
Epoch #280: Loss:0.8249, Accuracy:0.5823, Validation Loss:0.8699, Validation Accuracy:0.5452
Epoch #281: Loss:0.8250, Accuracy:0.5852, Validation Loss:0.8640, Validation Accuracy:0.5304
Epoch #282: Loss:0.8235, Accuracy:0.5897, Validation Loss:0.8637, Validation Accuracy:0.5435
Epoch #283: Loss:0.8249, Accuracy:0.5856, Validation Loss:0.8640, Validation Accuracy:0.5320
Epoch #284: Loss:0.8254, Accuracy:0.5848, Validation Loss:0.8648, Validation Accuracy:0.5304
Epoch #285: Loss:0.8240, Accuracy:0.5799, Validation Loss:0.8653, Validation Accuracy:0.5304
Epoch #286: Loss:0.8209, Accuracy:0.5906, Validation Loss:0.8927, Validation Accuracy:0.5452
Epoch #287: Loss:0.8366, Accuracy:0.5799, Validation Loss:0.8652, Validation Accuracy:0.5419
Epoch #288: Loss:0.8242, Accuracy:0.5819, Validation Loss:0.8654, Validation Accuracy:0.5386
Epoch #289: Loss:0.8214, Accuracy:0.5869, Validation Loss:0.8634, Validation Accuracy:0.5353
Epoch #290: Loss:0.8228, Accuracy:0.5860, Validation Loss:0.8626, Validation Accuracy:0.5452
Epoch #291: Loss:0.8239, Accuracy:0.5852, Validation Loss:0.8716, Validation Accuracy:0.5517
Epoch #292: Loss:0.8276, Accuracy:0.5782, Validation Loss:0.8656, Validation Accuracy:0.5419
Epoch #293: Loss:0.8237, Accuracy:0.5864, Validation Loss:0.8673, Validation Accuracy:0.5435
Epoch #294: Loss:0.8263, Accuracy:0.5877, Validation Loss:0.8667, Validation Accuracy:0.5369
Epoch #295: Loss:0.8280, Accuracy:0.5754, Validation Loss:0.8630, Validation Accuracy:0.5320
Epoch #296: Loss:0.8220, Accuracy:0.5828, Validation Loss:0.8654, Validation Accuracy:0.5452
Epoch #297: Loss:0.8232, Accuracy:0.5823, Validation Loss:0.8653, Validation Accuracy:0.5435
Epoch #298: Loss:0.8236, Accuracy:0.5828, Validation Loss:0.8625, Validation Accuracy:0.5452
Epoch #299: Loss:0.8202, Accuracy:0.5877, Validation Loss:0.8602, Validation Accuracy:0.5386
Epoch #300: Loss:0.8200, Accuracy:0.5864, Validation Loss:0.8657, Validation Accuracy:0.5435

Test:
Test Loss:0.86568350, Accuracy:0.5435
Labels: ['01', '02', '03']
Confusion Matrix:
       01  02   03
t:01  165  38   37
t:02  147  63   17
t:03   37   2  103
Classification Report:
              precision    recall  f1-score   support

          01       0.47      0.69      0.56       240
          02       0.61      0.28      0.38       227
          03       0.66      0.73      0.69       142

    accuracy                           0.54       609
   macro avg       0.58      0.56      0.54       609
weighted avg       0.57      0.54      0.52       609

============ Config: 1/1 === End Time: 2019.07.27 09:44:11 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 16 minutes, 4 seconds =====================

Ending script after plotting results...

======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: D:\atili\MMIExt\Python Projects\Thesis02wDL\confFiles\conf14.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.11.05 03:26:54 =======================================
Parameters: inputFolder : D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
sampRate : 48
featureMode : Mags
channelMode : 0
classificationMode : Speaker
trainingEpoch : 400
stepSize : 0
batchSize : 32
lengthCut : 600
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
clsVersion : 5
Loading from Previous Data Files...
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_inputs_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labels_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labelDict_Mags_0_Speaker_0_48_600_True.dat
Inputs Shape: (1989, 28800, 9)

Total of 1989 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
Total of 20 classes
1591 steps for training, 398 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (1591, 28800, 9)
Test Batch: (398, 28800, 9)
Classifier Version: 5
Model Layer Parameters:
Name: conv1d_1, Filters: 16, Kernel Size: (96,), Strides: (12,), Activation: linear.
Name: dropout_1, Rate: 0.5.
Name: conv1d_2, Filters: 32, Kernel Size: (48,), Strides: (6,), Activation: linear.
Name: dropout_2, Rate: 0.5.
Name: conv1d_3, Filters: 64, Kernel Size: (24,), Strides: (2,), Activation: linear.
Name: dropout_3, Rate: 0.5.
Name: dropout_4, Rate: 0.5.
Optimizer: <keras.optimizers.Adam object at 0x0000023B9C3955C0>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x0000023AED7639D8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 2393, 16)          13840     
_________________________________________________________________
dropout_1 (Dropout)          (None, 2393, 16)          0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 391, 32)           24608     
_________________________________________________________________
dropout_2 (Dropout)          (None, 391, 32)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 184, 64)           49216     
_________________________________________________________________
dropout_3 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_1 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_4 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_2 (CuDNNGRU)       (None, 32)                9408      
_________________________________________________________________
dense_1 (Dense)              (None, 20)                660       
=================================================================
Total params: 122,692
Trainable params: 122,692
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.9867, Accuracy:0.0559, Validation Loss:2.9652, Validation Accuracy:0.0503
Epoch #2: Loss:2.9470, Accuracy:0.0710, Validation Loss:2.9182, Validation Accuracy:0.0678
Epoch #3: Loss:2.9232, Accuracy:0.0761, Validation Loss:2.9049, Validation Accuracy:0.0729
Epoch #4: Loss:2.9059, Accuracy:0.0673, Validation Loss:2.8958, Validation Accuracy:0.0754
Epoch #5: Loss:2.8877, Accuracy:0.0805, Validation Loss:2.8820, Validation Accuracy:0.0729
Epoch #6: Loss:2.8795, Accuracy:0.0748, Validation Loss:2.8249, Validation Accuracy:0.0754
Epoch #7: Loss:2.8691, Accuracy:0.0867, Validation Loss:2.8644, Validation Accuracy:0.0804
Epoch #8: Loss:2.8655, Accuracy:0.0911, Validation Loss:2.8029, Validation Accuracy:0.0980
Epoch #9: Loss:2.8248, Accuracy:0.1025, Validation Loss:2.7993, Validation Accuracy:0.0905
Epoch #10: Loss:2.8114, Accuracy:0.1006, Validation Loss:2.7649, Validation Accuracy:0.1055
Epoch #11: Loss:2.7796, Accuracy:0.1062, Validation Loss:2.7624, Validation Accuracy:0.1005
Epoch #12: Loss:2.7616, Accuracy:0.1081, Validation Loss:2.7557, Validation Accuracy:0.1106
Epoch #13: Loss:2.7431, Accuracy:0.1314, Validation Loss:2.7218, Validation Accuracy:0.1307
Epoch #14: Loss:2.7013, Accuracy:0.1332, Validation Loss:2.7067, Validation Accuracy:0.1432
Epoch #15: Loss:2.6723, Accuracy:0.1596, Validation Loss:2.6842, Validation Accuracy:0.1256
Epoch #16: Loss:2.6103, Accuracy:0.1640, Validation Loss:2.6321, Validation Accuracy:0.1332
Epoch #17: Loss:2.5676, Accuracy:0.1615, Validation Loss:2.6050, Validation Accuracy:0.1658
Epoch #18: Loss:2.4627, Accuracy:0.1829, Validation Loss:2.4220, Validation Accuracy:0.2111
Epoch #19: Loss:2.4218, Accuracy:0.2194, Validation Loss:2.5356, Validation Accuracy:0.1482
Epoch #20: Loss:2.3626, Accuracy:0.2162, Validation Loss:2.3721, Validation Accuracy:0.2286
Epoch #21: Loss:2.2938, Accuracy:0.2288, Validation Loss:2.3914, Validation Accuracy:0.2487
Epoch #22: Loss:2.2755, Accuracy:0.2432, Validation Loss:2.3286, Validation Accuracy:0.2487
Epoch #23: Loss:2.2207, Accuracy:0.2728, Validation Loss:2.2630, Validation Accuracy:0.2638
Epoch #24: Loss:2.1731, Accuracy:0.2784, Validation Loss:2.4764, Validation Accuracy:0.2186
Epoch #25: Loss:2.1721, Accuracy:0.2948, Validation Loss:2.2906, Validation Accuracy:0.2588
Epoch #26: Loss:2.1160, Accuracy:0.3099, Validation Loss:2.2801, Validation Accuracy:0.2513
Epoch #27: Loss:2.0822, Accuracy:0.3155, Validation Loss:2.2080, Validation Accuracy:0.2839
Epoch #28: Loss:2.0519, Accuracy:0.3325, Validation Loss:2.1217, Validation Accuracy:0.2915
Epoch #29: Loss:2.0123, Accuracy:0.3350, Validation Loss:2.1083, Validation Accuracy:0.3216
Epoch #30: Loss:1.9767, Accuracy:0.3576, Validation Loss:2.1380, Validation Accuracy:0.3216
Epoch #31: Loss:1.9726, Accuracy:0.3388, Validation Loss:2.1292, Validation Accuracy:0.3116
Epoch #32: Loss:1.9260, Accuracy:0.3583, Validation Loss:2.0621, Validation Accuracy:0.3141
Epoch #33: Loss:1.9189, Accuracy:0.3614, Validation Loss:2.0610, Validation Accuracy:0.3216
Epoch #34: Loss:1.8968, Accuracy:0.3777, Validation Loss:1.9471, Validation Accuracy:0.3693
Epoch #35: Loss:1.8824, Accuracy:0.3803, Validation Loss:2.1387, Validation Accuracy:0.2990
Epoch #36: Loss:1.8882, Accuracy:0.3664, Validation Loss:2.0475, Validation Accuracy:0.3216
Epoch #37: Loss:1.8484, Accuracy:0.3859, Validation Loss:2.0109, Validation Accuracy:0.3467
Epoch #38: Loss:1.7991, Accuracy:0.4123, Validation Loss:1.9581, Validation Accuracy:0.3618
Epoch #39: Loss:1.8023, Accuracy:0.4111, Validation Loss:2.0174, Validation Accuracy:0.2990
Epoch #40: Loss:1.9872, Accuracy:0.3426, Validation Loss:1.9553, Validation Accuracy:0.3618
Epoch #41: Loss:1.8338, Accuracy:0.4111, Validation Loss:2.0681, Validation Accuracy:0.3518
Epoch #42: Loss:1.7827, Accuracy:0.4079, Validation Loss:1.9714, Validation Accuracy:0.3719
Epoch #43: Loss:1.7530, Accuracy:0.4243, Validation Loss:1.8170, Validation Accuracy:0.3945
Epoch #44: Loss:1.7380, Accuracy:0.4312, Validation Loss:1.9097, Validation Accuracy:0.3719
Epoch #45: Loss:1.7309, Accuracy:0.4387, Validation Loss:1.8491, Validation Accuracy:0.3970
Epoch #46: Loss:1.7133, Accuracy:0.4318, Validation Loss:1.8346, Validation Accuracy:0.4221
Epoch #47: Loss:1.6758, Accuracy:0.4595, Validation Loss:1.9101, Validation Accuracy:0.3920
Epoch #48: Loss:1.6722, Accuracy:0.4513, Validation Loss:1.8711, Validation Accuracy:0.3920
Epoch #49: Loss:1.6356, Accuracy:0.4651, Validation Loss:1.9124, Validation Accuracy:0.3995
Epoch #50: Loss:1.6228, Accuracy:0.4708, Validation Loss:1.8806, Validation Accuracy:0.3945
Epoch #51: Loss:1.6467, Accuracy:0.4833, Validation Loss:1.8858, Validation Accuracy:0.3945
Epoch #52: Loss:1.6224, Accuracy:0.4538, Validation Loss:1.7839, Validation Accuracy:0.3995
Epoch #53: Loss:1.5818, Accuracy:0.4815, Validation Loss:1.8226, Validation Accuracy:0.3995
Epoch #54: Loss:1.5754, Accuracy:0.4796, Validation Loss:1.8246, Validation Accuracy:0.4020
Epoch #55: Loss:1.5363, Accuracy:0.5028, Validation Loss:1.7352, Validation Accuracy:0.4246
Epoch #56: Loss:1.5522, Accuracy:0.4940, Validation Loss:1.7917, Validation Accuracy:0.4271
Epoch #57: Loss:1.5252, Accuracy:0.5097, Validation Loss:1.8185, Validation Accuracy:0.4196
Epoch #58: Loss:1.5319, Accuracy:0.4815, Validation Loss:1.8221, Validation Accuracy:0.4196
Epoch #59: Loss:1.5222, Accuracy:0.4890, Validation Loss:1.7782, Validation Accuracy:0.4246
Epoch #60: Loss:1.5138, Accuracy:0.4972, Validation Loss:1.9228, Validation Accuracy:0.3869
Epoch #61: Loss:1.4564, Accuracy:0.5261, Validation Loss:1.7302, Validation Accuracy:0.4573
Epoch #62: Loss:1.4777, Accuracy:0.4915, Validation Loss:1.7861, Validation Accuracy:0.4422
Epoch #63: Loss:1.4599, Accuracy:0.5154, Validation Loss:1.8720, Validation Accuracy:0.4121
Epoch #64: Loss:1.4298, Accuracy:0.5255, Validation Loss:1.8721, Validation Accuracy:0.4221
Epoch #65: Loss:1.4560, Accuracy:0.5261, Validation Loss:1.7651, Validation Accuracy:0.4246
Epoch #66: Loss:1.4299, Accuracy:0.5229, Validation Loss:1.7568, Validation Accuracy:0.4573
Epoch #67: Loss:1.3876, Accuracy:0.5374, Validation Loss:1.8318, Validation Accuracy:0.4246
Epoch #68: Loss:1.5533, Accuracy:0.5028, Validation Loss:2.0185, Validation Accuracy:0.3794
Epoch #69: Loss:1.4912, Accuracy:0.5091, Validation Loss:1.8008, Validation Accuracy:0.4070
Epoch #70: Loss:1.3904, Accuracy:0.5431, Validation Loss:1.8029, Validation Accuracy:0.4397
Epoch #71: Loss:1.4338, Accuracy:0.5248, Validation Loss:1.8308, Validation Accuracy:0.4171
Epoch #72: Loss:1.3192, Accuracy:0.5657, Validation Loss:1.7746, Validation Accuracy:0.4497
Epoch #73: Loss:1.3020, Accuracy:0.5676, Validation Loss:1.7714, Validation Accuracy:0.4598
Epoch #74: Loss:1.2841, Accuracy:0.5833, Validation Loss:1.7579, Validation Accuracy:0.4724
Epoch #75: Loss:1.2715, Accuracy:0.5776, Validation Loss:1.7065, Validation Accuracy:0.4799
Epoch #76: Loss:1.2707, Accuracy:0.5801, Validation Loss:1.7662, Validation Accuracy:0.4447
Epoch #77: Loss:1.2557, Accuracy:0.5933, Validation Loss:1.7145, Validation Accuracy:0.4724
Epoch #78: Loss:1.2266, Accuracy:0.6065, Validation Loss:1.6936, Validation Accuracy:0.4849
Epoch #79: Loss:1.2231, Accuracy:0.6015, Validation Loss:1.7450, Validation Accuracy:0.4799
Epoch #80: Loss:1.2285, Accuracy:0.6040, Validation Loss:1.7652, Validation Accuracy:0.4548
Epoch #81: Loss:1.2165, Accuracy:0.6028, Validation Loss:1.8055, Validation Accuracy:0.4497
Epoch #82: Loss:1.2053, Accuracy:0.6034, Validation Loss:1.7515, Validation Accuracy:0.4623
Epoch #83: Loss:1.2032, Accuracy:0.6109, Validation Loss:1.7633, Validation Accuracy:0.4497
Epoch #84: Loss:1.1703, Accuracy:0.6298, Validation Loss:1.7599, Validation Accuracy:0.4698
Epoch #85: Loss:1.1822, Accuracy:0.6015, Validation Loss:1.7383, Validation Accuracy:0.4849
Epoch #86: Loss:1.1765, Accuracy:0.6229, Validation Loss:1.7666, Validation Accuracy:0.4799
Epoch #87: Loss:1.1715, Accuracy:0.6216, Validation Loss:1.8167, Validation Accuracy:0.4548
Epoch #88: Loss:1.1756, Accuracy:0.6091, Validation Loss:1.7173, Validation Accuracy:0.4899
Epoch #89: Loss:1.1682, Accuracy:0.6248, Validation Loss:1.7062, Validation Accuracy:0.4824
Epoch #90: Loss:1.1606, Accuracy:0.6091, Validation Loss:1.8142, Validation Accuracy:0.4523
Epoch #91: Loss:1.1297, Accuracy:0.6273, Validation Loss:1.7600, Validation Accuracy:0.4523
Epoch #92: Loss:1.1057, Accuracy:0.6436, Validation Loss:1.7266, Validation Accuracy:0.4673
Epoch #93: Loss:1.0921, Accuracy:0.6442, Validation Loss:1.7475, Validation Accuracy:0.4724
Epoch #94: Loss:1.0808, Accuracy:0.6612, Validation Loss:1.7759, Validation Accuracy:0.4472
Epoch #95: Loss:1.0731, Accuracy:0.6493, Validation Loss:1.7745, Validation Accuracy:0.4724
Epoch #96: Loss:1.0884, Accuracy:0.6411, Validation Loss:1.7689, Validation Accuracy:0.4698
Epoch #97: Loss:1.1036, Accuracy:0.6449, Validation Loss:1.7890, Validation Accuracy:0.4724
Epoch #98: Loss:1.0775, Accuracy:0.6499, Validation Loss:1.7989, Validation Accuracy:0.4623
Epoch #99: Loss:1.0770, Accuracy:0.6505, Validation Loss:1.7780, Validation Accuracy:0.4698
Epoch #100: Loss:1.0939, Accuracy:0.6424, Validation Loss:1.7544, Validation Accuracy:0.4623
Epoch #101: Loss:1.0746, Accuracy:0.6543, Validation Loss:1.7892, Validation Accuracy:0.4799
Epoch #102: Loss:1.0618, Accuracy:0.6442, Validation Loss:1.8258, Validation Accuracy:0.4573
Epoch #103: Loss:1.0707, Accuracy:0.6424, Validation Loss:1.7493, Validation Accuracy:0.4874
Epoch #104: Loss:1.0592, Accuracy:0.6505, Validation Loss:1.7852, Validation Accuracy:0.4598
Epoch #105: Loss:1.0458, Accuracy:0.6669, Validation Loss:1.8086, Validation Accuracy:0.4548
Epoch #106: Loss:1.0596, Accuracy:0.6581, Validation Loss:1.7896, Validation Accuracy:0.4799
Epoch #107: Loss:1.0382, Accuracy:0.6656, Validation Loss:1.7445, Validation Accuracy:0.4799
Epoch #108: Loss:1.0325, Accuracy:0.6644, Validation Loss:1.8130, Validation Accuracy:0.4673
Epoch #109: Loss:1.0555, Accuracy:0.6568, Validation Loss:1.8081, Validation Accuracy:0.4648
Epoch #110: Loss:1.0081, Accuracy:0.6662, Validation Loss:1.8100, Validation Accuracy:0.4749
Epoch #111: Loss:0.9882, Accuracy:0.6807, Validation Loss:1.7951, Validation Accuracy:0.4774
Epoch #112: Loss:1.0180, Accuracy:0.6776, Validation Loss:1.7700, Validation Accuracy:0.4824
Epoch #113: Loss:1.0099, Accuracy:0.6637, Validation Loss:1.7796, Validation Accuracy:0.4925
Epoch #114: Loss:1.0078, Accuracy:0.6801, Validation Loss:1.7781, Validation Accuracy:0.4899
Epoch #115: Loss:0.9916, Accuracy:0.6713, Validation Loss:1.8122, Validation Accuracy:0.4774
Epoch #116: Loss:0.9883, Accuracy:0.6832, Validation Loss:1.8063, Validation Accuracy:0.4849
Epoch #117: Loss:1.0046, Accuracy:0.6725, Validation Loss:1.8175, Validation Accuracy:0.4724
Epoch #118: Loss:0.9955, Accuracy:0.6788, Validation Loss:1.8147, Validation Accuracy:0.4749
Epoch #119: Loss:0.9839, Accuracy:0.6826, Validation Loss:1.8342, Validation Accuracy:0.4698
Epoch #120: Loss:0.9918, Accuracy:0.6675, Validation Loss:1.8139, Validation Accuracy:0.4548
Epoch #121: Loss:0.9847, Accuracy:0.6801, Validation Loss:1.8100, Validation Accuracy:0.4698
Epoch #122: Loss:0.9905, Accuracy:0.6813, Validation Loss:1.8211, Validation Accuracy:0.4724
Epoch #123: Loss:0.9980, Accuracy:0.6757, Validation Loss:1.8320, Validation Accuracy:0.4573

Restoring best model...
Test:
Test Loss:1.69360089, Accuracy:0.4849
Labels: ['ib', 'eg', 'yd', 'aa', 'my', 'kk', 'sg', 'sd', 'ck', 'eb', 'by', 'ce', 'am', 'eo', 'mb', 'ig', 'ek', 'sk', 'ds', 'ab']
Confusion Matrix:
      ib  eg  yd  aa  my  kk  sg  sd  ck  eb  by  ce  am  eo  mb  ig  ek  sk  ds  ab
t:ib  16   1   0   0   0   0   0   0   1   0   0   0   0   1   1   0   0   0   0   0
t:eg   2  10   0   1   0   0   0   0   0   1   1   1   0   0   0   0   0   2   1   1
t:yd   0   0  14   0   0   0   1   2   1   0   0   0   0   0   0   2   0   0   0   0
t:aa   0   1   0  13   0   0   0   0   0   0   0   1   3   0   0   1   1   0   0   0
t:my   0   0   0   0   5   2   0   1   1   0   0   1   0   0   3   0   2   1   1   1
t:kk   0   0   2   0   0  10   0   1   0   1   0   0   2   0   1   1   0   1   0   1
t:sg   1   0   5   0   0   1   7   1   0   0   0   0   0   0   0   4   0   0   0   1
t:sd   3   2   1   0   1   2   1   4   0   0   0   0   0   0   0   3   1   0   0   2
t:ck   0   0   0   1   2   1   0   0   6   1   0   0   0   0   2   0   0   3   4   0
t:eb   1   0   0   0   0   0   0   0   0  14   0   0   0   0   1   0   0   2   2   0
t:by   0   3   2   0   0   0   3   1   0   0   9   1   0   1   0   0   0   0   0   0
t:ce   4   1   0   0   0   0   0   0   0   0   1  11   0   2   0   0   0   0   0   1
t:am   0   0   0   1   0   1   1   0   0   0   0   0   9   0   0   0   2   4   1   1
t:eo   2   0   0   0   0   0   0   0   0   0   2   0   0  16   0   0   0   0   0   0
t:mb   0   1   0   0   0   0   0   0   0   0   0   0   0   0  10   0   2   2   0   5
t:ig   0   0   5   1   0   0   1   0   0   0   0   0   1   0   1   9   2   0   0   0
t:ek   0   0   0   1   0   4   1   0   0   0   0   0   4   0   1   0   6   1   1   1
t:sk   0   1   0   1   0   1   0   0   1   0   0   0   2   0   1   1   3   8   1   0
t:ds   0   0   1   0   0   1   0   0   1   2   0   0   0   0   0   0   2   4   8   1
t:ab   0   0   0   0   0   1   0   0   0   0   0   1   0   0   4   1   1   4   0   8
Classification Report:
              precision    recall  f1-score   support

          ib       0.55      0.80      0.65        20
          eg       0.50      0.50      0.50        20
          yd       0.47      0.70      0.56        20
          aa       0.68      0.65      0.67        20
          my       0.62      0.28      0.38        18
          kk       0.42      0.50      0.45        20
          sg       0.47      0.35      0.40        20
          sd       0.40      0.20      0.27        20
          ck       0.55      0.30      0.39        20
          eb       0.74      0.70      0.72        20
          by       0.69      0.45      0.55        20
          ce       0.69      0.55      0.61        20
          am       0.43      0.45      0.44        20
          eo       0.80      0.80      0.80        20
          mb       0.40      0.50      0.44        20
          ig       0.41      0.45      0.43        20
          ek       0.27      0.30      0.29        20
          sk       0.25      0.40      0.31        20
          ds       0.42      0.40      0.41        20
          ab       0.35      0.40      0.37        20

   micro avg       0.48      0.48      0.48       398
   macro avg       0.51      0.48      0.48       398
weighted avg       0.50      0.48      0.48       398

============ Config: 1/1 === End Time: 2019.11.05 03:40:32 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 13 minutes, 37 seconds =====================

Ending script after plotting results...

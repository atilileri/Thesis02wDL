======= Running File: classifierLSTMnSVM.py =======
Reading Configuration from command line argument: D:\atili\MMIExt\Python Projects\Thesis02wDL\confFiles\conf18.txt
Total of 1 configuration(s) will be run
============ Config: 1/1 === Start Time: 2019.11.05 04:29:18 =======================================
Parameters: inputFolder : D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
sampRate : 48
featureMode : Mags
channelMode : 0
classificationMode : Speaker
trainingEpoch : 400
stepSize : 0
batchSize : 128
lengthCut : 600
learningRate : 0.001
lossFunction : CatCrosEnt
optimizer : Adam
clsModel : LSTM
clsVersion : 5
Loading from Previous Data Files...
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_inputs_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labels_Mags_0_Speaker_0_48_600_True.dat
Loaded: D:/atili/MMIExt/Audacity/METU Recordings/Dataset/tempDataStorage/allSmall_labelDict_Mags_0_Speaker_0_48_600_True.dat
Inputs Shape: (1989, 28800, 9)

Total of 1989 inputs loaded @ D:/atili/MMIExt/Audacity/METU Recordings/Dataset/allSmall/
Total of 20 classes
1591 steps for training, 398 steps for test
Splitting Train and Test Data...
------Model for Mags------
---LSTM Classifier---
Train Batch: (1591, 28800, 9)
Test Batch: (398, 28800, 9)
Classifier Version: 5
Model Layer Parameters:
Name: conv1d_1, Filters: 16, Kernel Size: (96,), Strides: (12,), Activation: linear.
Name: dropout_1, Rate: 0.5.
Name: conv1d_2, Filters: 32, Kernel Size: (48,), Strides: (6,), Activation: linear.
Name: dropout_2, Rate: 0.5.
Name: conv1d_3, Filters: 64, Kernel Size: (24,), Strides: (2,), Activation: linear.
Name: dropout_3, Rate: 0.5.
Name: dropout_4, Rate: 0.5.
Optimizer: <keras.optimizers.Adam object at 0x000001B21C2055C0>
Learning Rate: 0.001
Loss func: <function categorical_crossentropy at 0x000001B141F539D8>
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 2393, 16)          13840     
_________________________________________________________________
dropout_1 (Dropout)          (None, 2393, 16)          0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 391, 32)           24608     
_________________________________________________________________
dropout_2 (Dropout)          (None, 391, 32)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 184, 64)           49216     
_________________________________________________________________
dropout_3 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_1 (CuDNNGRU)       (None, 184, 64)           24960     
_________________________________________________________________
dropout_4 (Dropout)          (None, 184, 64)           0         
_________________________________________________________________
cu_dnngru_2 (CuDNNGRU)       (None, 32)                9408      
_________________________________________________________________
dense_1 (Dense)              (None, 20)                660       
=================================================================
Total params: 122,692
Trainable params: 122,692
Non-trainable params: 0
_________________________________________________________________

Training:
Epoch #1: Loss:2.9906, Accuracy:0.0465, Validation Loss:2.9583, Validation Accuracy:0.0729
Epoch #2: Loss:2.9454, Accuracy:0.0710, Validation Loss:2.9321, Validation Accuracy:0.0754
Epoch #3: Loss:2.9239, Accuracy:0.0679, Validation Loss:2.9222, Validation Accuracy:0.0704
Epoch #4: Loss:2.9161, Accuracy:0.0754, Validation Loss:2.9250, Validation Accuracy:0.0779
Epoch #5: Loss:2.9237, Accuracy:0.0767, Validation Loss:2.9207, Validation Accuracy:0.0653
Epoch #6: Loss:2.9052, Accuracy:0.0761, Validation Loss:2.9084, Validation Accuracy:0.0804
Epoch #7: Loss:2.8890, Accuracy:0.0830, Validation Loss:2.9005, Validation Accuracy:0.0829
Epoch #8: Loss:2.8713, Accuracy:0.0899, Validation Loss:2.8713, Validation Accuracy:0.1030
Epoch #9: Loss:2.8417, Accuracy:0.0999, Validation Loss:2.8522, Validation Accuracy:0.0879
Epoch #10: Loss:2.8585, Accuracy:0.0962, Validation Loss:2.8779, Validation Accuracy:0.0829
Epoch #11: Loss:2.8544, Accuracy:0.0893, Validation Loss:2.8553, Validation Accuracy:0.0955
Epoch #12: Loss:2.8224, Accuracy:0.1062, Validation Loss:2.8293, Validation Accuracy:0.1030
Epoch #13: Loss:2.8005, Accuracy:0.1037, Validation Loss:2.8203, Validation Accuracy:0.1005
Epoch #14: Loss:2.7979, Accuracy:0.0987, Validation Loss:2.8228, Validation Accuracy:0.1005
Epoch #15: Loss:2.7964, Accuracy:0.1138, Validation Loss:2.8037, Validation Accuracy:0.1131
Epoch #16: Loss:2.7754, Accuracy:0.1062, Validation Loss:2.7932, Validation Accuracy:0.1206
Epoch #17: Loss:2.7713, Accuracy:0.1113, Validation Loss:2.7980, Validation Accuracy:0.1055
Epoch #18: Loss:2.7612, Accuracy:0.1144, Validation Loss:2.7826, Validation Accuracy:0.1131
Epoch #19: Loss:2.7529, Accuracy:0.1245, Validation Loss:2.7909, Validation Accuracy:0.1030
Epoch #20: Loss:2.7496, Accuracy:0.1238, Validation Loss:2.7700, Validation Accuracy:0.1106
Epoch #21: Loss:2.7456, Accuracy:0.1207, Validation Loss:2.7729, Validation Accuracy:0.1206
Epoch #22: Loss:2.7364, Accuracy:0.1245, Validation Loss:2.7894, Validation Accuracy:0.1106
Epoch #23: Loss:2.7241, Accuracy:0.1395, Validation Loss:2.7705, Validation Accuracy:0.1332
Epoch #24: Loss:2.7226, Accuracy:0.1395, Validation Loss:2.7483, Validation Accuracy:0.1307
Epoch #25: Loss:2.7112, Accuracy:0.1358, Validation Loss:2.7316, Validation Accuracy:0.1256
Epoch #26: Loss:2.6983, Accuracy:0.1389, Validation Loss:2.7484, Validation Accuracy:0.1131
Epoch #27: Loss:2.6707, Accuracy:0.1414, Validation Loss:2.7229, Validation Accuracy:0.1030
Epoch #28: Loss:2.6531, Accuracy:0.1427, Validation Loss:2.6835, Validation Accuracy:0.1407
Epoch #29: Loss:2.6137, Accuracy:0.1483, Validation Loss:2.6619, Validation Accuracy:0.1533
Epoch #30: Loss:2.5753, Accuracy:0.1684, Validation Loss:2.6310, Validation Accuracy:0.1457
Epoch #31: Loss:2.5426, Accuracy:0.1741, Validation Loss:2.6721, Validation Accuracy:0.1608
Epoch #32: Loss:2.5139, Accuracy:0.1760, Validation Loss:2.5306, Validation Accuracy:0.1884
Epoch #33: Loss:2.4954, Accuracy:0.1810, Validation Loss:2.5418, Validation Accuracy:0.1935
Epoch #34: Loss:2.5163, Accuracy:0.1804, Validation Loss:2.7441, Validation Accuracy:0.1407
Epoch #35: Loss:2.4927, Accuracy:0.1904, Validation Loss:2.5452, Validation Accuracy:0.1809
Epoch #36: Loss:2.4288, Accuracy:0.1948, Validation Loss:2.4724, Validation Accuracy:0.1784
Epoch #37: Loss:2.3850, Accuracy:0.2194, Validation Loss:2.4882, Validation Accuracy:0.2060
Epoch #38: Loss:2.3518, Accuracy:0.2200, Validation Loss:2.4311, Validation Accuracy:0.1985
Epoch #39: Loss:2.3416, Accuracy:0.2470, Validation Loss:2.6090, Validation Accuracy:0.1985
Epoch #40: Loss:2.3505, Accuracy:0.2200, Validation Loss:2.4884, Validation Accuracy:0.2085
Epoch #41: Loss:2.2823, Accuracy:0.2533, Validation Loss:2.3655, Validation Accuracy:0.2111
Epoch #42: Loss:2.2575, Accuracy:0.2514, Validation Loss:2.4507, Validation Accuracy:0.1910
Epoch #43: Loss:2.2354, Accuracy:0.2696, Validation Loss:2.3956, Validation Accuracy:0.2136
Epoch #44: Loss:2.1904, Accuracy:0.2759, Validation Loss:2.3024, Validation Accuracy:0.2060
Epoch #45: Loss:2.1685, Accuracy:0.2879, Validation Loss:2.4041, Validation Accuracy:0.2563
Epoch #46: Loss:2.1734, Accuracy:0.2860, Validation Loss:2.4093, Validation Accuracy:0.2337
Epoch #47: Loss:2.1310, Accuracy:0.3023, Validation Loss:2.3242, Validation Accuracy:0.2663
Epoch #48: Loss:2.0934, Accuracy:0.3124, Validation Loss:2.2930, Validation Accuracy:0.2412
Epoch #49: Loss:2.0826, Accuracy:0.3055, Validation Loss:2.3154, Validation Accuracy:0.2663
Epoch #50: Loss:2.0669, Accuracy:0.3124, Validation Loss:2.2572, Validation Accuracy:0.2814
Epoch #51: Loss:2.0377, Accuracy:0.3206, Validation Loss:2.2442, Validation Accuracy:0.3015
Epoch #52: Loss:2.0409, Accuracy:0.3111, Validation Loss:2.2688, Validation Accuracy:0.2839
Epoch #53: Loss:2.0369, Accuracy:0.3268, Validation Loss:2.2338, Validation Accuracy:0.2864
Epoch #54: Loss:2.0147, Accuracy:0.3325, Validation Loss:2.1858, Validation Accuracy:0.3116
Epoch #55: Loss:2.0001, Accuracy:0.3281, Validation Loss:2.3540, Validation Accuracy:0.2839
Epoch #56: Loss:1.9999, Accuracy:0.3413, Validation Loss:2.1928, Validation Accuracy:0.2814
Epoch #57: Loss:2.0148, Accuracy:0.3306, Validation Loss:2.2098, Validation Accuracy:0.2814
Epoch #58: Loss:1.9653, Accuracy:0.3444, Validation Loss:2.1971, Validation Accuracy:0.2965
Epoch #59: Loss:1.9522, Accuracy:0.3463, Validation Loss:2.1844, Validation Accuracy:0.3266
Epoch #60: Loss:1.9338, Accuracy:0.3551, Validation Loss:2.1242, Validation Accuracy:0.3090
Epoch #61: Loss:1.9504, Accuracy:0.3551, Validation Loss:2.1620, Validation Accuracy:0.3116
Epoch #62: Loss:1.9232, Accuracy:0.3551, Validation Loss:2.2086, Validation Accuracy:0.2965
Epoch #63: Loss:1.9273, Accuracy:0.3551, Validation Loss:2.2033, Validation Accuracy:0.2864
Epoch #64: Loss:1.8926, Accuracy:0.3696, Validation Loss:2.1149, Validation Accuracy:0.3116
Epoch #65: Loss:1.8702, Accuracy:0.3696, Validation Loss:2.1617, Validation Accuracy:0.2889
Epoch #66: Loss:1.8649, Accuracy:0.3752, Validation Loss:2.0914, Validation Accuracy:0.3141
Epoch #67: Loss:1.8495, Accuracy:0.3872, Validation Loss:2.0985, Validation Accuracy:0.3291
Epoch #68: Loss:1.8746, Accuracy:0.3809, Validation Loss:2.1462, Validation Accuracy:0.3342
Epoch #69: Loss:1.8495, Accuracy:0.3784, Validation Loss:2.0723, Validation Accuracy:0.3266
Epoch #70: Loss:1.8220, Accuracy:0.3922, Validation Loss:2.0711, Validation Accuracy:0.3317
Epoch #71: Loss:1.8333, Accuracy:0.3997, Validation Loss:2.1216, Validation Accuracy:0.3065
Epoch #72: Loss:1.8162, Accuracy:0.4060, Validation Loss:2.1107, Validation Accuracy:0.3116
Epoch #73: Loss:1.8218, Accuracy:0.3922, Validation Loss:2.1563, Validation Accuracy:0.2814
Epoch #74: Loss:1.8200, Accuracy:0.3991, Validation Loss:2.0978, Validation Accuracy:0.3141
Epoch #75: Loss:1.8117, Accuracy:0.3979, Validation Loss:2.1131, Validation Accuracy:0.3241
Epoch #76: Loss:1.7744, Accuracy:0.4155, Validation Loss:2.0491, Validation Accuracy:0.3241
Epoch #77: Loss:1.7696, Accuracy:0.4142, Validation Loss:2.0485, Validation Accuracy:0.3467
Epoch #78: Loss:1.7539, Accuracy:0.4186, Validation Loss:2.0430, Validation Accuracy:0.3467
Epoch #79: Loss:1.7588, Accuracy:0.4224, Validation Loss:2.0039, Validation Accuracy:0.3543
Epoch #80: Loss:1.7401, Accuracy:0.4180, Validation Loss:2.0221, Validation Accuracy:0.3518
Epoch #81: Loss:1.7259, Accuracy:0.4255, Validation Loss:2.0225, Validation Accuracy:0.3593
Epoch #82: Loss:1.7224, Accuracy:0.4331, Validation Loss:2.0723, Validation Accuracy:0.3668
Epoch #83: Loss:1.7282, Accuracy:0.4186, Validation Loss:2.0650, Validation Accuracy:0.3543
Epoch #84: Loss:1.7252, Accuracy:0.4274, Validation Loss:2.0215, Validation Accuracy:0.3693
Epoch #85: Loss:1.7118, Accuracy:0.4362, Validation Loss:2.0339, Validation Accuracy:0.3920
Epoch #86: Loss:1.7021, Accuracy:0.4318, Validation Loss:2.0006, Validation Accuracy:0.3693
Epoch #87: Loss:1.6863, Accuracy:0.4400, Validation Loss:2.0220, Validation Accuracy:0.3568
Epoch #88: Loss:1.6810, Accuracy:0.4444, Validation Loss:1.9928, Validation Accuracy:0.3744
Epoch #89: Loss:1.6936, Accuracy:0.4312, Validation Loss:1.9833, Validation Accuracy:0.3593
Epoch #90: Loss:1.6858, Accuracy:0.4494, Validation Loss:1.9952, Validation Accuracy:0.3920
Epoch #91: Loss:1.7024, Accuracy:0.4343, Validation Loss:2.0090, Validation Accuracy:0.3618
Epoch #92: Loss:1.6601, Accuracy:0.4513, Validation Loss:1.9968, Validation Accuracy:0.3518
Epoch #93: Loss:1.6600, Accuracy:0.4551, Validation Loss:2.0237, Validation Accuracy:0.3518
Epoch #94: Loss:1.6512, Accuracy:0.4475, Validation Loss:1.9667, Validation Accuracy:0.3719
Epoch #95: Loss:1.6337, Accuracy:0.4544, Validation Loss:1.9663, Validation Accuracy:0.3719
Epoch #96: Loss:1.6274, Accuracy:0.4576, Validation Loss:1.9552, Validation Accuracy:0.3543
Epoch #97: Loss:1.6271, Accuracy:0.4601, Validation Loss:1.9490, Validation Accuracy:0.4121
Epoch #98: Loss:1.6554, Accuracy:0.4419, Validation Loss:1.9860, Validation Accuracy:0.3693
Epoch #99: Loss:1.6659, Accuracy:0.4381, Validation Loss:1.9577, Validation Accuracy:0.3920
Epoch #100: Loss:1.6137, Accuracy:0.4651, Validation Loss:1.8979, Validation Accuracy:0.4271
Epoch #101: Loss:1.6070, Accuracy:0.4683, Validation Loss:1.9691, Validation Accuracy:0.3970
Epoch #102: Loss:1.6041, Accuracy:0.4771, Validation Loss:1.9133, Validation Accuracy:0.3920
Epoch #103: Loss:1.5813, Accuracy:0.4695, Validation Loss:1.9007, Validation Accuracy:0.4070
Epoch #104: Loss:1.5675, Accuracy:0.4783, Validation Loss:1.9287, Validation Accuracy:0.3920
Epoch #105: Loss:1.5518, Accuracy:0.4714, Validation Loss:1.9083, Validation Accuracy:0.3970
Epoch #106: Loss:1.5521, Accuracy:0.4745, Validation Loss:1.8795, Validation Accuracy:0.4121
Epoch #107: Loss:1.5532, Accuracy:0.4821, Validation Loss:1.8601, Validation Accuracy:0.4196
Epoch #108: Loss:1.5396, Accuracy:0.4833, Validation Loss:1.8886, Validation Accuracy:0.4070
Epoch #109: Loss:1.5410, Accuracy:0.4827, Validation Loss:1.9123, Validation Accuracy:0.4070
Epoch #110: Loss:1.5396, Accuracy:0.4884, Validation Loss:1.9248, Validation Accuracy:0.3819
Epoch #111: Loss:1.5431, Accuracy:0.4771, Validation Loss:1.8833, Validation Accuracy:0.4095
Epoch #112: Loss:1.5160, Accuracy:0.5047, Validation Loss:1.8836, Validation Accuracy:0.4146
Epoch #113: Loss:1.4940, Accuracy:0.5192, Validation Loss:1.8674, Validation Accuracy:0.4171
Epoch #114: Loss:1.5102, Accuracy:0.4871, Validation Loss:1.8770, Validation Accuracy:0.4196
Epoch #115: Loss:1.5079, Accuracy:0.4903, Validation Loss:1.8562, Validation Accuracy:0.4171
Epoch #116: Loss:1.5003, Accuracy:0.5041, Validation Loss:1.8807, Validation Accuracy:0.4095
Epoch #117: Loss:1.4666, Accuracy:0.5060, Validation Loss:1.8364, Validation Accuracy:0.3920
Epoch #118: Loss:1.4536, Accuracy:0.5066, Validation Loss:1.8334, Validation Accuracy:0.4347
Epoch #119: Loss:1.4535, Accuracy:0.5041, Validation Loss:1.8350, Validation Accuracy:0.4397
Epoch #120: Loss:1.4442, Accuracy:0.5280, Validation Loss:1.8435, Validation Accuracy:0.4121
Epoch #121: Loss:1.4423, Accuracy:0.5167, Validation Loss:1.8084, Validation Accuracy:0.4648
Epoch #122: Loss:1.4300, Accuracy:0.5267, Validation Loss:1.7949, Validation Accuracy:0.4422
Epoch #123: Loss:1.4306, Accuracy:0.5242, Validation Loss:1.8346, Validation Accuracy:0.4347
Epoch #124: Loss:1.4303, Accuracy:0.5211, Validation Loss:1.8222, Validation Accuracy:0.4372
Epoch #125: Loss:1.4038, Accuracy:0.5292, Validation Loss:1.8602, Validation Accuracy:0.4397
Epoch #126: Loss:1.3880, Accuracy:0.5292, Validation Loss:1.8387, Validation Accuracy:0.4246
Epoch #127: Loss:1.3716, Accuracy:0.5380, Validation Loss:1.8145, Validation Accuracy:0.4347
Epoch #128: Loss:1.4143, Accuracy:0.5286, Validation Loss:1.8900, Validation Accuracy:0.3995
Epoch #129: Loss:1.4179, Accuracy:0.5280, Validation Loss:1.8597, Validation Accuracy:0.4322
Epoch #130: Loss:1.3957, Accuracy:0.5292, Validation Loss:1.8805, Validation Accuracy:0.3970
Epoch #131: Loss:1.3737, Accuracy:0.5399, Validation Loss:1.8714, Validation Accuracy:0.4171
Epoch #132: Loss:1.3952, Accuracy:0.5267, Validation Loss:1.8317, Validation Accuracy:0.4271
Epoch #133: Loss:1.3399, Accuracy:0.5468, Validation Loss:1.7923, Validation Accuracy:0.4648
Epoch #134: Loss:1.3129, Accuracy:0.5644, Validation Loss:1.7877, Validation Accuracy:0.4472
Epoch #135: Loss:1.3163, Accuracy:0.5449, Validation Loss:1.7758, Validation Accuracy:0.4698
Epoch #136: Loss:1.2892, Accuracy:0.5632, Validation Loss:1.7923, Validation Accuracy:0.4673
Epoch #137: Loss:1.2846, Accuracy:0.5651, Validation Loss:1.7868, Validation Accuracy:0.4573
Epoch #138: Loss:1.2893, Accuracy:0.5619, Validation Loss:1.8142, Validation Accuracy:0.4497
Epoch #139: Loss:1.2791, Accuracy:0.5588, Validation Loss:1.8064, Validation Accuracy:0.4447
Epoch #140: Loss:1.2836, Accuracy:0.5657, Validation Loss:1.8093, Validation Accuracy:0.4271
Epoch #141: Loss:1.2949, Accuracy:0.5663, Validation Loss:1.7989, Validation Accuracy:0.4422
Epoch #142: Loss:1.2741, Accuracy:0.5776, Validation Loss:1.7707, Validation Accuracy:0.4548
Epoch #143: Loss:1.2576, Accuracy:0.5808, Validation Loss:1.7988, Validation Accuracy:0.4523
Epoch #144: Loss:1.2400, Accuracy:0.5833, Validation Loss:1.7886, Validation Accuracy:0.4347
Epoch #145: Loss:1.2717, Accuracy:0.5676, Validation Loss:1.7875, Validation Accuracy:0.4548
Epoch #146: Loss:1.2499, Accuracy:0.5732, Validation Loss:1.7966, Validation Accuracy:0.4598
Epoch #147: Loss:1.2486, Accuracy:0.5764, Validation Loss:1.7978, Validation Accuracy:0.4623
Epoch #148: Loss:1.2370, Accuracy:0.5808, Validation Loss:1.7571, Validation Accuracy:0.4598
Epoch #149: Loss:1.2439, Accuracy:0.5814, Validation Loss:1.7986, Validation Accuracy:0.4648
Epoch #150: Loss:1.2537, Accuracy:0.5814, Validation Loss:1.8040, Validation Accuracy:0.4573
Epoch #151: Loss:1.2380, Accuracy:0.5827, Validation Loss:1.8350, Validation Accuracy:0.4322
Epoch #152: Loss:1.2406, Accuracy:0.5839, Validation Loss:1.8354, Validation Accuracy:0.4422
Epoch #153: Loss:1.2333, Accuracy:0.5877, Validation Loss:1.8138, Validation Accuracy:0.4322
Epoch #154: Loss:1.2211, Accuracy:0.5921, Validation Loss:1.8046, Validation Accuracy:0.4548
Epoch #155: Loss:1.2216, Accuracy:0.5984, Validation Loss:1.8322, Validation Accuracy:0.4372
Epoch #156: Loss:1.1989, Accuracy:0.5946, Validation Loss:1.7935, Validation Accuracy:0.4347
Epoch #157: Loss:1.2048, Accuracy:0.5940, Validation Loss:1.8049, Validation Accuracy:0.4422
Epoch #158: Loss:1.1828, Accuracy:0.6078, Validation Loss:1.7871, Validation Accuracy:0.4573
Epoch #159: Loss:1.1750, Accuracy:0.6021, Validation Loss:1.8023, Validation Accuracy:0.4548
Epoch #160: Loss:1.1808, Accuracy:0.6053, Validation Loss:1.8075, Validation Accuracy:0.4422
Epoch #161: Loss:1.1573, Accuracy:0.6141, Validation Loss:1.8010, Validation Accuracy:0.4447
Epoch #162: Loss:1.1814, Accuracy:0.6015, Validation Loss:1.7862, Validation Accuracy:0.4472
Epoch #163: Loss:1.1792, Accuracy:0.5984, Validation Loss:1.7938, Validation Accuracy:0.4497
Epoch #164: Loss:1.1652, Accuracy:0.6185, Validation Loss:1.8091, Validation Accuracy:0.4472
Epoch #165: Loss:1.1487, Accuracy:0.6160, Validation Loss:1.7964, Validation Accuracy:0.4523
Epoch #166: Loss:1.1441, Accuracy:0.6191, Validation Loss:1.7841, Validation Accuracy:0.4497
Epoch #167: Loss:1.1602, Accuracy:0.5996, Validation Loss:1.7990, Validation Accuracy:0.4523
Epoch #168: Loss:1.1527, Accuracy:0.6059, Validation Loss:1.7868, Validation Accuracy:0.4497
Epoch #169: Loss:1.1506, Accuracy:0.6084, Validation Loss:1.7835, Validation Accuracy:0.4648
Epoch #170: Loss:1.1409, Accuracy:0.6153, Validation Loss:1.7890, Validation Accuracy:0.4472
Epoch #171: Loss:1.1557, Accuracy:0.6197, Validation Loss:1.8000, Validation Accuracy:0.4397
Epoch #172: Loss:1.1491, Accuracy:0.6153, Validation Loss:1.8111, Validation Accuracy:0.4347
Epoch #173: Loss:1.1446, Accuracy:0.6210, Validation Loss:1.7984, Validation Accuracy:0.4246
Epoch #174: Loss:1.1395, Accuracy:0.6109, Validation Loss:1.8061, Validation Accuracy:0.4523
Epoch #175: Loss:1.1369, Accuracy:0.6210, Validation Loss:1.8006, Validation Accuracy:0.4598
Epoch #176: Loss:1.1348, Accuracy:0.6292, Validation Loss:1.7879, Validation Accuracy:0.4523
Epoch #177: Loss:1.1320, Accuracy:0.6147, Validation Loss:1.7929, Validation Accuracy:0.4573
Epoch #178: Loss:1.1312, Accuracy:0.6273, Validation Loss:1.8092, Validation Accuracy:0.4573
Epoch #179: Loss:1.1162, Accuracy:0.6254, Validation Loss:1.7716, Validation Accuracy:0.4598
Epoch #180: Loss:1.1213, Accuracy:0.6241, Validation Loss:1.7860, Validation Accuracy:0.4497
Epoch #181: Loss:1.1130, Accuracy:0.6266, Validation Loss:1.7839, Validation Accuracy:0.4724
Epoch #182: Loss:1.1002, Accuracy:0.6411, Validation Loss:1.8019, Validation Accuracy:0.4472
Epoch #183: Loss:1.1009, Accuracy:0.6298, Validation Loss:1.8109, Validation Accuracy:0.4598
Epoch #184: Loss:1.1095, Accuracy:0.6329, Validation Loss:1.7939, Validation Accuracy:0.4623
Epoch #185: Loss:1.1173, Accuracy:0.6179, Validation Loss:1.7963, Validation Accuracy:0.4548
Epoch #186: Loss:1.1050, Accuracy:0.6260, Validation Loss:1.8035, Validation Accuracy:0.4497
Epoch #187: Loss:1.1110, Accuracy:0.6298, Validation Loss:1.8143, Validation Accuracy:0.4397
Epoch #188: Loss:1.1005, Accuracy:0.6348, Validation Loss:1.7989, Validation Accuracy:0.4497
Epoch #189: Loss:1.1157, Accuracy:0.6166, Validation Loss:1.8069, Validation Accuracy:0.4497
Epoch #190: Loss:1.1172, Accuracy:0.6172, Validation Loss:1.8038, Validation Accuracy:0.4497
Epoch #191: Loss:1.1182, Accuracy:0.6266, Validation Loss:1.8100, Validation Accuracy:0.4347
Epoch #192: Loss:1.1107, Accuracy:0.6323, Validation Loss:1.8078, Validation Accuracy:0.4497
Epoch #193: Loss:1.1099, Accuracy:0.6235, Validation Loss:1.8053, Validation Accuracy:0.4497

Restoring best model...
Test:
Test Loss:1.75708425, Accuracy:0.4598
Labels: ['ib', 'eg', 'yd', 'aa', 'my', 'kk', 'sg', 'sd', 'ck', 'eb', 'by', 'ce', 'am', 'eo', 'mb', 'ig', 'ek', 'sk', 'ds', 'ab']
Confusion Matrix:
      ib  eg  yd  aa  my  kk  sg  sd  ck  eb  by  ce  am  eo  mb  ig  ek  sk  ds  ab
t:ib   9   2   2   0   1   0   1   1   0   0   0   1   2   0   0   0   0   1   0   0
t:eg   1   9   0   0   0   0   0   0   1   0   1   0   4   0   0   0   1   0   2   1
t:yd   0   0   8   1   0   0   3   0   0   0   0   0   1   0   0   4   1   0   0   2
t:aa   0   4   0   8   0   1   1   0   0   0   0   1   4   0   1   0   0   0   0   0
t:my   1   1   0   0   5   1   0   0   3   0   0   0   0   0   3   0   1   1   1   1
t:kk   0   0   1   0   0   9   0   0   0   0   0   0   2   0   0   1   4   0   0   3
t:sg   0   0   3   0   0   0  14   0   0   0   0   0   0   0   0   1   1   0   0   1
t:sd   1   0   3   0   1   1   1  11   0   0   0   0   0   0   0   1   1   0   0   0
t:ck   0   0   1   1   2   0   0   0   9   1   0   1   1   0   1   0   0   1   1   1
t:eb   0   0   0   0   0   0   0   0   0  15   0   0   1   0   0   0   0   0   2   2
t:by   0   5   0   0   0   0   5   0   0   0   8   1   0   0   0   1   0   0   0   0
t:ce   2   0   0   1   0   0   0   0   1   1   4   8   0   0   2   1   0   0   0   0
t:am   0   0   0   0   0   1   1   0   0   0   0   0  12   0   0   2   1   1   1   1
t:eo   1   1   0   1   0   0   0   0   0   0   2   2   0  13   0   0   0   0   0   0
t:mb   1   0   0   0   2   0   0   1   1   0   0   0   1   0   4   0   2   2   0   6
t:ig   1   0   4   0   0   1   0   1   1   0   0   0   0   0   0  12   0   0   0   0
t:ek   0   0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   5   5   1   0
t:sk   1   1   0   0   1   0   0   0   4   3   0   0   3   0   2   0   0   2   2   1
t:ds   0   0   0   0   0   0   0   0   1   4   0   1   0   0   0   0   2   2  10   0
t:ab   1   0   0   0   0   0   0   0   0   1   0   0   3   0   2   1   0   0   0  12
Classification Report:
              precision    recall  f1-score   support

          ib       0.47      0.45      0.46        20
          eg       0.39      0.45      0.42        20
          yd       0.36      0.40      0.38        20
          aa       0.67      0.40      0.50        20
          my       0.42      0.28      0.33        18
          kk       0.64      0.45      0.53        20
          sg       0.54      0.70      0.61        20
          sd       0.79      0.55      0.65        20
          ck       0.43      0.45      0.44        20
          eb       0.60      0.75      0.67        20
          by       0.53      0.40      0.46        20
          ce       0.53      0.40      0.46        20
          am       0.28      0.60      0.38        20
          eo       1.00      0.65      0.79        20
          mb       0.27      0.20      0.23        20
          ig       0.50      0.60      0.55        20
          ek       0.26      0.25      0.26        20
          sk       0.13      0.10      0.11        20
          ds       0.50      0.50      0.50        20
          ab       0.39      0.60      0.47        20

   micro avg       0.46      0.46      0.46       398
   macro avg       0.49      0.46      0.46       398
weighted avg       0.49      0.46      0.46       398

============ Config: 1/1 === End Time: 2019.11.05 04:47:18 =========================================
============ Config: 1/1 === Duration: 0 days, 0 hours, 18 minutes, 0 seconds =====================

Ending script after plotting results...
